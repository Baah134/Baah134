{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1He4n3H-TkbbquC1ypigYe1B7npGx-PFw",
      "authorship_tag": "ABX9TyOcKSYCaQ0pmzO/lVCZ65dO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/SER_CARINE/Paper_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfuGDb0ihyl1",
        "outputId": "073c85df-3101-4c44-a0c8-7736550d7b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Processing RAVDESS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 6/24 [04:49<14:57, 49.86s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1012\n",
            "  warnings.warn(\n",
            "100%|██████████| 24/24 [19:22<00:00, 48.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAVDESS Saved: 1440 samples.\n",
            "\n",
            ">>> Processing EMO-DB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/535 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=692\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=562\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=854\n",
            "  warnings.warn(\n",
            "  0%|          | 1/535 [00:01<15:34,  1.75s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=655\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=532\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=808\n",
            "  warnings.warn(\n",
            "  0%|          | 2/535 [00:03<15:36,  1.76s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=993\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=497\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=807\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=404\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=613\n",
            "  warnings.warn(\n",
            "  1%|          | 3/535 [00:05<14:46,  1.67s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=732\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=595\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=904\n",
            "  warnings.warn(\n",
            "  1%|          | 4/535 [00:06<14:51,  1.68s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=647\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=526\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=799\n",
            "  warnings.warn(\n",
            "  1%|          | 5/535 [00:09<17:19,  1.96s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=598\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=973\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=487\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=739\n",
            "  warnings.warn(\n",
            "  1%|          | 6/535 [00:12<20:36,  2.34s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=556\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=903\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=452\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=686\n",
            "  warnings.warn(\n",
            "  1%|▏         | 8/535 [00:20<26:26,  3.01s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=680\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=553\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=840\n",
            "  warnings.warn(\n",
            "  2%|▏         | 11/535 [00:25<18:58,  2.17s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=989\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=804\n",
            "  warnings.warn(\n",
            "  2%|▏         | 12/535 [00:27<19:13,  2.20s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1021\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=830\n",
            "  warnings.warn(\n",
            "  3%|▎         | 16/535 [00:29<10:02,  1.16s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=744\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=605\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=918\n",
            "  warnings.warn(\n",
            "  3%|▎         | 17/535 [00:30<10:30,  1.22s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=849\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=691\n",
            "  warnings.warn(\n",
            "  3%|▎         | 18/535 [00:32<11:09,  1.29s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=554\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=901\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=451\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=684\n",
            "  warnings.warn(\n",
            "  4%|▎         | 19/535 [00:33<11:07,  1.29s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=682\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=841\n",
            "  warnings.warn(\n",
            "  4%|▎         | 20/535 [00:35<11:18,  1.32s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=677\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=550\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=835\n",
            "  warnings.warn(\n",
            "  4%|▍         | 21/535 [00:36<11:29,  1.34s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=705\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=573\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=870\n",
            "  warnings.warn(\n",
            "  4%|▍         | 22/535 [00:38<13:12,  1.54s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=928\n",
            "  warnings.warn(\n",
            "  4%|▍         | 23/535 [00:41<16:31,  1.94s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=622\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=506\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=768\n",
            "  warnings.warn(\n",
            "  4%|▍         | 24/535 [00:43<15:46,  1.85s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=927\n",
            "  warnings.warn(\n",
            "  5%|▍         | 25/535 [00:45<15:55,  1.87s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=936\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=761\n",
            "  warnings.warn(\n",
            "  5%|▌         | 27/535 [00:46<11:55,  1.41s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=712\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=579\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=879\n",
            "  warnings.warn(\n",
            "  5%|▌         | 28/535 [00:48<11:57,  1.42s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=427\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=649\n",
            "  warnings.warn(\n",
            "  5%|▌         | 29/535 [00:49<11:37,  1.38s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=856\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=696\n",
            "  warnings.warn(\n",
            "  6%|▌         | 30/535 [00:51<12:02,  1.43s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=912\n",
            "  warnings.warn(\n",
            "  6%|▌         | 32/535 [00:53<10:46,  1.29s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=892\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=726\n",
            "  warnings.warn(\n",
            "  6%|▌         | 33/535 [00:55<13:09,  1.57s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=519\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=843\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=422\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=640\n",
            "  warnings.warn(\n",
            "  6%|▋         | 34/535 [00:57<13:48,  1.65s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=674\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=548\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=832\n",
            "  warnings.warn(\n",
            "  7%|▋         | 36/535 [00:59<10:34,  1.27s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=687\n",
            "  warnings.warn(\n",
            "  7%|▋         | 37/535 [01:00<10:31,  1.27s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=530\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=861\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=431\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=654\n",
            "  warnings.warn(\n",
            "  7%|▋         | 38/535 [01:01<10:31,  1.27s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=771\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=627\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=951\n",
            "  warnings.warn(\n",
            "  7%|▋         | 39/535 [01:03<11:00,  1.33s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=639\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=520\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=789\n",
            "  warnings.warn(\n",
            "  7%|▋         | 40/535 [01:04<11:02,  1.34s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1010\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=821\n",
            "  warnings.warn(\n",
            "  8%|▊         | 41/535 [01:06<11:57,  1.45s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=650\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=529\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=803\n",
            "  warnings.warn(\n",
            "  8%|▊         | 42/535 [01:07<11:47,  1.43s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=720\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=585\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=888\n",
            "  warnings.warn(\n",
            "  8%|▊         | 44/535 [01:09<10:16,  1.26s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=812\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=660\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1002\n",
            "  warnings.warn(\n",
            "  8%|▊         | 45/535 [01:12<12:24,  1.52s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1005\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=817\n",
            "  warnings.warn(\n",
            "  9%|▉         | 47/535 [01:14<11:04,  1.36s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=619\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=939\n",
            "  warnings.warn(\n",
            "  9%|▉         | 48/535 [01:15<11:15,  1.39s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=984\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=800\n",
            "  warnings.warn(\n",
            "  9%|▉         | 49/535 [01:17<11:52,  1.47s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=735\n",
            "  warnings.warn(\n",
            "  9%|▉         | 50/535 [01:19<12:12,  1.51s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=955\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=777\n",
            "  warnings.warn(\n",
            " 10%|▉         | 51/535 [01:20<12:36,  1.56s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=685\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=557\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=846\n",
            "  warnings.warn(\n",
            " 10%|▉         | 52/535 [01:22<12:15,  1.52s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=725\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=589\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=895\n",
            "  warnings.warn(\n",
            " 10%|▉         | 53/535 [01:23<12:30,  1.56s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=748\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=608\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=924\n",
            "  warnings.warn(\n",
            " 10%|█         | 54/535 [01:26<14:16,  1.78s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=571\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=464\n",
            "  warnings.warn(\n",
            " 11%|█         | 57/535 [01:27<08:56,  1.12s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=941\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=471\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=715\n",
            "  warnings.warn(\n",
            " 11%|█         | 58/535 [01:29<09:12,  1.16s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=820\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=667\n",
            "  warnings.warn(\n",
            " 11%|█         | 59/535 [01:30<09:54,  1.25s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=763\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=620\n",
            "  warnings.warn(\n",
            " 11%|█         | 60/535 [01:32<10:28,  1.32s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=862\n",
            "  warnings.warn(\n",
            " 11%|█▏        | 61/535 [01:33<10:16,  1.30s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=537\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=873\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=437\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=663\n",
            "  warnings.warn(\n",
            " 12%|█▏        | 63/535 [01:37<13:22,  1.70s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=448\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=679\n",
            "  warnings.warn(\n",
            " 12%|█▏        | 64/535 [01:39<13:58,  1.78s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=633\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=515\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=781\n",
            "  warnings.warn(\n",
            " 12%|█▏        | 65/535 [01:41<14:54,  1.90s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=845\n",
            "  warnings.warn(\n",
            " 12%|█▏        | 66/535 [01:43<14:17,  1.83s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=476\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=722\n",
            "  warnings.warn(\n",
            " 13%|█▎        | 67/535 [01:44<13:06,  1.68s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=546\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=444\n",
            "  warnings.warn(\n",
            " 13%|█▎        | 70/535 [01:48<10:54,  1.41s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=839\n",
            "  warnings.warn(\n",
            " 13%|█▎        | 71/535 [01:49<11:13,  1.45s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=616\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1001\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=501\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=760\n",
            "  warnings.warn(\n",
            " 13%|█▎        | 72/535 [01:51<11:04,  1.44s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=617\n",
            "  warnings.warn(\n",
            " 14%|█▍        | 76/535 [01:55<09:40,  1.26s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=580\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=943\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=472\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=716\n",
            "  warnings.warn(\n",
            " 14%|█▍        | 77/535 [01:57<10:09,  1.33s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=863\n",
            "  warnings.warn(\n",
            " 15%|█▍        | 79/535 [01:58<08:49,  1.16s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=711\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=878\n",
            "  warnings.warn(\n",
            " 15%|█▍        | 80/535 [02:00<09:14,  1.22s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=765\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=944\n",
            "  warnings.warn(\n",
            " 15%|█▌        | 82/535 [02:01<07:53,  1.05s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=980\n",
            "  warnings.warn(\n",
            " 16%|█▌        | 83/535 [02:03<09:22,  1.24s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=964\n",
            "  warnings.warn(\n",
            " 16%|█▌        | 84/535 [02:05<10:36,  1.41s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=938\n",
            "  warnings.warn(\n",
            " 16%|█▌        | 85/535 [02:08<12:18,  1.64s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=538\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=875\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=438\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=665\n",
            "  warnings.warn(\n",
            " 16%|█▋        | 87/535 [02:12<14:05,  1.89s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=609\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=991\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=496\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=752\n",
            "  warnings.warn(\n",
            " 17%|█▋        | 89/535 [02:13<10:03,  1.35s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=517\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=420\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=638\n",
            "  warnings.warn(\n",
            " 17%|█▋        | 90/535 [02:14<09:51,  1.33s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=662\n",
            "  warnings.warn(\n",
            " 17%|█▋        | 91/535 [02:16<10:02,  1.36s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=887\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 94/535 [02:20<09:32,  1.30s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=844\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=641\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 95/535 [02:22<10:23,  1.42s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=975\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=793\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 96/535 [02:24<12:14,  1.67s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=707\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=575\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=872\n",
            "  warnings.warn(\n",
            " 18%|█▊        | 98/535 [02:28<13:46,  1.89s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=625\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1015\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=508\n",
            "  warnings.warn(\n",
            " 19%|█▊        | 99/535 [02:30<12:45,  1.75s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=631\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=513\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=779\n",
            "  warnings.warn(\n",
            " 19%|█▉        | 102/535 [02:33<09:48,  1.36s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=899\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=450\n",
            "  warnings.warn(\n",
            " 19%|█▉        | 103/535 [02:34<09:38,  1.34s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=581\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=717\n",
            "  warnings.warn(\n",
            " 20%|█▉        | 105/535 [02:38<13:04,  1.83s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=970\n",
            "  warnings.warn(\n",
            " 20%|█▉        | 106/535 [02:40<13:30,  1.89s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=495\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=751\n",
            "  warnings.warn(\n",
            " 20%|██        | 108/535 [02:44<13:09,  1.85s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=987\n",
            "  warnings.warn(\n",
            " 20%|██        | 109/535 [02:45<12:30,  1.76s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=934\n",
            "  warnings.warn(\n",
            " 21%|██        | 110/535 [02:47<12:44,  1.80s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=893\n",
            "  warnings.warn(\n",
            " 21%|██        | 112/535 [02:49<10:19,  1.46s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=587\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=954\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=477\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=724\n",
            "  warnings.warn(\n",
            " 21%|██▏       | 114/535 [02:54<12:17,  1.75s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1004\n",
            "  warnings.warn(\n",
            " 21%|██▏       | 115/535 [02:56<12:43,  1.82s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=860\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=430\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=653\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 117/535 [02:57<09:00,  1.29s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=621\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1009\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=505\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=766\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 118/535 [02:58<09:04,  1.31s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=623\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1013\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=507\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=769\n",
            "  warnings.warn(\n",
            " 23%|██▎       | 124/535 [03:04<07:19,  1.07s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=865\n",
            "  warnings.warn(\n",
            " 23%|██▎       | 125/535 [03:07<09:24,  1.38s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=502\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=762\n",
            "  warnings.warn(\n",
            " 24%|██▎       | 127/535 [03:10<10:37,  1.56s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=945\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=473\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=718\n",
            "  warnings.warn(\n",
            " 25%|██▍       | 133/535 [03:23<14:24,  2.15s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=867\n",
            "  warnings.warn(\n",
            " 25%|██▌       | 134/535 [03:25<13:23,  2.00s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=572\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=930\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=465\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=706\n",
            "  warnings.warn(\n",
            " 25%|██▌       | 136/535 [03:26<09:53,  1.49s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=782\n",
            "  warnings.warn(\n",
            " 26%|██▌       | 140/535 [03:36<14:46,  2.24s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=511\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=415\n",
            "  warnings.warn(\n",
            " 26%|██▋       | 141/535 [03:38<13:09,  2.00s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=923\n",
            "  warnings.warn(\n",
            " 27%|██▋       | 143/535 [03:39<09:55,  1.52s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=701\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=570\n",
            "  warnings.warn(\n",
            " 27%|██▋       | 144/535 [03:41<09:45,  1.50s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=583\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=948\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=474\n",
            "  warnings.warn(\n",
            " 27%|██▋       | 145/535 [03:42<09:26,  1.45s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=584\n",
            "  warnings.warn(\n",
            " 27%|██▋       | 147/535 [03:46<10:26,  1.61s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=688\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=559\n",
            "  warnings.warn(\n",
            " 28%|██▊       | 148/535 [03:48<11:10,  1.73s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=997\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=811\n",
            "  warnings.warn(\n",
            " 28%|██▊       | 149/535 [03:50<12:40,  1.97s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=778\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=960\n",
            "  warnings.warn(\n",
            " 28%|██▊       | 150/535 [03:52<11:53,  1.85s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=868\n",
            "  warnings.warn(\n",
            " 29%|██▊       | 153/535 [03:55<09:00,  1.42s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=931\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=757\n",
            "  warnings.warn(\n",
            " 29%|██▉       | 154/535 [03:57<09:23,  1.48s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=750\n",
            "  warnings.warn(\n",
            " 30%|██▉       | 159/535 [04:04<08:42,  1.39s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=645\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=979\n",
            "  warnings.warn(\n",
            " 30%|██▉       | 160/535 [04:06<09:14,  1.48s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=736\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=908\n",
            "  warnings.warn(\n",
            " 30%|███       | 161/535 [04:07<09:14,  1.48s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=826\n",
            "  warnings.warn(\n",
            " 31%|███       | 164/535 [04:13<10:45,  1.74s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=690\n",
            "  warnings.warn(\n",
            " 31%|███       | 166/535 [04:14<08:08,  1.32s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=824\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=670\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1017\n",
            "  warnings.warn(\n",
            " 32%|███▏      | 171/535 [04:23<10:12,  1.68s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=814\n",
            "  warnings.warn(\n",
            " 32%|███▏      | 173/535 [04:27<10:54,  1.81s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=896\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 174/535 [04:29<10:55,  1.81s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=764\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 177/535 [04:33<09:27,  1.59s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=747\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=607\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=922\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 179/535 [04:37<10:11,  1.72s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=644\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=524\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=795\n",
            "  warnings.warn(\n",
            " 34%|███▎      | 180/535 [04:38<09:36,  1.62s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=836\n",
            "  warnings.warn(\n",
            " 34%|███▍      | 181/535 [04:40<09:26,  1.60s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=950\n",
            "  warnings.warn(\n",
            " 34%|███▍      | 184/535 [04:48<13:58,  2.39s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=881\n",
            "  warnings.warn(\n",
            " 35%|███▍      | 186/535 [04:54<16:06,  2.77s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=742\n",
            "  warnings.warn(\n",
            " 35%|███▌      | 189/535 [04:55<08:47,  1.53s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=953\n",
            "  warnings.warn(\n",
            " 36%|███▌      | 190/535 [04:57<09:15,  1.61s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=564\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=917\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=459\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=697\n",
            "  warnings.warn(\n",
            " 36%|███▌      | 192/535 [04:59<07:33,  1.32s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=850\n",
            "  warnings.warn(\n",
            " 36%|███▋      | 194/535 [05:01<07:21,  1.29s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=915\n",
            "  warnings.warn(\n",
            " 37%|███▋      | 197/535 [05:04<06:22,  1.13s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=842\n",
            "  warnings.warn(\n",
            " 38%|███▊      | 202/535 [05:10<05:58,  1.08s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=558\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=454\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=689\n",
            "  warnings.warn(\n",
            " 38%|███▊      | 203/535 [05:11<06:13,  1.12s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=611\n",
            "  warnings.warn(\n",
            " 38%|███▊      | 205/535 [05:15<08:57,  1.63s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=776\n",
            "  warnings.warn(\n",
            " 39%|███▊      | 206/535 [05:17<09:16,  1.69s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=898\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=730\n",
            "  warnings.warn(\n",
            " 39%|███▉      | 208/535 [05:21<09:37,  1.77s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1014\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=825\n",
            "  warnings.warn(\n",
            " 40%|███▉      | 212/535 [05:30<12:26,  2.31s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=910\n",
            "  warnings.warn(\n",
            " 40%|████      | 216/535 [05:38<11:32,  2.17s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=700\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=569\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=864\n",
            "  warnings.warn(\n",
            " 41%|████      | 219/535 [05:43<09:00,  1.71s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=643\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=523\n",
            "  warnings.warn(\n",
            " 41%|████▏     | 221/535 [05:47<10:39,  2.04s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=858\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=698\n",
            "  warnings.warn(\n",
            " 41%|████▏     | 222/535 [05:49<09:59,  1.92s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=816\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=664\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1008\n",
            "  warnings.warn(\n",
            " 42%|████▏     | 225/535 [05:52<07:03,  1.36s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=710\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=577\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=877\n",
            "  warnings.warn(\n",
            " 42%|████▏     | 227/535 [05:54<05:44,  1.12s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=694\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=857\n",
            "  warnings.warn(\n",
            " 43%|████▎     | 229/535 [05:58<08:41,  1.71s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=423\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=642\n",
            "  warnings.warn(\n",
            " 43%|████▎     | 231/535 [06:00<06:32,  1.29s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=906\n",
            "  warnings.warn(\n",
            " 44%|████▎     | 233/535 [06:04<08:04,  1.60s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=683\n",
            "  warnings.warn(\n",
            " 44%|████▎     | 234/535 [06:05<07:58,  1.59s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=576\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=935\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=468\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 236/535 [06:08<07:47,  1.56s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=834\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=678\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 237/535 [06:11<08:39,  1.74s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=756\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 238/535 [06:13<09:42,  1.96s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=565\n",
            "  warnings.warn(\n",
            " 45%|████▍     | 239/535 [06:14<08:42,  1.77s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=977\n",
            "  warnings.warn(\n",
            " 45%|████▌     | 241/535 [06:16<06:55,  1.41s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=410\n",
            "  warnings.warn(\n",
            " 45%|████▌     | 243/535 [06:18<05:20,  1.10s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1020\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=510\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=630\n",
            "  warnings.warn(\n",
            " 46%|████▌     | 244/535 [06:19<05:28,  1.13s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=767\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=946\n",
            "  warnings.warn(\n",
            " 47%|████▋     | 249/535 [06:24<04:51,  1.02s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=974\n",
            "  warnings.warn(\n",
            " 47%|████▋     | 250/535 [06:27<06:07,  1.29s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=958\n",
            "  warnings.warn(\n",
            " 47%|████▋     | 253/535 [06:30<05:55,  1.26s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=983\n",
            "  warnings.warn(\n",
            " 48%|████▊     | 259/535 [06:36<04:18,  1.07it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=876\n",
            "  warnings.warn(\n",
            " 49%|████▉     | 261/535 [06:41<06:43,  1.47s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=831\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=676\n",
            "  warnings.warn(\n",
            " 49%|████▉     | 264/535 [06:42<04:51,  1.08s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=544\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=442\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=672\n",
            "  warnings.warn(\n",
            " 50%|████▉     | 265/535 [06:44<04:59,  1.11s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=994\n",
            "  warnings.warn(\n",
            " 50%|█████     | 268/535 [06:48<05:15,  1.18s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=568\n",
            "  warnings.warn(\n",
            " 51%|█████     | 273/535 [06:59<08:22,  1.92s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=790\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=976\n",
            "  warnings.warn(\n",
            " 51%|█████     | 274/535 [07:00<07:51,  1.81s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1018\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=509\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=828\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=414\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=629\n",
            "  warnings.warn(\n",
            " 52%|█████▏    | 278/535 [07:05<06:41,  1.56s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=772\n",
            "  warnings.warn(\n",
            " 52%|█████▏    | 279/535 [07:08<07:29,  1.76s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=723\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=588\n",
            "  warnings.warn(\n",
            " 52%|█████▏    | 280/535 [07:10<07:55,  1.87s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=982\n",
            "  warnings.warn(\n",
            " 53%|█████▎    | 281/535 [07:12<07:56,  1.88s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1011\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=822\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=411\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=624\n",
            "  warnings.warn(\n",
            " 53%|█████▎    | 283/535 [07:13<05:32,  1.32s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=999\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=813\n",
            "  warnings.warn(\n",
            " 53%|█████▎    | 285/535 [07:16<06:01,  1.45s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=780\n",
            "  warnings.warn(\n",
            " 53%|█████▎    | 286/535 [07:18<06:14,  1.50s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=913\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=743\n",
            "  warnings.warn(\n",
            " 54%|█████▍    | 288/535 [07:19<04:58,  1.21s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=838\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=681\n",
            "  warnings.warn(\n",
            " 54%|█████▍    | 289/535 [07:22<05:57,  1.45s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=965\n",
            "  warnings.warn(\n",
            " 54%|█████▍    | 290/535 [07:24<07:04,  1.73s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=823\n",
            "  warnings.warn(\n",
            " 55%|█████▍    | 292/535 [07:27<06:34,  1.62s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=661\n",
            "  warnings.warn(\n",
            " 55%|█████▍    | 293/535 [07:29<06:28,  1.60s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=805\n",
            "  warnings.warn(\n",
            " 55%|█████▍    | 294/535 [07:31<06:32,  1.63s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=883\n",
            "  warnings.warn(\n",
            " 55%|█████▌    | 296/535 [07:32<05:02,  1.27s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=704\n",
            "  warnings.warn(\n",
            " 56%|█████▌    | 298/535 [07:38<08:25,  2.13s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=947\n",
            "  warnings.warn(\n",
            " 56%|█████▋    | 301/535 [07:44<08:11,  2.10s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=926\n",
            "  warnings.warn(\n",
            " 57%|█████▋    | 303/535 [07:46<06:06,  1.58s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=425\n",
            "  warnings.warn(\n",
            " 57%|█████▋    | 305/535 [07:51<07:54,  2.06s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=852\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=693\n",
            "  warnings.warn(\n",
            " 57%|█████▋    | 306/535 [07:53<07:48,  2.05s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=582\n",
            "  warnings.warn(\n",
            " 58%|█████▊    | 308/535 [07:54<05:32,  1.47s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=433\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=657\n",
            "  warnings.warn(\n",
            " 58%|█████▊    | 309/535 [07:56<05:19,  1.42s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1000\n",
            "  warnings.warn(\n",
            " 59%|█████▉    | 318/535 [08:07<04:55,  1.36s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=656\n",
            "  warnings.warn(\n",
            " 60%|█████▉    | 320/535 [08:10<04:58,  1.39s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=738\n",
            "  warnings.warn(\n",
            " 61%|██████    | 324/535 [08:13<03:48,  1.08s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=721\n",
            "  warnings.warn(\n",
            " 61%|██████    | 325/535 [08:14<04:09,  1.19s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=594\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=483\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=733\n",
            "  warnings.warn(\n",
            " 61%|██████    | 326/535 [08:16<04:14,  1.22s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=626\n",
            "  warnings.warn(\n",
            " 61%|██████    | 327/535 [08:17<04:40,  1.35s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=615\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=500\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=759\n",
            "  warnings.warn(\n",
            " 63%|██████▎   | 335/535 [08:26<03:50,  1.15s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=827\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=673\n",
            "  warnings.warn(\n",
            " 63%|██████▎   | 336/535 [08:27<04:05,  1.23s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=919\n",
            "  warnings.warn(\n",
            " 63%|██████▎   | 339/535 [08:30<03:43,  1.14s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=659\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=536\n",
            "  warnings.warn(\n",
            " 64%|██████▍   | 342/535 [08:32<02:57,  1.09it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=527\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=801\n",
            "  warnings.warn(\n",
            " 64%|██████▍   | 345/535 [08:37<04:03,  1.28s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=905\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=453\n",
            "  warnings.warn(\n",
            " 65%|██████▍   | 346/535 [08:39<04:03,  1.29s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=995\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=809\n",
            "  warnings.warn(\n",
            " 65%|██████▌   | 348/535 [08:40<03:30,  1.13s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=533\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=810\n",
            "  warnings.warn(\n",
            " 65%|██████▌   | 350/535 [08:43<03:58,  1.29s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=962\n",
            "  warnings.warn(\n",
            " 66%|██████▌   | 351/535 [08:45<04:14,  1.38s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=961\n",
            "  warnings.warn(\n",
            " 66%|██████▌   | 352/535 [08:47<04:57,  1.62s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=886\n",
            "  warnings.warn(\n",
            " 66%|██████▌   | 354/535 [08:50<04:11,  1.39s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=344\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=522\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 357/535 [08:51<02:41,  1.10it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=952\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 360/535 [08:55<03:30,  1.21s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=859\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 361/535 [08:57<03:55,  1.35s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=851\n",
            "  warnings.warn(\n",
            " 68%|██████▊   | 363/535 [09:01<04:38,  1.62s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=986\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=493\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=802\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=401\n",
            "  warnings.warn(\n",
            " 68%|██████▊   | 365/535 [09:05<05:09,  1.82s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=925\n",
            "  warnings.warn(\n",
            " 69%|██████▉   | 368/535 [09:08<03:27,  1.24s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=775\n",
            "  warnings.warn(\n",
            " 69%|██████▉   | 369/535 [09:09<03:43,  1.35s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=978\n",
            "  warnings.warn(\n",
            " 69%|██████▉   | 371/535 [09:12<03:54,  1.43s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=528\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=429\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=652\n",
            "  warnings.warn(\n",
            " 70%|██████▉   | 372/535 [09:14<03:44,  1.38s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=921\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=749\n",
            "  warnings.warn(\n",
            " 70%|███████   | 377/535 [09:22<04:11,  1.59s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=829\n",
            "  warnings.warn(\n",
            " 71%|███████   | 378/535 [09:24<04:16,  1.63s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=597\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=971\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=486\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=737\n",
            "  warnings.warn(\n",
            " 71%|███████   | 379/535 [09:25<04:00,  1.54s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=937\n",
            "  warnings.warn(\n",
            " 71%|███████   | 380/535 [09:26<03:56,  1.53s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=796\n",
            "  warnings.warn(\n",
            " 71%|███████   | 381/535 [09:28<04:07,  1.61s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=384\n",
            "  warnings.warn(\n",
            " 72%|███████▏  | 383/535 [09:34<05:43,  2.26s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=599\n",
            "  warnings.warn(\n",
            " 72%|███████▏  | 386/535 [09:39<04:49,  1.94s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=967\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=786\n",
            "  warnings.warn(\n",
            " 73%|███████▎  | 392/535 [09:47<03:45,  1.58s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=998\n",
            "  warnings.warn(\n",
            " 74%|███████▎  | 394/535 [09:49<03:34,  1.52s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=891\n",
            "  warnings.warn(\n",
            " 74%|███████▍  | 395/535 [09:51<03:30,  1.50s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=770\n",
            "  warnings.warn(\n",
            " 74%|███████▍  | 397/535 [09:54<03:23,  1.48s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=551\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=837\n",
            "  warnings.warn(\n",
            " 75%|███████▍  | 400/535 [09:58<03:04,  1.37s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=754\n",
            "  warnings.warn(\n",
            " 75%|███████▍  | 401/535 [10:00<03:31,  1.58s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=586\n",
            "  warnings.warn(\n",
            " 75%|███████▌  | 402/535 [10:01<03:24,  1.54s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=897\n",
            "  warnings.warn(\n",
            " 75%|███████▌  | 403/535 [10:03<03:34,  1.63s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=907\n",
            "  warnings.warn(\n",
            " 76%|███████▋  | 408/535 [10:12<04:30,  2.13s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=635\n",
            "  warnings.warn(\n",
            " 77%|███████▋  | 414/535 [10:23<03:47,  1.88s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=847\n",
            "  warnings.warn(\n",
            " 78%|███████▊  | 416/535 [10:27<03:58,  2.01s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=929\n",
            "  warnings.warn(\n",
            " 78%|███████▊  | 417/535 [10:29<04:02,  2.05s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=567\n",
            "  warnings.warn(\n",
            " 79%|███████▉  | 424/535 [10:35<02:02,  1.10s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=628\n",
            "  warnings.warn(\n",
            " 81%|████████▏ | 435/535 [10:50<01:52,  1.12s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=561\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=457\n",
            "  warnings.warn(\n",
            " 82%|████████▏ | 438/535 [10:53<01:43,  1.06s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=731\n",
            "  warnings.warn(\n",
            " 82%|████████▏ | 440/535 [10:56<01:43,  1.09s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=758\n",
            "  warnings.warn(\n",
            " 83%|████████▎ | 443/535 [11:01<02:18,  1.50s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=942\n",
            "  warnings.warn(\n",
            " 83%|████████▎ | 444/535 [11:03<02:26,  1.61s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1023\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=512\n",
            "  warnings.warn(\n",
            " 86%|████████▋ | 462/535 [11:20<00:52,  1.40it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=545\n",
            "  warnings.warn(\n",
            " 87%|████████▋ | 464/535 [11:21<00:51,  1.39it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=610\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=992\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=753\n",
            "  warnings.warn(\n",
            " 87%|████████▋ | 465/535 [11:23<01:03,  1.10it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=563\n",
            "  warnings.warn(\n",
            " 87%|████████▋ | 468/535 [11:29<01:32,  1.38s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=709\n",
            "  warnings.warn(\n",
            " 88%|████████▊ | 469/535 [11:31<01:34,  1.43s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=981\n",
            "  warnings.warn(\n",
            " 88%|████████▊ | 473/535 [11:34<01:05,  1.06s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=466\n",
            "  warnings.warn(\n",
            " 89%|████████▉ | 476/535 [11:38<01:02,  1.06s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=618\n",
            "  warnings.warn(\n",
            " 89%|████████▉ | 477/535 [11:40<01:15,  1.30s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=668\n",
            "  warnings.warn(\n",
            " 89%|████████▉ | 478/535 [11:41<01:17,  1.35s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1022\n",
            "  warnings.warn(\n",
            " 90%|████████▉ | 481/535 [11:45<01:03,  1.17s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=456\n",
            "  warnings.warn(\n",
            " 90%|█████████ | 482/535 [11:46<01:03,  1.19s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=916\n",
            "  warnings.warn(\n",
            " 91%|█████████ | 487/535 [11:53<01:09,  1.44s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=900\n",
            "  warnings.warn(\n",
            " 93%|█████████▎| 495/535 [12:09<01:23,  2.10s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=543\n",
            "  warnings.warn(\n",
            " 94%|█████████▎| 501/535 [12:13<00:30,  1.12it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=956\n",
            "  warnings.warn(\n",
            " 94%|█████████▍| 502/535 [12:15<00:36,  1.09s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1003\n",
            "  warnings.warn(\n",
            " 95%|█████████▍| 506/535 [12:18<00:23,  1.22it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=671\n",
            "  warnings.warn(\n",
            " 95%|█████████▌| 509/535 [12:22<00:28,  1.10s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=636\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=785\n",
            "  warnings.warn(\n",
            " 96%|█████████▋| 515/535 [12:27<00:17,  1.12it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=746\n",
            "  warnings.warn(\n",
            " 97%|█████████▋| 518/535 [12:30<00:16,  1.05it/s]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=531\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=806\n",
            "  warnings.warn(\n",
            " 98%|█████████▊| 526/535 [12:39<00:09,  1.05s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=614\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=933\n",
            "  warnings.warn(\n",
            " 99%|█████████▉| 529/535 [12:42<00:06,  1.06s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=990\n",
            "  warnings.warn(\n",
            " 99%|█████████▉| 530/535 [12:44<00:06,  1.24s/it]/usr/local/lib/python3.12/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=890\n",
            "  warnings.warn(\n",
            "100%|██████████| 535/535 [12:52<00:00,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EMO-DB Saved: 2040 samples (should be 5x original count).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "import soundfile as sf\n",
        "\n",
        "# --- Configuration ---\n",
        "# Output Path for Saved Arrays\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/DeepLearning/Paper_9_Replication_Features/\"\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Audio Settings\n",
        "SAMPLE_RATE = 22050 # Librosa default\n",
        "DURATION_FIXED = 3.0 # Optional: Fix duration if needed, or leave dynamic\n",
        "\n",
        "# --- Part 1: Feature Extraction Logic (The 193-Dim Vector) ---\n",
        "def extract_features(data, sr=SAMPLE_RATE):\n",
        "    \"\"\"\n",
        "    Extracts the 5 features specified in Issa et al. (2020) and returns a 193-dim vector.\n",
        "    Features: MFCC (40), Chroma (12), Mel (128), Contrast (7), Tonnetz (6).\n",
        "    \"\"\"\n",
        "    # 1. MFCC (40)\n",
        "    stft = np.abs(librosa.stft(data))\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40).T, axis=0)\n",
        "\n",
        "    # 2. Chroma (12)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T, axis=0)\n",
        "\n",
        "    # 3. Mel Spectrogram (128)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sr).T, axis=0)\n",
        "\n",
        "    # 4. Spectral Contrast (7)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sr).T, axis=0)\n",
        "\n",
        "    # 5. Tonnetz (6)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(data), sr=sr).T, axis=0)\n",
        "\n",
        "    # Stack all features (40 + 12 + 128 + 7 + 6 = 193)\n",
        "    return np.hstack([mfccs, chroma, mel, contrast, tonnetz])\n",
        "\n",
        "# --- Part 2: Augmentation Logic (For EMO-DB Only) ---\n",
        "def augment_audio(data, sr):\n",
        "    \"\"\"\n",
        "    Generates 4 augmented versions of the input audio.\n",
        "    1. Speed Up (1.23x)\n",
        "    2. Slow Down (0.81x)\n",
        "    3. Noise (25% of length)\n",
        "    4. Time Shift\n",
        "    \"\"\"\n",
        "    augmented_versions = []\n",
        "\n",
        "    # 1. Speed Up (1.23)\n",
        "    # Note: simple resampling changes pitch too, which is common in simple augmentation\n",
        "    y_fast = librosa.effects.time_stretch(data, rate=1.23)\n",
        "    augmented_versions.append(y_fast)\n",
        "\n",
        "    # 2. Slow Down (0.81)\n",
        "    y_slow = librosa.effects.time_stretch(data, rate=0.81)\n",
        "    augmented_versions.append(y_slow)\n",
        "\n",
        "    # 3. Noise (Add random noise to 25% of the file)\n",
        "    y_noise = data.copy()\n",
        "    noise_len = int(len(y_noise) * 0.25)\n",
        "    start_idx = np.random.randint(0, len(y_noise) - noise_len)\n",
        "    noise = np.random.randn(noise_len) * 0.005 # Scale noise\n",
        "    y_noise[start_idx : start_idx + noise_len] += noise\n",
        "    augmented_versions.append(y_noise)\n",
        "\n",
        "    # 4. Time Shift (Shift start by small amount)\n",
        "    shift_range = int(np.random.uniform(-0.05, 0.05) * len(data))\n",
        "    y_shift = np.roll(data, shift_range)\n",
        "    augmented_versions.append(y_shift)\n",
        "\n",
        "    return augmented_versions\n",
        "\n",
        "# ==========================================\n",
        "# PROCESS 1: RAVDESS (The Baseline - 8 Classes)\n",
        "# ==========================================\n",
        "print(\">>> Processing RAVDESS...\")\n",
        "ravdess_path = \"/content/drive/MyDrive/DeepLearning/External/RAVDESS Emotional Speech Audio/audio_speech_actors_01-24/\"\n",
        "\n",
        "X_rav = []\n",
        "y_rav = []\n",
        "groups_rav = [] # Actor IDs\n",
        "\n",
        "# Mapping (Paper uses 8 classes: Calm is distinct)\n",
        "rav_mapping = {\n",
        "    1:'neutral', 2:'calm', 3:'happy', 4:'sad',\n",
        "    5:'angry', 6:'fear', 7:'disgust', 8:'surprise'\n",
        "}\n",
        "\n",
        "if os.path.exists(ravdess_path):\n",
        "    actors = os.listdir(ravdess_path)\n",
        "    for actor_dir in tqdm(actors):\n",
        "        actor_path = os.path.join(ravdess_path, actor_dir)\n",
        "        if not os.path.isdir(actor_path): continue\n",
        "\n",
        "        for file in os.listdir(actor_path):\n",
        "            try:\n",
        "                # Parse Filename: 03-01-06-01-02-01-12.wav\n",
        "                parts = file.split('.')[0].split('-')\n",
        "                emotion_code = int(parts[2])\n",
        "                actor_id = parts[6] # The last part is the actor ID\n",
        "\n",
        "                # Load Audio\n",
        "                file_path = os.path.join(actor_path, file)\n",
        "                data, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "                # Extract Features (No Augmentation)\n",
        "                features = extract_features(data, sr)\n",
        "\n",
        "                label = rav_mapping.get(emotion_code)\n",
        "                if label:\n",
        "                    X_rav.append(features)\n",
        "                    y_rav.append(label)\n",
        "                    groups_rav.append(actor_id)\n",
        "            except Exception as e:\n",
        "                print(f\"Error RAVDESS {file}: {e}\")\n",
        "\n",
        "    # Save RAVDESS\n",
        "    np.save(f\"{OUTPUT_PATH}RAVDESS_X.npy\", np.array(X_rav))\n",
        "    np.save(f\"{OUTPUT_PATH}RAVDESS_y.npy\", np.array(y_rav))\n",
        "    np.save(f\"{OUTPUT_PATH}RAVDESS_groups.npy\", np.array(groups_rav))\n",
        "    print(f\"RAVDESS Saved: {len(X_rav)} samples.\")\n",
        "\n",
        "# ==========================================\n",
        "# PROCESS 2: EMO-DB (Model B - 5 Classes + Augmentation)\n",
        "# ==========================================\n",
        "print(\"\\n>>> Processing EMO-DB...\")\n",
        "emodb_path = \"/content/drive/MyDrive/DeepLearning/External/EMoDB/\"\n",
        "\n",
        "X_emo = []\n",
        "y_emo = []\n",
        "groups_emo = []\n",
        "\n",
        "# Filter: Remove 'Boredom' (L) and 'Disgust' (E) to replicate Model B\n",
        "# Map: W->Angry, A->Anxiety(Fear), F->Happiness, T->Sadness, N->Neutral\n",
        "valid_emotions = {\n",
        "    'W': 'Angry',\n",
        "    'A': 'Fear',\n",
        "    'F': 'Happiness',\n",
        "    'T': 'Sadness',\n",
        "    'N': 'Neutral'\n",
        "}\n",
        "\n",
        "if os.path.exists(emodb_path):\n",
        "    files = os.listdir(emodb_path)\n",
        "    for file in tqdm(files):\n",
        "        try:\n",
        "            # Parse: 03a01Fa.wav\n",
        "            emotion_code = file[5]\n",
        "            speaker_id = file[0:2] # First 2 chars are Speaker ID\n",
        "\n",
        "            # Check if this is one of the 5 allowed classes\n",
        "            if emotion_code in valid_emotions:\n",
        "                label = valid_emotions[emotion_code]\n",
        "                file_path = os.path.join(emodb_path, file)\n",
        "\n",
        "                # Load Audio\n",
        "                data, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "                # 1. Original\n",
        "                X_emo.append(extract_features(data, sr))\n",
        "                y_emo.append(label)\n",
        "                groups_emo.append(speaker_id)\n",
        "\n",
        "                # 2. Augmentations (4 versions)\n",
        "                aug_data_list = augment_audio(data, sr)\n",
        "                for aug_data in aug_data_list:\n",
        "                    X_emo.append(extract_features(aug_data, sr))\n",
        "                    y_emo.append(label)\n",
        "                    groups_emo.append(speaker_id) # IMPORTANT: Augmentations get same Speaker ID\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error EMO-DB {file}: {e}\")\n",
        "\n",
        "    # Save EMO-DB\n",
        "    np.save(f\"{OUTPUT_PATH}EMODB_X.npy\", np.array(X_emo))\n",
        "    np.save(f\"{OUTPUT_PATH}EMODB_y.npy\", np.array(y_emo))\n",
        "    np.save(f\"{OUTPUT_PATH}EMODB_groups.npy\", np.array(groups_emo))\n",
        "    print(f\"EMO-DB Saved: {len(X_emo)} samples (should be 5x original count).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RAVDESS REPLICATION**"
      ],
      "metadata": {
        "id": "J6gOXRRm0Zmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "# --- Configuration (from Issa et al. 2020) ---\n",
        "BATCH_SIZE = 32 # Not specified, 32 is standard\n",
        "LEARNING_RATE = 0.00001 # Specified in paper\n",
        "DECAY = 1e-6 # Specified in paper\n",
        "EPOCHS = 700 # Specified in paper (It's a lot, but required for replication)\n",
        "DATA_PATH = \"/content/drive/MyDrive/DeepLearning/Paper_9_Replication_Features/\"\n",
        "\n",
        "# Set seeds\n",
        "def set_seed(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ==========================================\n",
        "# 1. MODEL ARCHITECTURE (Baseline 1D-CNN)\n",
        "# ==========================================\n",
        "# Based on Section 3.3 and Fig 2 of Issa et al. (2020)\n",
        "def build_baseline_model(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Layer 1: Conv(256) -> BN -> ReLU\n",
        "    x = layers.Conv1D(256, 5, strides=1, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Layer 2: Conv(128) -> ReLU -> Dropout(0.1) -> BN -> MaxPool(8)\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=8)(x)\n",
        "\n",
        "    # Layer 3: Conv(128) -> ReLU\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Layer 4: Conv(128) -> ReLU\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Layer 5: Conv(128) -> BN -> ReLU -> Dropout(0.2)\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Layer 6: Conv(128) -> Flatten -> Dropout(0.2)\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Output: Dense(8) -> BN -> Softmax\n",
        "    x = layers.Dense(num_classes)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.Activation('softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs, name=\"Issa_Baseline_RAVDESS\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# 2. DATA LOADING & EXPERIMENT SWITCH\n",
        "# ==========================================\n",
        "print(\"Loading RAVDESS data...\")\n",
        "X = np.load(os.path.join(DATA_PATH, 'RAVDESS_X.npy'))\n",
        "y = np.load(os.path.join(DATA_PATH, 'RAVDESS_y.npy'))\n",
        "groups = np.load(os.path.join(DATA_PATH, 'RAVDESS_groups.npy'))\n",
        "\n",
        "# Encode Labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "classes = le.classes_\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "# Reshape for 1D CNN: (N, 193) -> (N, 193, 1)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# [THE CONTROL SWITCH]\n",
        "# 'REPLICATION' = Random 80/20 Split (Try to match ~71%)\n",
        "# 'DISPROVE'    = Hold out Actors 21-24 (Test Generalization)\n",
        "EXPERIMENT_MODE = 'REPLICATION'\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "if EXPERIMENT_MODE == 'REPLICATION':\n",
        "    print(f\"\\n>>> MODE: REPLICATION (Random Split) <<<\")\n",
        "    # Paper uses 5-fold cross val, but for quick check we use single 80/20 random split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42, shuffle=True)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42) # Create Val set\n",
        "\n",
        "elif EXPERIMENT_MODE == 'DISPROVE':\n",
        "    print(f\"\\n>>> MODE: DISPROVE (Speaker Strict) <<<\")\n",
        "    # Hold out the last 4 actors (21, 22, 23, 24)\n",
        "    # Note: IDs in groups are strings like '21', '22'\n",
        "    test_actors = ['21', '22', '23', '24']\n",
        "    print(f\"Testing on Actors: {test_actors}\")\n",
        "\n",
        "    test_mask = np.isin(groups, test_actors)\n",
        "\n",
        "    X_test = X[test_mask]\n",
        "    y_test = y_enc[test_mask]\n",
        "\n",
        "    X_train_full = X[~test_mask]\n",
        "    y_train_full = y_enc[~test_mask]\n",
        "\n",
        "    # Create Val set from Train\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING\n",
        "# ==========================================\n",
        "\n",
        "model = build_baseline_model(input_shape=(193, 1), num_classes=len(classes))\n",
        "\n",
        "# Optimizer from paper: RMSProp, lr=0.00001\n",
        "opt = optimizers.RMSprop(learning_rate=LEARNING_RATE) # Decay is deprecated in new Keras, handled by scheduling if needed\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True)\n",
        "\n",
        "print(\"\\nStarting Training...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_val, y_val),\n",
        "\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 4. EVALUATION\n",
        "# ==========================================\n",
        "print(\"\\n--- FINAL EVALUATION ---\")\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Detailed Metrics\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Test F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(f\"Class Order: {classes}\")\n",
        "\n",
        "if EXPERIMENT_MODE == 'REPLICATION':\n",
        "    print(f\"\\nTarget to beat: ~71.61% (Paper Result)\")\n",
        "elif EXPERIMENT_MODE == 'DISPROVE':\n",
        "    print(f\"\\nIf this is significantly lower than 71%, you have successfully disproven the model's generalization.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Abs2Fu0Y8o",
        "outputId": "888219d6-7ec0-411b-f366-da7184f6d88f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading RAVDESS data...\n",
            "Classes: ['angry' 'calm' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "\n",
            ">>> MODE: REPLICATION (Random Split) <<<\n",
            "Train: (1036, 193, 1), Val: (116, 193, 1), Test: (288, 193, 1)\n",
            "\n",
            "Starting Training...\n",
            "Epoch 1/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 160ms/step - accuracy: 0.1267 - loss: 2.5010 - val_accuracy: 0.1552 - val_loss: 2.1403\n",
            "Epoch 2/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1598 - loss: 2.3566 - val_accuracy: 0.2069 - val_loss: 2.1014\n",
            "Epoch 3/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1449 - loss: 2.2884 - val_accuracy: 0.1897 - val_loss: 2.0808\n",
            "Epoch 4/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1919 - loss: 2.2078 - val_accuracy: 0.1983 - val_loss: 2.0497\n",
            "Epoch 5/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2058 - loss: 2.2264 - val_accuracy: 0.1724 - val_loss: 2.0118\n",
            "Epoch 6/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1913 - loss: 2.1683 - val_accuracy: 0.1724 - val_loss: 1.9765\n",
            "Epoch 7/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1596 - loss: 2.1698 - val_accuracy: 0.2069 - val_loss: 1.9570\n",
            "Epoch 8/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2157 - loss: 2.0348 - val_accuracy: 0.2328 - val_loss: 1.9385\n",
            "Epoch 9/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2056 - loss: 2.0650 - val_accuracy: 0.2586 - val_loss: 1.9249\n",
            "Epoch 10/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2032 - loss: 2.0799 - val_accuracy: 0.2500 - val_loss: 1.9065\n",
            "Epoch 11/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2365 - loss: 2.0036 - val_accuracy: 0.3017 - val_loss: 1.8764\n",
            "Epoch 12/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1973 - loss: 2.0385 - val_accuracy: 0.2672 - val_loss: 1.8729\n",
            "Epoch 13/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1976 - loss: 2.0290 - val_accuracy: 0.3017 - val_loss: 1.8467\n",
            "Epoch 14/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2412 - loss: 1.9804 - val_accuracy: 0.3017 - val_loss: 1.8399\n",
            "Epoch 15/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2196 - loss: 2.0110 - val_accuracy: 0.2931 - val_loss: 1.8171\n",
            "Epoch 16/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2376 - loss: 1.9488 - val_accuracy: 0.3017 - val_loss: 1.8039\n",
            "Epoch 17/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2273 - loss: 1.9808 - val_accuracy: 0.3276 - val_loss: 1.7956\n",
            "Epoch 18/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2555 - loss: 1.9414 - val_accuracy: 0.3362 - val_loss: 1.7926\n",
            "Epoch 19/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2533 - loss: 1.9101 - val_accuracy: 0.3103 - val_loss: 1.7876\n",
            "Epoch 20/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2398 - loss: 1.9391 - val_accuracy: 0.3362 - val_loss: 1.7644\n",
            "Epoch 21/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2639 - loss: 1.9033 - val_accuracy: 0.3190 - val_loss: 1.7631\n",
            "Epoch 22/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2876 - loss: 1.8825 - val_accuracy: 0.3103 - val_loss: 1.7528\n",
            "Epoch 23/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2736 - loss: 1.8742 - val_accuracy: 0.3190 - val_loss: 1.7543\n",
            "Epoch 24/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2705 - loss: 1.8637 - val_accuracy: 0.3190 - val_loss: 1.7404\n",
            "Epoch 25/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2909 - loss: 1.8567 - val_accuracy: 0.3362 - val_loss: 1.7311\n",
            "Epoch 26/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2932 - loss: 1.8351 - val_accuracy: 0.3276 - val_loss: 1.7071\n",
            "Epoch 27/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3010 - loss: 1.8401 - val_accuracy: 0.3534 - val_loss: 1.7039\n",
            "Epoch 28/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3121 - loss: 1.8018 - val_accuracy: 0.3103 - val_loss: 1.7121\n",
            "Epoch 29/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3149 - loss: 1.7809 - val_accuracy: 0.2845 - val_loss: 1.7056\n",
            "Epoch 30/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3007 - loss: 1.8150 - val_accuracy: 0.3276 - val_loss: 1.6775\n",
            "Epoch 31/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3124 - loss: 1.7973 - val_accuracy: 0.3534 - val_loss: 1.6778\n",
            "Epoch 32/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3248 - loss: 1.8099 - val_accuracy: 0.3448 - val_loss: 1.6643\n",
            "Epoch 33/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3170 - loss: 1.7662 - val_accuracy: 0.3362 - val_loss: 1.6613\n",
            "Epoch 34/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3503 - loss: 1.7097 - val_accuracy: 0.3621 - val_loss: 1.6499\n",
            "Epoch 35/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3623 - loss: 1.7259 - val_accuracy: 0.3707 - val_loss: 1.6453\n",
            "Epoch 36/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3582 - loss: 1.7462 - val_accuracy: 0.3362 - val_loss: 1.6327\n",
            "Epoch 37/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3894 - loss: 1.6931 - val_accuracy: 0.3362 - val_loss: 1.6293\n",
            "Epoch 38/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3613 - loss: 1.6996 - val_accuracy: 0.3448 - val_loss: 1.6234\n",
            "Epoch 39/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3947 - loss: 1.6537 - val_accuracy: 0.3448 - val_loss: 1.6135\n",
            "Epoch 40/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3622 - loss: 1.6876 - val_accuracy: 0.3362 - val_loss: 1.6052\n",
            "Epoch 41/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3773 - loss: 1.6733 - val_accuracy: 0.3793 - val_loss: 1.6067\n",
            "Epoch 42/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3982 - loss: 1.7021 - val_accuracy: 0.3621 - val_loss: 1.5952\n",
            "Epoch 43/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3632 - loss: 1.6665 - val_accuracy: 0.3621 - val_loss: 1.5956\n",
            "Epoch 44/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3801 - loss: 1.6311 - val_accuracy: 0.3448 - val_loss: 1.5743\n",
            "Epoch 45/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3841 - loss: 1.6249 - val_accuracy: 0.3707 - val_loss: 1.5867\n",
            "Epoch 46/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3858 - loss: 1.6183 - val_accuracy: 0.3707 - val_loss: 1.5793\n",
            "Epoch 47/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4005 - loss: 1.5845 - val_accuracy: 0.3707 - val_loss: 1.5893\n",
            "Epoch 48/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3984 - loss: 1.6094 - val_accuracy: 0.3276 - val_loss: 1.5933\n",
            "Epoch 49/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3884 - loss: 1.6341 - val_accuracy: 0.3448 - val_loss: 1.5632\n",
            "Epoch 50/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4273 - loss: 1.6106 - val_accuracy: 0.3448 - val_loss: 1.5720\n",
            "Epoch 51/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4042 - loss: 1.6280 - val_accuracy: 0.3879 - val_loss: 1.5586\n",
            "Epoch 52/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4222 - loss: 1.5446 - val_accuracy: 0.3448 - val_loss: 1.5471\n",
            "Epoch 53/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4111 - loss: 1.5888 - val_accuracy: 0.3621 - val_loss: 1.5399\n",
            "Epoch 54/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4310 - loss: 1.5431 - val_accuracy: 0.3534 - val_loss: 1.5538\n",
            "Epoch 55/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4300 - loss: 1.5447 - val_accuracy: 0.3362 - val_loss: 1.5572\n",
            "Epoch 56/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4238 - loss: 1.5457 - val_accuracy: 0.3707 - val_loss: 1.5496\n",
            "Epoch 57/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4473 - loss: 1.5408 - val_accuracy: 0.3879 - val_loss: 1.5362\n",
            "Epoch 58/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4229 - loss: 1.5483 - val_accuracy: 0.3793 - val_loss: 1.5211\n",
            "Epoch 59/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4358 - loss: 1.5464 - val_accuracy: 0.3879 - val_loss: 1.5246\n",
            "Epoch 60/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4592 - loss: 1.5194 - val_accuracy: 0.3793 - val_loss: 1.5243\n",
            "Epoch 61/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4639 - loss: 1.5099 - val_accuracy: 0.3966 - val_loss: 1.5191\n",
            "Epoch 62/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4495 - loss: 1.4957 - val_accuracy: 0.3534 - val_loss: 1.5195\n",
            "Epoch 63/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4776 - loss: 1.4789 - val_accuracy: 0.3793 - val_loss: 1.5347\n",
            "Epoch 64/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4741 - loss: 1.4602 - val_accuracy: 0.3707 - val_loss: 1.5023\n",
            "Epoch 65/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5141 - loss: 1.4808 - val_accuracy: 0.3707 - val_loss: 1.5035\n",
            "Epoch 66/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4940 - loss: 1.4490 - val_accuracy: 0.3879 - val_loss: 1.5147\n",
            "Epoch 67/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4560 - loss: 1.4648 - val_accuracy: 0.3793 - val_loss: 1.5153\n",
            "Epoch 68/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4646 - loss: 1.4989 - val_accuracy: 0.3879 - val_loss: 1.5096\n",
            "Epoch 69/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4769 - loss: 1.4663 - val_accuracy: 0.4052 - val_loss: 1.5053\n",
            "Epoch 70/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4750 - loss: 1.4553 - val_accuracy: 0.4052 - val_loss: 1.4830\n",
            "Epoch 71/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4731 - loss: 1.4554 - val_accuracy: 0.3966 - val_loss: 1.4936\n",
            "Epoch 72/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5145 - loss: 1.4624 - val_accuracy: 0.3966 - val_loss: 1.4919\n",
            "Epoch 73/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4803 - loss: 1.4424 - val_accuracy: 0.4224 - val_loss: 1.4743\n",
            "Epoch 74/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5000 - loss: 1.4443 - val_accuracy: 0.3879 - val_loss: 1.4838\n",
            "Epoch 75/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5237 - loss: 1.3974 - val_accuracy: 0.3793 - val_loss: 1.4856\n",
            "Epoch 76/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5049 - loss: 1.4124 - val_accuracy: 0.4138 - val_loss: 1.4836\n",
            "Epoch 77/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5096 - loss: 1.4209 - val_accuracy: 0.4052 - val_loss: 1.4746\n",
            "Epoch 78/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5206 - loss: 1.4035 - val_accuracy: 0.4310 - val_loss: 1.4754\n",
            "Epoch 79/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5377 - loss: 1.3737 - val_accuracy: 0.4569 - val_loss: 1.4596\n",
            "Epoch 80/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5077 - loss: 1.3851 - val_accuracy: 0.4397 - val_loss: 1.4559\n",
            "Epoch 81/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5070 - loss: 1.4266 - val_accuracy: 0.4310 - val_loss: 1.4657\n",
            "Epoch 82/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5463 - loss: 1.3671 - val_accuracy: 0.4569 - val_loss: 1.4490\n",
            "Epoch 83/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5208 - loss: 1.3704 - val_accuracy: 0.4483 - val_loss: 1.4401\n",
            "Epoch 84/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5389 - loss: 1.3890 - val_accuracy: 0.4569 - val_loss: 1.4457\n",
            "Epoch 85/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5414 - loss: 1.3640 - val_accuracy: 0.4483 - val_loss: 1.4653\n",
            "Epoch 86/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5646 - loss: 1.3262 - val_accuracy: 0.4310 - val_loss: 1.4605\n",
            "Epoch 87/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5064 - loss: 1.3792 - val_accuracy: 0.4310 - val_loss: 1.4541\n",
            "Epoch 88/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5247 - loss: 1.3692 - val_accuracy: 0.4569 - val_loss: 1.4302\n",
            "Epoch 89/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5533 - loss: 1.3375 - val_accuracy: 0.4397 - val_loss: 1.4330\n",
            "Epoch 90/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5508 - loss: 1.3463 - val_accuracy: 0.4397 - val_loss: 1.4317\n",
            "Epoch 91/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5566 - loss: 1.3550 - val_accuracy: 0.4741 - val_loss: 1.4274\n",
            "Epoch 92/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5750 - loss: 1.3330 - val_accuracy: 0.4655 - val_loss: 1.4198\n",
            "Epoch 93/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5831 - loss: 1.3066 - val_accuracy: 0.4310 - val_loss: 1.4253\n",
            "Epoch 94/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5856 - loss: 1.3019 - val_accuracy: 0.4483 - val_loss: 1.4397\n",
            "Epoch 95/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5557 - loss: 1.3426 - val_accuracy: 0.4828 - val_loss: 1.4192\n",
            "Epoch 96/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5796 - loss: 1.3182 - val_accuracy: 0.4655 - val_loss: 1.4086\n",
            "Epoch 97/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5803 - loss: 1.3093 - val_accuracy: 0.5000 - val_loss: 1.4048\n",
            "Epoch 98/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5722 - loss: 1.3044 - val_accuracy: 0.5172 - val_loss: 1.4003\n",
            "Epoch 99/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5674 - loss: 1.3119 - val_accuracy: 0.5345 - val_loss: 1.3776\n",
            "Epoch 100/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5998 - loss: 1.2615 - val_accuracy: 0.5172 - val_loss: 1.3910\n",
            "Epoch 101/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5883 - loss: 1.2856 - val_accuracy: 0.5345 - val_loss: 1.4129\n",
            "Epoch 102/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5688 - loss: 1.2936 - val_accuracy: 0.4914 - val_loss: 1.4179\n",
            "Epoch 103/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5763 - loss: 1.2888 - val_accuracy: 0.5172 - val_loss: 1.3886\n",
            "Epoch 104/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5872 - loss: 1.2597 - val_accuracy: 0.5259 - val_loss: 1.3685\n",
            "Epoch 105/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6171 - loss: 1.2562 - val_accuracy: 0.5259 - val_loss: 1.3952\n",
            "Epoch 106/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5962 - loss: 1.2557 - val_accuracy: 0.4828 - val_loss: 1.3863\n",
            "Epoch 107/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5850 - loss: 1.2779 - val_accuracy: 0.5259 - val_loss: 1.3727\n",
            "Epoch 108/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6009 - loss: 1.2587 - val_accuracy: 0.5172 - val_loss: 1.3717\n",
            "Epoch 109/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5930 - loss: 1.2553 - val_accuracy: 0.5086 - val_loss: 1.3800\n",
            "Epoch 110/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5774 - loss: 1.2682 - val_accuracy: 0.4655 - val_loss: 1.3796\n",
            "Epoch 111/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6157 - loss: 1.2415 - val_accuracy: 0.5259 - val_loss: 1.3766\n",
            "Epoch 112/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6056 - loss: 1.2532 - val_accuracy: 0.5086 - val_loss: 1.3730\n",
            "Epoch 113/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6044 - loss: 1.2392 - val_accuracy: 0.5086 - val_loss: 1.3763\n",
            "Epoch 114/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6448 - loss: 1.1985 - val_accuracy: 0.5086 - val_loss: 1.3820\n",
            "Epoch 115/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6347 - loss: 1.2121 - val_accuracy: 0.5259 - val_loss: 1.3658\n",
            "Epoch 116/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6095 - loss: 1.2323 - val_accuracy: 0.5259 - val_loss: 1.3926\n",
            "Epoch 117/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6330 - loss: 1.2046 - val_accuracy: 0.5086 - val_loss: 1.3708\n",
            "Epoch 118/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6264 - loss: 1.2133 - val_accuracy: 0.4828 - val_loss: 1.3700\n",
            "Epoch 119/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6518 - loss: 1.1956 - val_accuracy: 0.5259 - val_loss: 1.3707\n",
            "Epoch 120/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6607 - loss: 1.1846 - val_accuracy: 0.5603 - val_loss: 1.3591\n",
            "Epoch 121/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6627 - loss: 1.1720 - val_accuracy: 0.5000 - val_loss: 1.3863\n",
            "Epoch 122/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6692 - loss: 1.1837 - val_accuracy: 0.5086 - val_loss: 1.3676\n",
            "Epoch 123/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6435 - loss: 1.1964 - val_accuracy: 0.5345 - val_loss: 1.3520\n",
            "Epoch 124/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6518 - loss: 1.1780 - val_accuracy: 0.5172 - val_loss: 1.3557\n",
            "Epoch 125/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6519 - loss: 1.1665 - val_accuracy: 0.5431 - val_loss: 1.3571\n",
            "Epoch 126/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6325 - loss: 1.1846 - val_accuracy: 0.5345 - val_loss: 1.3591\n",
            "Epoch 127/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6404 - loss: 1.1775 - val_accuracy: 0.5172 - val_loss: 1.3462\n",
            "Epoch 128/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6506 - loss: 1.1591 - val_accuracy: 0.5345 - val_loss: 1.3543\n",
            "Epoch 129/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6407 - loss: 1.1831 - val_accuracy: 0.5431 - val_loss: 1.3506\n",
            "Epoch 130/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6797 - loss: 1.1470 - val_accuracy: 0.5259 - val_loss: 1.3752\n",
            "Epoch 131/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6522 - loss: 1.1477 - val_accuracy: 0.5259 - val_loss: 1.3707\n",
            "Epoch 132/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6789 - loss: 1.1379 - val_accuracy: 0.5517 - val_loss: 1.3382\n",
            "Epoch 133/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6702 - loss: 1.1576 - val_accuracy: 0.5431 - val_loss: 1.3484\n",
            "Epoch 134/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6749 - loss: 1.1426 - val_accuracy: 0.5172 - val_loss: 1.3608\n",
            "Epoch 135/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6688 - loss: 1.1531 - val_accuracy: 0.5172 - val_loss: 1.3511\n",
            "Epoch 136/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6857 - loss: 1.1354 - val_accuracy: 0.5345 - val_loss: 1.3514\n",
            "Epoch 137/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6793 - loss: 1.1196 - val_accuracy: 0.5259 - val_loss: 1.3560\n",
            "Epoch 138/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6682 - loss: 1.1463 - val_accuracy: 0.5603 - val_loss: 1.3350\n",
            "Epoch 139/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6948 - loss: 1.1148 - val_accuracy: 0.5172 - val_loss: 1.3409\n",
            "Epoch 140/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6895 - loss: 1.1141 - val_accuracy: 0.5259 - val_loss: 1.3283\n",
            "Epoch 141/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6871 - loss: 1.1267 - val_accuracy: 0.5431 - val_loss: 1.3420\n",
            "Epoch 142/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6885 - loss: 1.1017 - val_accuracy: 0.5086 - val_loss: 1.3536\n",
            "Epoch 143/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6892 - loss: 1.1156 - val_accuracy: 0.5259 - val_loss: 1.3428\n",
            "Epoch 144/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6784 - loss: 1.1082 - val_accuracy: 0.5431 - val_loss: 1.3378\n",
            "Epoch 145/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6967 - loss: 1.0945 - val_accuracy: 0.5603 - val_loss: 1.3412\n",
            "Epoch 146/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6956 - loss: 1.1305 - val_accuracy: 0.5862 - val_loss: 1.3079\n",
            "Epoch 147/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7222 - loss: 1.1086 - val_accuracy: 0.5259 - val_loss: 1.3362\n",
            "Epoch 148/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6783 - loss: 1.0849 - val_accuracy: 0.5345 - val_loss: 1.3359\n",
            "Epoch 149/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6984 - loss: 1.1022 - val_accuracy: 0.5431 - val_loss: 1.3395\n",
            "Epoch 150/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7057 - loss: 1.0917 - val_accuracy: 0.5431 - val_loss: 1.3246\n",
            "Epoch 151/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6953 - loss: 1.0971 - val_accuracy: 0.5603 - val_loss: 1.3238\n",
            "Epoch 152/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7276 - loss: 1.0677 - val_accuracy: 0.5431 - val_loss: 1.3209\n",
            "Epoch 153/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7346 - loss: 1.0694 - val_accuracy: 0.5259 - val_loss: 1.3330\n",
            "Epoch 154/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7159 - loss: 1.0688 - val_accuracy: 0.5431 - val_loss: 1.3392\n",
            "Epoch 155/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7185 - loss: 1.0731 - val_accuracy: 0.5172 - val_loss: 1.3379\n",
            "Epoch 156/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7156 - loss: 1.0682 - val_accuracy: 0.5345 - val_loss: 1.3233\n",
            "Epoch 157/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6876 - loss: 1.0831 - val_accuracy: 0.5603 - val_loss: 1.3159\n",
            "Epoch 158/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6984 - loss: 1.0683 - val_accuracy: 0.5776 - val_loss: 1.3279\n",
            "Epoch 159/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7196 - loss: 1.0653 - val_accuracy: 0.5603 - val_loss: 1.2939\n",
            "Epoch 160/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7208 - loss: 1.0397 - val_accuracy: 0.5517 - val_loss: 1.3122\n",
            "Epoch 161/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7289 - loss: 1.0422 - val_accuracy: 0.5776 - val_loss: 1.3041\n",
            "Epoch 162/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7146 - loss: 1.0562 - val_accuracy: 0.5603 - val_loss: 1.3046\n",
            "Epoch 163/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7284 - loss: 1.0411 - val_accuracy: 0.5517 - val_loss: 1.3242\n",
            "Epoch 164/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7307 - loss: 1.0378 - val_accuracy: 0.5603 - val_loss: 1.3137\n",
            "Epoch 165/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7328 - loss: 1.0427 - val_accuracy: 0.5259 - val_loss: 1.3147\n",
            "Epoch 166/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7435 - loss: 1.0468 - val_accuracy: 0.5603 - val_loss: 1.3076\n",
            "Epoch 167/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7406 - loss: 1.0422 - val_accuracy: 0.5431 - val_loss: 1.3084\n",
            "Epoch 168/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7593 - loss: 1.0250 - val_accuracy: 0.5603 - val_loss: 1.3007\n",
            "Epoch 169/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7279 - loss: 1.0298 - val_accuracy: 0.5862 - val_loss: 1.2956\n",
            "Epoch 170/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7426 - loss: 1.0187 - val_accuracy: 0.5431 - val_loss: 1.3321\n",
            "Epoch 171/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7382 - loss: 1.0187 - val_accuracy: 0.5517 - val_loss: 1.3108\n",
            "Epoch 172/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7336 - loss: 1.0403 - val_accuracy: 0.5690 - val_loss: 1.3053\n",
            "Epoch 173/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7430 - loss: 1.0253 - val_accuracy: 0.5603 - val_loss: 1.3128\n",
            "Epoch 174/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7411 - loss: 1.0221 - val_accuracy: 0.5603 - val_loss: 1.3193\n",
            "Epoch 175/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7395 - loss: 1.0203 - val_accuracy: 0.5690 - val_loss: 1.2921\n",
            "Epoch 176/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7634 - loss: 0.9950 - val_accuracy: 0.5517 - val_loss: 1.2926\n",
            "Epoch 177/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7446 - loss: 1.0259 - val_accuracy: 0.5517 - val_loss: 1.2984\n",
            "Epoch 178/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7522 - loss: 0.9997 - val_accuracy: 0.5431 - val_loss: 1.2795\n",
            "Epoch 179/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7509 - loss: 0.9940 - val_accuracy: 0.5690 - val_loss: 1.2777\n",
            "Epoch 180/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7248 - loss: 1.0087 - val_accuracy: 0.5690 - val_loss: 1.3098\n",
            "Epoch 181/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7481 - loss: 0.9996 - val_accuracy: 0.5431 - val_loss: 1.2948\n",
            "Epoch 182/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7239 - loss: 1.0252 - val_accuracy: 0.5603 - val_loss: 1.3004\n",
            "Epoch 183/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7629 - loss: 0.9793 - val_accuracy: 0.5259 - val_loss: 1.3106\n",
            "Epoch 184/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7777 - loss: 0.9811 - val_accuracy: 0.5948 - val_loss: 1.3092\n",
            "Epoch 185/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7633 - loss: 0.9865 - val_accuracy: 0.5517 - val_loss: 1.2812\n",
            "Epoch 186/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7517 - loss: 1.0023 - val_accuracy: 0.5603 - val_loss: 1.3062\n",
            "Epoch 187/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7527 - loss: 0.9880 - val_accuracy: 0.5690 - val_loss: 1.2981\n",
            "Epoch 188/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7466 - loss: 0.9875 - val_accuracy: 0.5776 - val_loss: 1.3000\n",
            "Epoch 189/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7626 - loss: 0.9812 - val_accuracy: 0.5603 - val_loss: 1.2996\n",
            "Epoch 190/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7843 - loss: 0.9634 - val_accuracy: 0.5690 - val_loss: 1.3012\n",
            "Epoch 191/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7664 - loss: 0.9676 - val_accuracy: 0.5776 - val_loss: 1.2916\n",
            "Epoch 192/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7802 - loss: 0.9827 - val_accuracy: 0.5431 - val_loss: 1.2918\n",
            "Epoch 193/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7746 - loss: 0.9621 - val_accuracy: 0.5776 - val_loss: 1.2912\n",
            "Epoch 194/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7779 - loss: 0.9681 - val_accuracy: 0.5776 - val_loss: 1.2901\n",
            "Epoch 195/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7621 - loss: 0.9751 - val_accuracy: 0.5776 - val_loss: 1.2841\n",
            "Epoch 196/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7775 - loss: 0.9662 - val_accuracy: 0.5776 - val_loss: 1.2795\n",
            "Epoch 197/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7925 - loss: 0.9602 - val_accuracy: 0.5776 - val_loss: 1.2833\n",
            "Epoch 198/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7657 - loss: 0.9658 - val_accuracy: 0.5776 - val_loss: 1.2668\n",
            "Epoch 199/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7771 - loss: 0.9685 - val_accuracy: 0.5517 - val_loss: 1.2867\n",
            "Epoch 200/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.9472 - val_accuracy: 0.5690 - val_loss: 1.2787\n",
            "Epoch 201/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7824 - loss: 0.9599 - val_accuracy: 0.5690 - val_loss: 1.2796\n",
            "Epoch 202/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7876 - loss: 0.9526 - val_accuracy: 0.5776 - val_loss: 1.2755\n",
            "Epoch 203/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7932 - loss: 0.9375 - val_accuracy: 0.5690 - val_loss: 1.2775\n",
            "Epoch 204/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7740 - loss: 0.9570 - val_accuracy: 0.5517 - val_loss: 1.2694\n",
            "Epoch 205/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7663 - loss: 0.9715 - val_accuracy: 0.5690 - val_loss: 1.2883\n",
            "Epoch 206/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7668 - loss: 0.9564 - val_accuracy: 0.5517 - val_loss: 1.2854\n",
            "Epoch 207/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7815 - loss: 0.9416 - val_accuracy: 0.5690 - val_loss: 1.2832\n",
            "Epoch 208/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7964 - loss: 0.9340 - val_accuracy: 0.5517 - val_loss: 1.2642\n",
            "Epoch 209/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7941 - loss: 0.9320 - val_accuracy: 0.5776 - val_loss: 1.2615\n",
            "Epoch 210/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7859 - loss: 0.9429 - val_accuracy: 0.5862 - val_loss: 1.2685\n",
            "Epoch 211/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7933 - loss: 0.9322 - val_accuracy: 0.5776 - val_loss: 1.2530\n",
            "Epoch 212/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7654 - loss: 0.9349 - val_accuracy: 0.5690 - val_loss: 1.2648\n",
            "Epoch 213/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8080 - loss: 0.9071 - val_accuracy: 0.5517 - val_loss: 1.2594\n",
            "Epoch 214/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7986 - loss: 0.9384 - val_accuracy: 0.6034 - val_loss: 1.2535\n",
            "Epoch 215/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8029 - loss: 0.9163 - val_accuracy: 0.5862 - val_loss: 1.2463\n",
            "Epoch 216/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8018 - loss: 0.9166 - val_accuracy: 0.5862 - val_loss: 1.2619\n",
            "Epoch 217/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7985 - loss: 0.9324 - val_accuracy: 0.5776 - val_loss: 1.2618\n",
            "Epoch 218/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8162 - loss: 0.8950 - val_accuracy: 0.5948 - val_loss: 1.2515\n",
            "Epoch 219/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8194 - loss: 0.9073 - val_accuracy: 0.5517 - val_loss: 1.2829\n",
            "Epoch 220/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8127 - loss: 0.8944 - val_accuracy: 0.5690 - val_loss: 1.2765\n",
            "Epoch 221/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8031 - loss: 0.9201 - val_accuracy: 0.6121 - val_loss: 1.2684\n",
            "Epoch 222/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8002 - loss: 0.9111 - val_accuracy: 0.5862 - val_loss: 1.2443\n",
            "Epoch 223/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8229 - loss: 0.8995 - val_accuracy: 0.5517 - val_loss: 1.2569\n",
            "Epoch 224/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7959 - loss: 0.9177 - val_accuracy: 0.5690 - val_loss: 1.2547\n",
            "Epoch 225/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8156 - loss: 0.9080 - val_accuracy: 0.5862 - val_loss: 1.2587\n",
            "Epoch 226/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7976 - loss: 0.9147 - val_accuracy: 0.5948 - val_loss: 1.2488\n",
            "Epoch 227/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8247 - loss: 0.9065 - val_accuracy: 0.5690 - val_loss: 1.2483\n",
            "Epoch 228/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8218 - loss: 0.8909 - val_accuracy: 0.5948 - val_loss: 1.2577\n",
            "Epoch 229/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8107 - loss: 0.8939 - val_accuracy: 0.6034 - val_loss: 1.2667\n",
            "Epoch 230/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8077 - loss: 0.8898 - val_accuracy: 0.5862 - val_loss: 1.2417\n",
            "Epoch 231/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8500 - loss: 0.8638 - val_accuracy: 0.6034 - val_loss: 1.2466\n",
            "Epoch 232/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8205 - loss: 0.9032 - val_accuracy: 0.5776 - val_loss: 1.2395\n",
            "Epoch 233/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8293 - loss: 0.8744 - val_accuracy: 0.5862 - val_loss: 1.2534\n",
            "Epoch 234/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8244 - loss: 0.8735 - val_accuracy: 0.6034 - val_loss: 1.2537\n",
            "Epoch 235/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8315 - loss: 0.8688 - val_accuracy: 0.5948 - val_loss: 1.2483\n",
            "Epoch 236/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8091 - loss: 0.8809 - val_accuracy: 0.5862 - val_loss: 1.2442\n",
            "Epoch 237/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8338 - loss: 0.8766 - val_accuracy: 0.5776 - val_loss: 1.2572\n",
            "Epoch 238/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8248 - loss: 0.8747 - val_accuracy: 0.5690 - val_loss: 1.2537\n",
            "Epoch 239/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8331 - loss: 0.8778 - val_accuracy: 0.5603 - val_loss: 1.2662\n",
            "Epoch 240/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8206 - loss: 0.8704 - val_accuracy: 0.5431 - val_loss: 1.2540\n",
            "Epoch 241/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8204 - loss: 0.8861 - val_accuracy: 0.6034 - val_loss: 1.2406\n",
            "Epoch 242/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8419 - loss: 0.8558 - val_accuracy: 0.5690 - val_loss: 1.2567\n",
            "Epoch 243/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8487 - loss: 0.8584 - val_accuracy: 0.6207 - val_loss: 1.2341\n",
            "Epoch 244/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8307 - loss: 0.8616 - val_accuracy: 0.5776 - val_loss: 1.2402\n",
            "Epoch 245/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8427 - loss: 0.8798 - val_accuracy: 0.5690 - val_loss: 1.2528\n",
            "Epoch 246/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8400 - loss: 0.8536 - val_accuracy: 0.5603 - val_loss: 1.2405\n",
            "Epoch 247/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8351 - loss: 0.8631 - val_accuracy: 0.5776 - val_loss: 1.2351\n",
            "Epoch 248/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8517 - loss: 0.8568 - val_accuracy: 0.5776 - val_loss: 1.2511\n",
            "Epoch 249/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8544 - loss: 0.8513 - val_accuracy: 0.5603 - val_loss: 1.2546\n",
            "Epoch 250/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8417 - loss: 0.8387 - val_accuracy: 0.5862 - val_loss: 1.2325\n",
            "Epoch 251/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8434 - loss: 0.8377 - val_accuracy: 0.5862 - val_loss: 1.2494\n",
            "Epoch 252/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8414 - loss: 0.8319 - val_accuracy: 0.6121 - val_loss: 1.2456\n",
            "Epoch 253/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8600 - loss: 0.8537 - val_accuracy: 0.5948 - val_loss: 1.2212\n",
            "Epoch 254/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8230 - loss: 0.8432 - val_accuracy: 0.5776 - val_loss: 1.2438\n",
            "Epoch 255/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8551 - loss: 0.8383 - val_accuracy: 0.5690 - val_loss: 1.2524\n",
            "Epoch 256/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8293 - loss: 0.8484 - val_accuracy: 0.5776 - val_loss: 1.2370\n",
            "Epoch 257/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8441 - loss: 0.8280 - val_accuracy: 0.6207 - val_loss: 1.2235\n",
            "Epoch 258/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8396 - loss: 0.8384 - val_accuracy: 0.5948 - val_loss: 1.2186\n",
            "Epoch 259/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8439 - loss: 0.8452 - val_accuracy: 0.5776 - val_loss: 1.2468\n",
            "Epoch 260/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8435 - loss: 0.8390 - val_accuracy: 0.5948 - val_loss: 1.2332\n",
            "Epoch 261/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8786 - loss: 0.8119 - val_accuracy: 0.5862 - val_loss: 1.2343\n",
            "Epoch 262/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8600 - loss: 0.8269 - val_accuracy: 0.6207 - val_loss: 1.2454\n",
            "Epoch 263/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8551 - loss: 0.8183 - val_accuracy: 0.6121 - val_loss: 1.2353\n",
            "Epoch 264/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8536 - loss: 0.8244 - val_accuracy: 0.6121 - val_loss: 1.2258\n",
            "Epoch 265/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8485 - loss: 0.8211 - val_accuracy: 0.6121 - val_loss: 1.2095\n",
            "Epoch 266/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8358 - loss: 0.8238 - val_accuracy: 0.5690 - val_loss: 1.2259\n",
            "Epoch 267/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8710 - loss: 0.8106 - val_accuracy: 0.5948 - val_loss: 1.2401\n",
            "Epoch 268/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8518 - loss: 0.8285 - val_accuracy: 0.5776 - val_loss: 1.2402\n",
            "Epoch 269/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8622 - loss: 0.8229 - val_accuracy: 0.5862 - val_loss: 1.2253\n",
            "Epoch 270/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8673 - loss: 0.8164 - val_accuracy: 0.5517 - val_loss: 1.2400\n",
            "Epoch 271/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8541 - loss: 0.8277 - val_accuracy: 0.6207 - val_loss: 1.2169\n",
            "Epoch 272/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8626 - loss: 0.8174 - val_accuracy: 0.6121 - val_loss: 1.2235\n",
            "Epoch 273/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8468 - loss: 0.8264 - val_accuracy: 0.5948 - val_loss: 1.2141\n",
            "Epoch 274/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8672 - loss: 0.8097 - val_accuracy: 0.6207 - val_loss: 1.2063\n",
            "Epoch 275/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8722 - loss: 0.8005 - val_accuracy: 0.5948 - val_loss: 1.2216\n",
            "Epoch 276/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8612 - loss: 0.8016 - val_accuracy: 0.6207 - val_loss: 1.2113\n",
            "Epoch 277/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8663 - loss: 0.7906 - val_accuracy: 0.5948 - val_loss: 1.2202\n",
            "Epoch 278/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8568 - loss: 0.8050 - val_accuracy: 0.6293 - val_loss: 1.2104\n",
            "Epoch 279/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8654 - loss: 0.8043 - val_accuracy: 0.5948 - val_loss: 1.2080\n",
            "Epoch 280/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8734 - loss: 0.8100 - val_accuracy: 0.6034 - val_loss: 1.2150\n",
            "Epoch 281/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8586 - loss: 0.8126 - val_accuracy: 0.6034 - val_loss: 1.2099\n",
            "Epoch 282/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8614 - loss: 0.8091 - val_accuracy: 0.6466 - val_loss: 1.1994\n",
            "Epoch 283/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8661 - loss: 0.7941 - val_accuracy: 0.5862 - val_loss: 1.2328\n",
            "Epoch 284/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8849 - loss: 0.7805 - val_accuracy: 0.6121 - val_loss: 1.2281\n",
            "Epoch 285/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8864 - loss: 0.7843 - val_accuracy: 0.5948 - val_loss: 1.2259\n",
            "Epoch 286/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8928 - loss: 0.7706 - val_accuracy: 0.5948 - val_loss: 1.2019\n",
            "Epoch 287/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8654 - loss: 0.7950 - val_accuracy: 0.5948 - val_loss: 1.2093\n",
            "Epoch 288/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8716 - loss: 0.7897 - val_accuracy: 0.6293 - val_loss: 1.2175\n",
            "Epoch 289/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8688 - loss: 0.7919 - val_accuracy: 0.5948 - val_loss: 1.2200\n",
            "Epoch 290/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8748 - loss: 0.7979 - val_accuracy: 0.6207 - val_loss: 1.2155\n",
            "Epoch 291/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8792 - loss: 0.7722 - val_accuracy: 0.6034 - val_loss: 1.2161\n",
            "Epoch 292/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8871 - loss: 0.7884 - val_accuracy: 0.6034 - val_loss: 1.2228\n",
            "Epoch 293/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8613 - loss: 0.8016 - val_accuracy: 0.6034 - val_loss: 1.1898\n",
            "Epoch 294/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8760 - loss: 0.7749 - val_accuracy: 0.6034 - val_loss: 1.1900\n",
            "Epoch 295/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8882 - loss: 0.7720 - val_accuracy: 0.6207 - val_loss: 1.2025\n",
            "Epoch 296/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8839 - loss: 0.7767 - val_accuracy: 0.6724 - val_loss: 1.1978\n",
            "Epoch 297/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8737 - loss: 0.7866 - val_accuracy: 0.5862 - val_loss: 1.2194\n",
            "Epoch 298/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8905 - loss: 0.7657 - val_accuracy: 0.6207 - val_loss: 1.2040\n",
            "Epoch 299/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.7557 - val_accuracy: 0.5603 - val_loss: 1.2000\n",
            "Epoch 300/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8769 - loss: 0.7831 - val_accuracy: 0.6293 - val_loss: 1.2022\n",
            "Epoch 301/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8942 - loss: 0.7716 - val_accuracy: 0.6293 - val_loss: 1.1920\n",
            "Epoch 302/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8765 - loss: 0.7831 - val_accuracy: 0.6121 - val_loss: 1.2172\n",
            "Epoch 303/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8899 - loss: 0.7612 - val_accuracy: 0.6034 - val_loss: 1.2067\n",
            "Epoch 304/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8972 - loss: 0.7575 - val_accuracy: 0.6034 - val_loss: 1.2093\n",
            "Epoch 305/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8854 - loss: 0.7593 - val_accuracy: 0.6293 - val_loss: 1.1968\n",
            "Epoch 306/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8814 - loss: 0.7571 - val_accuracy: 0.6207 - val_loss: 1.1995\n",
            "Epoch 307/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8934 - loss: 0.7648 - val_accuracy: 0.6121 - val_loss: 1.1957\n",
            "Epoch 308/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9080 - loss: 0.7486 - val_accuracy: 0.5862 - val_loss: 1.1931\n",
            "Epoch 309/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8705 - loss: 0.7629 - val_accuracy: 0.6552 - val_loss: 1.1904\n",
            "Epoch 310/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8884 - loss: 0.7638 - val_accuracy: 0.6121 - val_loss: 1.2098\n",
            "Epoch 311/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8844 - loss: 0.7527 - val_accuracy: 0.6034 - val_loss: 1.2041\n",
            "Epoch 312/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8972 - loss: 0.7567 - val_accuracy: 0.6293 - val_loss: 1.1944\n",
            "Epoch 313/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9008 - loss: 0.7508 - val_accuracy: 0.6552 - val_loss: 1.1999\n",
            "Epoch 314/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9024 - loss: 0.7541 - val_accuracy: 0.5603 - val_loss: 1.1913\n",
            "Epoch 315/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8864 - loss: 0.7470 - val_accuracy: 0.6121 - val_loss: 1.1969\n",
            "Epoch 316/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8860 - loss: 0.7607 - val_accuracy: 0.6293 - val_loss: 1.1835\n",
            "Epoch 317/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9046 - loss: 0.7347 - val_accuracy: 0.6293 - val_loss: 1.2058\n",
            "Epoch 318/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9041 - loss: 0.7446 - val_accuracy: 0.6379 - val_loss: 1.1721\n",
            "Epoch 319/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8920 - loss: 0.7334 - val_accuracy: 0.6207 - val_loss: 1.2026\n",
            "Epoch 320/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8889 - loss: 0.7483 - val_accuracy: 0.5776 - val_loss: 1.1842\n",
            "Epoch 321/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9120 - loss: 0.7360 - val_accuracy: 0.6207 - val_loss: 1.1953\n",
            "Epoch 322/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9223 - loss: 0.7254 - val_accuracy: 0.5776 - val_loss: 1.2015\n",
            "Epoch 323/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9128 - loss: 0.7356 - val_accuracy: 0.6293 - val_loss: 1.1942\n",
            "Epoch 324/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9053 - loss: 0.7280 - val_accuracy: 0.5948 - val_loss: 1.2008\n",
            "Epoch 325/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9066 - loss: 0.7255 - val_accuracy: 0.6034 - val_loss: 1.1966\n",
            "Epoch 326/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8990 - loss: 0.7295 - val_accuracy: 0.6207 - val_loss: 1.1992\n",
            "Epoch 327/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9212 - loss: 0.7069 - val_accuracy: 0.6552 - val_loss: 1.1825\n",
            "Epoch 328/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9263 - loss: 0.7120 - val_accuracy: 0.6207 - val_loss: 1.1873\n",
            "Epoch 329/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9045 - loss: 0.7324 - val_accuracy: 0.6034 - val_loss: 1.1963\n",
            "Epoch 330/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8881 - loss: 0.7328 - val_accuracy: 0.6293 - val_loss: 1.1827\n",
            "Epoch 331/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9003 - loss: 0.7300 - val_accuracy: 0.6552 - val_loss: 1.1617\n",
            "Epoch 332/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9064 - loss: 0.7178 - val_accuracy: 0.6293 - val_loss: 1.1870\n",
            "Epoch 333/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9067 - loss: 0.7218 - val_accuracy: 0.6379 - val_loss: 1.2069\n",
            "Epoch 334/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9038 - loss: 0.7189 - val_accuracy: 0.5948 - val_loss: 1.1958\n",
            "Epoch 335/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9216 - loss: 0.7066 - val_accuracy: 0.6293 - val_loss: 1.1938\n",
            "Epoch 336/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9188 - loss: 0.7156 - val_accuracy: 0.6466 - val_loss: 1.1847\n",
            "Epoch 337/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9235 - loss: 0.7066 - val_accuracy: 0.6034 - val_loss: 1.2024\n",
            "Epoch 338/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9110 - loss: 0.7243 - val_accuracy: 0.6034 - val_loss: 1.1913\n",
            "Epoch 339/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9102 - loss: 0.7199 - val_accuracy: 0.6207 - val_loss: 1.1856\n",
            "Epoch 340/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9043 - loss: 0.7138 - val_accuracy: 0.6121 - val_loss: 1.1803\n",
            "Epoch 341/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9148 - loss: 0.7067 - val_accuracy: 0.5862 - val_loss: 1.1655\n",
            "Epoch 342/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9168 - loss: 0.7008 - val_accuracy: 0.5862 - val_loss: 1.1800\n",
            "Epoch 343/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.6934 - val_accuracy: 0.6121 - val_loss: 1.1819\n",
            "Epoch 344/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9033 - loss: 0.7243 - val_accuracy: 0.6207 - val_loss: 1.1793\n",
            "Epoch 345/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9181 - loss: 0.6996 - val_accuracy: 0.6034 - val_loss: 1.1881\n",
            "Epoch 346/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9259 - loss: 0.6935 - val_accuracy: 0.6379 - val_loss: 1.1666\n",
            "Epoch 347/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9163 - loss: 0.7130 - val_accuracy: 0.6379 - val_loss: 1.1757\n",
            "Epoch 348/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9062 - loss: 0.7093 - val_accuracy: 0.6121 - val_loss: 1.1750\n",
            "Epoch 349/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9288 - loss: 0.6902 - val_accuracy: 0.6034 - val_loss: 1.1848\n",
            "Epoch 350/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9335 - loss: 0.6983 - val_accuracy: 0.6379 - val_loss: 1.1848\n",
            "Epoch 351/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.6965 - val_accuracy: 0.6207 - val_loss: 1.1825\n",
            "Epoch 352/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9207 - loss: 0.6966 - val_accuracy: 0.6034 - val_loss: 1.1967\n",
            "Epoch 353/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8932 - loss: 0.7152 - val_accuracy: 0.6121 - val_loss: 1.1832\n",
            "Epoch 354/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9201 - loss: 0.6840 - val_accuracy: 0.6379 - val_loss: 1.1829\n",
            "Epoch 355/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9248 - loss: 0.6755 - val_accuracy: 0.6207 - val_loss: 1.1765\n",
            "Epoch 356/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9097 - loss: 0.7018 - val_accuracy: 0.5776 - val_loss: 1.1778\n",
            "Epoch 357/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9159 - loss: 0.6886 - val_accuracy: 0.6379 - val_loss: 1.1613\n",
            "Epoch 358/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9273 - loss: 0.6900 - val_accuracy: 0.6552 - val_loss: 1.1636\n",
            "Epoch 359/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9388 - loss: 0.6919 - val_accuracy: 0.6121 - val_loss: 1.1717\n",
            "Epoch 360/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9234 - loss: 0.6906 - val_accuracy: 0.6034 - val_loss: 1.1734\n",
            "Epoch 361/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9181 - loss: 0.6875 - val_accuracy: 0.5862 - val_loss: 1.1599\n",
            "Epoch 362/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9282 - loss: 0.6654 - val_accuracy: 0.6207 - val_loss: 1.1620\n",
            "Epoch 363/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9329 - loss: 0.6830 - val_accuracy: 0.5776 - val_loss: 1.1811\n",
            "Epoch 364/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9356 - loss: 0.6607 - val_accuracy: 0.5948 - val_loss: 1.1752\n",
            "Epoch 365/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9391 - loss: 0.6748 - val_accuracy: 0.6293 - val_loss: 1.1631\n",
            "Epoch 366/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9169 - loss: 0.6840 - val_accuracy: 0.6207 - val_loss: 1.1670\n",
            "Epoch 367/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9245 - loss: 0.6870 - val_accuracy: 0.5948 - val_loss: 1.1753\n",
            "Epoch 368/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9380 - loss: 0.6727 - val_accuracy: 0.6207 - val_loss: 1.1551\n",
            "Epoch 369/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9200 - loss: 0.6827 - val_accuracy: 0.6293 - val_loss: 1.1667\n",
            "Epoch 370/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9178 - loss: 0.6781 - val_accuracy: 0.6207 - val_loss: 1.1739\n",
            "Epoch 371/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9331 - loss: 0.6652 - val_accuracy: 0.6207 - val_loss: 1.1701\n",
            "Epoch 372/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9321 - loss: 0.6716 - val_accuracy: 0.6379 - val_loss: 1.1757\n",
            "Epoch 373/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9302 - loss: 0.6782 - val_accuracy: 0.6121 - val_loss: 1.1484\n",
            "Epoch 374/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9404 - loss: 0.6673 - val_accuracy: 0.6293 - val_loss: 1.1592\n",
            "Epoch 375/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9215 - loss: 0.6591 - val_accuracy: 0.6121 - val_loss: 1.1576\n",
            "Epoch 376/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9478 - loss: 0.6520 - val_accuracy: 0.5862 - val_loss: 1.1692\n",
            "Epoch 377/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9202 - loss: 0.6573 - val_accuracy: 0.6379 - val_loss: 1.1760\n",
            "Epoch 378/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9515 - loss: 0.6543 - val_accuracy: 0.6466 - val_loss: 1.1561\n",
            "Epoch 379/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9186 - loss: 0.6584 - val_accuracy: 0.6034 - val_loss: 1.1756\n",
            "Epoch 380/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9401 - loss: 0.6514 - val_accuracy: 0.5948 - val_loss: 1.1611\n",
            "Epoch 381/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9351 - loss: 0.6581 - val_accuracy: 0.6034 - val_loss: 1.1694\n",
            "Epoch 382/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9112 - loss: 0.6671 - val_accuracy: 0.6207 - val_loss: 1.1935\n",
            "Epoch 383/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9271 - loss: 0.6663 - val_accuracy: 0.6034 - val_loss: 1.1704\n",
            "Epoch 384/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9283 - loss: 0.6531 - val_accuracy: 0.6293 - val_loss: 1.1591\n",
            "Epoch 385/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.6411 - val_accuracy: 0.5862 - val_loss: 1.1700\n",
            "Epoch 386/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9414 - loss: 0.6502 - val_accuracy: 0.5690 - val_loss: 1.1552\n",
            "Epoch 387/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9495 - loss: 0.6380 - val_accuracy: 0.6379 - val_loss: 1.1587\n",
            "Epoch 388/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9392 - loss: 0.6502 - val_accuracy: 0.6379 - val_loss: 1.1472\n",
            "Epoch 389/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9472 - loss: 0.6427 - val_accuracy: 0.6121 - val_loss: 1.1626\n",
            "Epoch 390/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9414 - loss: 0.6513 - val_accuracy: 0.6293 - val_loss: 1.1311\n",
            "Epoch 391/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9433 - loss: 0.6474 - val_accuracy: 0.6293 - val_loss: 1.1408\n",
            "Epoch 392/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9353 - loss: 0.6460 - val_accuracy: 0.6466 - val_loss: 1.1472\n",
            "Epoch 393/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9330 - loss: 0.6412 - val_accuracy: 0.6466 - val_loss: 1.1680\n",
            "Epoch 394/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9408 - loss: 0.6452 - val_accuracy: 0.6466 - val_loss: 1.1512\n",
            "Epoch 395/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9209 - loss: 0.6642 - val_accuracy: 0.6293 - val_loss: 1.1368\n",
            "Epoch 396/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9440 - loss: 0.6428 - val_accuracy: 0.6207 - val_loss: 1.1426\n",
            "Epoch 397/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9449 - loss: 0.6352 - val_accuracy: 0.5948 - val_loss: 1.1443\n",
            "Epoch 398/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9274 - loss: 0.6531 - val_accuracy: 0.6293 - val_loss: 1.1581\n",
            "Epoch 399/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9344 - loss: 0.6414 - val_accuracy: 0.6293 - val_loss: 1.1552\n",
            "Epoch 400/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9248 - loss: 0.6368 - val_accuracy: 0.5776 - val_loss: 1.1503\n",
            "Epoch 401/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9463 - loss: 0.6396 - val_accuracy: 0.6379 - val_loss: 1.1513\n",
            "Epoch 402/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9306 - loss: 0.6334 - val_accuracy: 0.5948 - val_loss: 1.1778\n",
            "Epoch 403/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.6292 - val_accuracy: 0.6293 - val_loss: 1.1519\n",
            "Epoch 404/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9364 - loss: 0.6344 - val_accuracy: 0.6379 - val_loss: 1.1503\n",
            "Epoch 405/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9508 - loss: 0.6336 - val_accuracy: 0.6379 - val_loss: 1.1455\n",
            "Epoch 406/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9581 - loss: 0.6339 - val_accuracy: 0.6034 - val_loss: 1.1499\n",
            "Epoch 407/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.6290 - val_accuracy: 0.5862 - val_loss: 1.1680\n",
            "Epoch 408/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9442 - loss: 0.6207 - val_accuracy: 0.6121 - val_loss: 1.1621\n",
            "Epoch 409/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.6329 - val_accuracy: 0.6207 - val_loss: 1.1216\n",
            "Epoch 410/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.6309 - val_accuracy: 0.6293 - val_loss: 1.1548\n",
            "Epoch 411/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9492 - loss: 0.6250 - val_accuracy: 0.6121 - val_loss: 1.1625\n",
            "Epoch 412/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9502 - loss: 0.6176 - val_accuracy: 0.6121 - val_loss: 1.1482\n",
            "Epoch 413/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9395 - loss: 0.6414 - val_accuracy: 0.5948 - val_loss: 1.1408\n",
            "Epoch 414/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9496 - loss: 0.6162 - val_accuracy: 0.6293 - val_loss: 1.1436\n",
            "Epoch 415/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9537 - loss: 0.6052 - val_accuracy: 0.6293 - val_loss: 1.1291\n",
            "Epoch 416/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9585 - loss: 0.6076 - val_accuracy: 0.6207 - val_loss: 1.1267\n",
            "Epoch 417/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9373 - loss: 0.6267 - val_accuracy: 0.6034 - val_loss: 1.1417\n",
            "Epoch 418/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9610 - loss: 0.6185 - val_accuracy: 0.5948 - val_loss: 1.1597\n",
            "Epoch 419/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9462 - loss: 0.6142 - val_accuracy: 0.6466 - val_loss: 1.1235\n",
            "Epoch 420/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.6201 - val_accuracy: 0.6121 - val_loss: 1.1352\n",
            "Epoch 421/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9510 - loss: 0.6169 - val_accuracy: 0.6379 - val_loss: 1.1312\n",
            "Epoch 422/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9466 - loss: 0.6171 - val_accuracy: 0.6121 - val_loss: 1.1423\n",
            "Epoch 423/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9470 - loss: 0.6247 - val_accuracy: 0.6724 - val_loss: 1.1233\n",
            "Epoch 424/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9608 - loss: 0.6128 - val_accuracy: 0.6207 - val_loss: 1.1412\n",
            "Epoch 425/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9533 - loss: 0.6202 - val_accuracy: 0.6293 - val_loss: 1.1222\n",
            "Epoch 426/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9652 - loss: 0.5955 - val_accuracy: 0.6293 - val_loss: 1.1359\n",
            "Epoch 427/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9605 - loss: 0.6014 - val_accuracy: 0.6121 - val_loss: 1.1328\n",
            "Epoch 428/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9595 - loss: 0.6015 - val_accuracy: 0.6293 - val_loss: 1.1226\n",
            "Epoch 429/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9381 - loss: 0.6172 - val_accuracy: 0.6293 - val_loss: 1.1456\n",
            "Epoch 430/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.6086 - val_accuracy: 0.5948 - val_loss: 1.1406\n",
            "Epoch 431/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9610 - loss: 0.5934 - val_accuracy: 0.6121 - val_loss: 1.1220\n",
            "Epoch 432/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9457 - loss: 0.6187 - val_accuracy: 0.6293 - val_loss: 1.1388\n",
            "Epoch 433/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9573 - loss: 0.6014 - val_accuracy: 0.6207 - val_loss: 1.1554\n",
            "Epoch 434/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9527 - loss: 0.5871 - val_accuracy: 0.5948 - val_loss: 1.1537\n",
            "Epoch 435/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9656 - loss: 0.5827 - val_accuracy: 0.6034 - val_loss: 1.1435\n",
            "Epoch 436/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.6075 - val_accuracy: 0.6466 - val_loss: 1.1255\n",
            "Epoch 437/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9542 - loss: 0.5958 - val_accuracy: 0.6034 - val_loss: 1.1498\n",
            "Epoch 438/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9487 - loss: 0.5962 - val_accuracy: 0.5948 - val_loss: 1.1514\n",
            "Epoch 439/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9568 - loss: 0.6119 - val_accuracy: 0.6293 - val_loss: 1.1175\n",
            "Epoch 440/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.5999 - val_accuracy: 0.6034 - val_loss: 1.1603\n",
            "Epoch 441/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9604 - loss: 0.5951 - val_accuracy: 0.6293 - val_loss: 1.1312\n",
            "Epoch 442/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9665 - loss: 0.6017 - val_accuracy: 0.6379 - val_loss: 1.1379\n",
            "Epoch 443/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9604 - loss: 0.5963 - val_accuracy: 0.6466 - val_loss: 1.1279\n",
            "Epoch 444/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9526 - loss: 0.5924 - val_accuracy: 0.5948 - val_loss: 1.1513\n",
            "Epoch 445/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9631 - loss: 0.5906 - val_accuracy: 0.6034 - val_loss: 1.1291\n",
            "Epoch 446/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9675 - loss: 0.5881 - val_accuracy: 0.6034 - val_loss: 1.1286\n",
            "Epoch 447/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.5839 - val_accuracy: 0.6552 - val_loss: 1.1311\n",
            "Epoch 448/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9630 - loss: 0.5929 - val_accuracy: 0.6466 - val_loss: 1.1217\n",
            "Epoch 449/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9587 - loss: 0.5969 - val_accuracy: 0.6121 - val_loss: 1.1228\n",
            "Epoch 450/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9525 - loss: 0.5908 - val_accuracy: 0.6379 - val_loss: 1.1172\n",
            "Epoch 451/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9634 - loss: 0.5880 - val_accuracy: 0.6207 - val_loss: 1.1258\n",
            "Epoch 452/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9568 - loss: 0.5893 - val_accuracy: 0.6293 - val_loss: 1.1431\n",
            "Epoch 453/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9685 - loss: 0.5893 - val_accuracy: 0.6379 - val_loss: 1.1376\n",
            "Epoch 454/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9592 - loss: 0.5859 - val_accuracy: 0.6034 - val_loss: 1.1391\n",
            "Epoch 455/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.5804 - val_accuracy: 0.6121 - val_loss: 1.1303\n",
            "Epoch 456/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9609 - loss: 0.5864 - val_accuracy: 0.6379 - val_loss: 1.1256\n",
            "Epoch 457/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9692 - loss: 0.5770 - val_accuracy: 0.6466 - val_loss: 1.1262\n",
            "Epoch 458/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9550 - loss: 0.5976 - val_accuracy: 0.6466 - val_loss: 1.1203\n",
            "Epoch 459/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9559 - loss: 0.5730 - val_accuracy: 0.6379 - val_loss: 1.1290\n",
            "Epoch 460/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9648 - loss: 0.5753 - val_accuracy: 0.6466 - val_loss: 1.1084\n",
            "Epoch 461/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9632 - loss: 0.5704 - val_accuracy: 0.6034 - val_loss: 1.1237\n",
            "Epoch 462/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.5650 - val_accuracy: 0.6552 - val_loss: 1.1197\n",
            "Epoch 463/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9533 - loss: 0.5876 - val_accuracy: 0.6379 - val_loss: 1.1304\n",
            "Epoch 464/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9581 - loss: 0.5755 - val_accuracy: 0.6121 - val_loss: 1.1484\n",
            "Epoch 465/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9668 - loss: 0.5763 - val_accuracy: 0.6034 - val_loss: 1.1188\n",
            "Epoch 466/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9598 - loss: 0.5717 - val_accuracy: 0.5776 - val_loss: 1.1320\n",
            "Epoch 467/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9628 - loss: 0.5650 - val_accuracy: 0.5603 - val_loss: 1.1340\n",
            "Epoch 468/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9654 - loss: 0.5730 - val_accuracy: 0.5948 - val_loss: 1.1111\n",
            "Epoch 469/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9447 - loss: 0.5885 - val_accuracy: 0.6207 - val_loss: 1.1298\n",
            "Epoch 470/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9578 - loss: 0.5769 - val_accuracy: 0.6121 - val_loss: 1.1331\n",
            "Epoch 471/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9567 - loss: 0.5790 - val_accuracy: 0.6121 - val_loss: 1.1125\n",
            "Epoch 472/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9613 - loss: 0.5651 - val_accuracy: 0.6379 - val_loss: 1.1050\n",
            "Epoch 473/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9645 - loss: 0.5678 - val_accuracy: 0.6121 - val_loss: 1.1406\n",
            "Epoch 474/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9627 - loss: 0.5722 - val_accuracy: 0.6293 - val_loss: 1.1177\n",
            "Epoch 475/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.5648 - val_accuracy: 0.6379 - val_loss: 1.1125\n",
            "Epoch 476/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9614 - loss: 0.5795 - val_accuracy: 0.6121 - val_loss: 1.1387\n",
            "Epoch 477/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9620 - loss: 0.5660 - val_accuracy: 0.5690 - val_loss: 1.1387\n",
            "Epoch 478/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9652 - loss: 0.5644 - val_accuracy: 0.5862 - val_loss: 1.1418\n",
            "Epoch 479/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.5646 - val_accuracy: 0.6293 - val_loss: 1.1301\n",
            "Epoch 480/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9514 - loss: 0.5661 - val_accuracy: 0.6207 - val_loss: 1.1308\n",
            "Epoch 481/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.5677 - val_accuracy: 0.6466 - val_loss: 1.1188\n",
            "Epoch 482/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9621 - loss: 0.5798 - val_accuracy: 0.5862 - val_loss: 1.1391\n",
            "Epoch 483/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9757 - loss: 0.5689 - val_accuracy: 0.6466 - val_loss: 1.1110\n",
            "Epoch 484/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9779 - loss: 0.5517 - val_accuracy: 0.6207 - val_loss: 1.1187\n",
            "Epoch 485/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9655 - loss: 0.5720 - val_accuracy: 0.6034 - val_loss: 1.1362\n",
            "Epoch 486/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9559 - loss: 0.5700 - val_accuracy: 0.6466 - val_loss: 1.1308\n",
            "Epoch 487/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9485 - loss: 0.5678 - val_accuracy: 0.5862 - val_loss: 1.1454\n",
            "Epoch 488/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9677 - loss: 0.5594 - val_accuracy: 0.6207 - val_loss: 1.1345\n",
            "Epoch 489/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9617 - loss: 0.5661 - val_accuracy: 0.6293 - val_loss: 1.1440\n",
            "Epoch 490/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.5558 - val_accuracy: 0.5948 - val_loss: 1.1244\n",
            "Epoch 491/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9486 - loss: 0.5724 - val_accuracy: 0.6552 - val_loss: 1.1151\n",
            "Epoch 492/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9665 - loss: 0.5477 - val_accuracy: 0.6293 - val_loss: 1.1257\n",
            "Epoch 493/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9724 - loss: 0.5492 - val_accuracy: 0.6121 - val_loss: 1.1320\n",
            "Epoch 494/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.5483 - val_accuracy: 0.6207 - val_loss: 1.1221\n",
            "Epoch 495/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9679 - loss: 0.5502 - val_accuracy: 0.6207 - val_loss: 1.1271\n",
            "Epoch 496/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9621 - loss: 0.5630 - val_accuracy: 0.6034 - val_loss: 1.1073\n",
            "Epoch 497/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9769 - loss: 0.5507 - val_accuracy: 0.6293 - val_loss: 1.1403\n",
            "Epoch 498/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9714 - loss: 0.5437 - val_accuracy: 0.6121 - val_loss: 1.1378\n",
            "Epoch 499/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9621 - loss: 0.5489 - val_accuracy: 0.6466 - val_loss: 1.1177\n",
            "Epoch 500/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9711 - loss: 0.5403 - val_accuracy: 0.6379 - val_loss: 1.1149\n",
            "Epoch 501/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9663 - loss: 0.5532 - val_accuracy: 0.6466 - val_loss: 1.0901\n",
            "Epoch 502/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9662 - loss: 0.5466 - val_accuracy: 0.6121 - val_loss: 1.1200\n",
            "Epoch 503/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9675 - loss: 0.5522 - val_accuracy: 0.6207 - val_loss: 1.1202\n",
            "Epoch 504/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9699 - loss: 0.5380 - val_accuracy: 0.5948 - val_loss: 1.1236\n",
            "Epoch 505/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9616 - loss: 0.5567 - val_accuracy: 0.6121 - val_loss: 1.1062\n",
            "Epoch 506/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9732 - loss: 0.5377 - val_accuracy: 0.5948 - val_loss: 1.1091\n",
            "Epoch 507/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.5392 - val_accuracy: 0.6121 - val_loss: 1.1312\n",
            "Epoch 508/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9643 - loss: 0.5540 - val_accuracy: 0.6724 - val_loss: 1.0951\n",
            "Epoch 509/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9719 - loss: 0.5277 - val_accuracy: 0.6379 - val_loss: 1.1043\n",
            "Epoch 510/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.5464 - val_accuracy: 0.5948 - val_loss: 1.1137\n",
            "Epoch 511/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9694 - loss: 0.5491 - val_accuracy: 0.6121 - val_loss: 1.1110\n",
            "Epoch 512/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.5336 - val_accuracy: 0.6121 - val_loss: 1.1137\n",
            "Epoch 513/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.5396 - val_accuracy: 0.6034 - val_loss: 1.1121\n",
            "Epoch 514/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9661 - loss: 0.5381 - val_accuracy: 0.6466 - val_loss: 1.1176\n",
            "Epoch 515/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9742 - loss: 0.5413 - val_accuracy: 0.6121 - val_loss: 1.1170\n",
            "Epoch 516/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9708 - loss: 0.5313 - val_accuracy: 0.6207 - val_loss: 1.1054\n",
            "Epoch 517/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9766 - loss: 0.5536 - val_accuracy: 0.6034 - val_loss: 1.1050\n",
            "Epoch 518/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9814 - loss: 0.5387 - val_accuracy: 0.6724 - val_loss: 1.0939\n",
            "Epoch 519/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.5396 - val_accuracy: 0.6207 - val_loss: 1.0923\n",
            "Epoch 520/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9814 - loss: 0.5346 - val_accuracy: 0.5862 - val_loss: 1.1098\n",
            "Epoch 521/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.5446 - val_accuracy: 0.6207 - val_loss: 1.1172\n",
            "Epoch 522/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9602 - loss: 0.5339 - val_accuracy: 0.5862 - val_loss: 1.1271\n",
            "Epoch 523/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9788 - loss: 0.5359 - val_accuracy: 0.5690 - val_loss: 1.1342\n",
            "Epoch 524/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9845 - loss: 0.5246 - val_accuracy: 0.6034 - val_loss: 1.1291\n",
            "Epoch 525/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9771 - loss: 0.5296 - val_accuracy: 0.6466 - val_loss: 1.1133\n",
            "Epoch 526/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9708 - loss: 0.5373 - val_accuracy: 0.6207 - val_loss: 1.1173\n",
            "Epoch 527/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.5230 - val_accuracy: 0.6207 - val_loss: 1.1023\n",
            "Epoch 528/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9570 - loss: 0.5369 - val_accuracy: 0.6379 - val_loss: 1.0959\n",
            "Epoch 529/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9775 - loss: 0.5245 - val_accuracy: 0.6207 - val_loss: 1.1228\n",
            "Epoch 530/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9780 - loss: 0.5275 - val_accuracy: 0.5948 - val_loss: 1.1211\n",
            "Epoch 531/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.5259 - val_accuracy: 0.6034 - val_loss: 1.1352\n",
            "Epoch 532/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.5226 - val_accuracy: 0.6121 - val_loss: 1.1131\n",
            "Epoch 533/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9662 - loss: 0.5297 - val_accuracy: 0.6121 - val_loss: 1.1168\n",
            "Epoch 534/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9768 - loss: 0.5303 - val_accuracy: 0.6638 - val_loss: 1.1091\n",
            "Epoch 535/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9834 - loss: 0.5187 - val_accuracy: 0.6552 - val_loss: 1.1023\n",
            "Epoch 536/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.5169 - val_accuracy: 0.6207 - val_loss: 1.1056\n",
            "Epoch 537/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.5179 - val_accuracy: 0.6552 - val_loss: 1.1021\n",
            "Epoch 538/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9745 - loss: 0.5278 - val_accuracy: 0.6034 - val_loss: 1.1177\n",
            "Epoch 539/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9699 - loss: 0.5251 - val_accuracy: 0.5776 - val_loss: 1.1002\n",
            "Epoch 540/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9820 - loss: 0.5149 - val_accuracy: 0.6466 - val_loss: 1.1097\n",
            "Epoch 541/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9692 - loss: 0.5183 - val_accuracy: 0.6466 - val_loss: 1.1116\n",
            "Epoch 542/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9763 - loss: 0.5128 - val_accuracy: 0.6121 - val_loss: 1.1108\n",
            "Epoch 543/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9815 - loss: 0.5141 - val_accuracy: 0.6207 - val_loss: 1.1067\n",
            "Epoch 544/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9771 - loss: 0.5147 - val_accuracy: 0.6638 - val_loss: 1.1026\n",
            "Epoch 545/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9804 - loss: 0.5188 - val_accuracy: 0.5776 - val_loss: 1.1173\n",
            "Epoch 546/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9749 - loss: 0.5152 - val_accuracy: 0.6121 - val_loss: 1.0953\n",
            "Epoch 547/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.5099 - val_accuracy: 0.6466 - val_loss: 1.1106\n",
            "Epoch 548/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.5047 - val_accuracy: 0.6293 - val_loss: 1.1047\n",
            "Epoch 549/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.5192 - val_accuracy: 0.6121 - val_loss: 1.1074\n",
            "Epoch 550/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9672 - loss: 0.5137 - val_accuracy: 0.6379 - val_loss: 1.1016\n",
            "Epoch 551/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9794 - loss: 0.5095 - val_accuracy: 0.6379 - val_loss: 1.0909\n",
            "Epoch 552/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.5094 - val_accuracy: 0.6207 - val_loss: 1.0873\n",
            "Epoch 553/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.5129 - val_accuracy: 0.6466 - val_loss: 1.0917\n",
            "Epoch 554/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.5112 - val_accuracy: 0.6207 - val_loss: 1.0990\n",
            "Epoch 555/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9789 - loss: 0.5170 - val_accuracy: 0.5948 - val_loss: 1.1156\n",
            "Epoch 556/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.5127 - val_accuracy: 0.6207 - val_loss: 1.0986\n",
            "Epoch 557/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 0.5157 - val_accuracy: 0.6207 - val_loss: 1.1116\n",
            "Epoch 558/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.5062 - val_accuracy: 0.6293 - val_loss: 1.0778\n",
            "Epoch 559/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.4992 - val_accuracy: 0.6379 - val_loss: 1.0843\n",
            "Epoch 560/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9760 - loss: 0.5087 - val_accuracy: 0.6293 - val_loss: 1.0870\n",
            "Epoch 561/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.5182 - val_accuracy: 0.6638 - val_loss: 1.1007\n",
            "Epoch 562/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9700 - loss: 0.5040 - val_accuracy: 0.6466 - val_loss: 1.0939\n",
            "Epoch 563/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9695 - loss: 0.5176 - val_accuracy: 0.6638 - val_loss: 1.0980\n",
            "Epoch 564/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.5092 - val_accuracy: 0.6121 - val_loss: 1.1141\n",
            "Epoch 565/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9821 - loss: 0.5129 - val_accuracy: 0.6552 - val_loss: 1.1007\n",
            "Epoch 566/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.4970 - val_accuracy: 0.6293 - val_loss: 1.1076\n",
            "Epoch 567/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9797 - loss: 0.5050 - val_accuracy: 0.6034 - val_loss: 1.1037\n",
            "Epoch 568/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9818 - loss: 0.4980 - val_accuracy: 0.6207 - val_loss: 1.1159\n",
            "Epoch 569/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9784 - loss: 0.5033 - val_accuracy: 0.6724 - val_loss: 1.0983\n",
            "Epoch 570/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.5110 - val_accuracy: 0.6638 - val_loss: 1.0879\n",
            "Epoch 571/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9778 - loss: 0.5017 - val_accuracy: 0.6638 - val_loss: 1.0892\n",
            "Epoch 572/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9826 - loss: 0.5022 - val_accuracy: 0.6552 - val_loss: 1.1047\n",
            "Epoch 573/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9818 - loss: 0.5110 - val_accuracy: 0.6293 - val_loss: 1.1045\n",
            "Epoch 574/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.5004 - val_accuracy: 0.6466 - val_loss: 1.0974\n",
            "Epoch 575/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.4963 - val_accuracy: 0.6293 - val_loss: 1.0932\n",
            "Epoch 576/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.4899 - val_accuracy: 0.6724 - val_loss: 1.0930\n",
            "Epoch 577/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9725 - loss: 0.4968 - val_accuracy: 0.6466 - val_loss: 1.0726\n",
            "Epoch 578/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.4898 - val_accuracy: 0.6207 - val_loss: 1.1043\n",
            "Epoch 579/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.4992 - val_accuracy: 0.6207 - val_loss: 1.1025\n",
            "Epoch 580/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9753 - loss: 0.5013 - val_accuracy: 0.6293 - val_loss: 1.0833\n",
            "Epoch 581/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9768 - loss: 0.5000 - val_accuracy: 0.6897 - val_loss: 1.0911\n",
            "Epoch 582/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9811 - loss: 0.4987 - val_accuracy: 0.5862 - val_loss: 1.1064\n",
            "Epoch 583/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9725 - loss: 0.5032 - val_accuracy: 0.6638 - val_loss: 1.0868\n",
            "Epoch 584/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9868 - loss: 0.4966 - val_accuracy: 0.6034 - val_loss: 1.1122\n",
            "Epoch 585/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.4935 - val_accuracy: 0.6638 - val_loss: 1.0878\n",
            "Epoch 586/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.4833 - val_accuracy: 0.6379 - val_loss: 1.1082\n",
            "Epoch 587/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.4945 - val_accuracy: 0.6293 - val_loss: 1.1273\n",
            "Epoch 588/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9855 - loss: 0.4865 - val_accuracy: 0.6379 - val_loss: 1.1148\n",
            "Epoch 589/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.4880 - val_accuracy: 0.6466 - val_loss: 1.1043\n",
            "Epoch 590/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.4860 - val_accuracy: 0.6034 - val_loss: 1.1120\n",
            "Epoch 591/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9793 - loss: 0.4849 - val_accuracy: 0.6552 - val_loss: 1.0945\n",
            "Epoch 592/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9804 - loss: 0.4864 - val_accuracy: 0.6552 - val_loss: 1.0997\n",
            "Epoch 593/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.4859 - val_accuracy: 0.6724 - val_loss: 1.0931\n",
            "Epoch 594/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9758 - loss: 0.4867 - val_accuracy: 0.6466 - val_loss: 1.0959\n",
            "Epoch 595/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.4912 - val_accuracy: 0.6207 - val_loss: 1.1002\n",
            "Epoch 596/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.4791 - val_accuracy: 0.6724 - val_loss: 1.0904\n",
            "Epoch 597/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9858 - loss: 0.4815 - val_accuracy: 0.6207 - val_loss: 1.1069\n",
            "Epoch 598/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.4816 - val_accuracy: 0.6379 - val_loss: 1.0922\n",
            "Epoch 599/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.4975 - val_accuracy: 0.6724 - val_loss: 1.0768\n",
            "Epoch 600/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9832 - loss: 0.4824 - val_accuracy: 0.6293 - val_loss: 1.0821\n",
            "Epoch 601/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.4883 - val_accuracy: 0.6552 - val_loss: 1.0758\n",
            "Epoch 602/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9887 - loss: 0.4811 - val_accuracy: 0.6034 - val_loss: 1.0795\n",
            "Epoch 603/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.4763 - val_accuracy: 0.6207 - val_loss: 1.1009\n",
            "Epoch 604/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9794 - loss: 0.4806 - val_accuracy: 0.6379 - val_loss: 1.1044\n",
            "Epoch 605/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.4813 - val_accuracy: 0.6379 - val_loss: 1.0863\n",
            "Epoch 606/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9766 - loss: 0.4930 - val_accuracy: 0.6466 - val_loss: 1.0921\n",
            "Epoch 607/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9834 - loss: 0.4734 - val_accuracy: 0.6293 - val_loss: 1.0952\n",
            "Epoch 608/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.4756 - val_accuracy: 0.6638 - val_loss: 1.0947\n",
            "Epoch 609/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9856 - loss: 0.4790 - val_accuracy: 0.6207 - val_loss: 1.0952\n",
            "Epoch 610/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9850 - loss: 0.4861 - val_accuracy: 0.6207 - val_loss: 1.0895\n",
            "Epoch 611/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9798 - loss: 0.4775 - val_accuracy: 0.6293 - val_loss: 1.1100\n",
            "Epoch 612/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.4763 - val_accuracy: 0.6293 - val_loss: 1.0998\n",
            "Epoch 613/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9765 - loss: 0.4929 - val_accuracy: 0.6466 - val_loss: 1.0958\n",
            "Epoch 614/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9847 - loss: 0.4726 - val_accuracy: 0.6379 - val_loss: 1.1012\n",
            "Epoch 615/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.4757 - val_accuracy: 0.6724 - val_loss: 1.0874\n",
            "Epoch 616/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.4716 - val_accuracy: 0.6810 - val_loss: 1.1059\n",
            "Epoch 617/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9866 - loss: 0.4705 - val_accuracy: 0.6810 - val_loss: 1.1089\n",
            "Epoch 618/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9804 - loss: 0.4667 - val_accuracy: 0.6379 - val_loss: 1.0952\n",
            "Epoch 619/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9759 - loss: 0.4798 - val_accuracy: 0.6724 - val_loss: 1.0800\n",
            "Epoch 620/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.4790 - val_accuracy: 0.6724 - val_loss: 1.0908\n",
            "Epoch 621/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.4627 - val_accuracy: 0.6897 - val_loss: 1.0771\n",
            "Epoch 622/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.4636 - val_accuracy: 0.6897 - val_loss: 1.0809\n",
            "Epoch 623/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9825 - loss: 0.4702 - val_accuracy: 0.6724 - val_loss: 1.0940\n",
            "Epoch 624/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.4586 - val_accuracy: 0.6293 - val_loss: 1.1098\n",
            "Epoch 625/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.4685 - val_accuracy: 0.6379 - val_loss: 1.0896\n",
            "Epoch 626/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.4688 - val_accuracy: 0.6293 - val_loss: 1.1060\n",
            "Epoch 627/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9932 - loss: 0.4653 - val_accuracy: 0.6552 - val_loss: 1.0946\n",
            "Epoch 628/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9925 - loss: 0.4610 - val_accuracy: 0.6293 - val_loss: 1.1001\n",
            "Epoch 629/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.4712 - val_accuracy: 0.6379 - val_loss: 1.0979\n",
            "Epoch 630/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.4631 - val_accuracy: 0.6552 - val_loss: 1.0979\n",
            "Epoch 631/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.4664 - val_accuracy: 0.6552 - val_loss: 1.0894\n",
            "Epoch 632/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.4692 - val_accuracy: 0.6121 - val_loss: 1.0880\n",
            "Epoch 633/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.4608 - val_accuracy: 0.6552 - val_loss: 1.0891\n",
            "Epoch 634/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 0.4722 - val_accuracy: 0.6379 - val_loss: 1.0944\n",
            "Epoch 635/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9848 - loss: 0.4617 - val_accuracy: 0.6724 - val_loss: 1.1036\n",
            "Epoch 636/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.4525 - val_accuracy: 0.6207 - val_loss: 1.0820\n",
            "Epoch 637/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.4574 - val_accuracy: 0.6724 - val_loss: 1.0943\n",
            "Epoch 638/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.4606 - val_accuracy: 0.6379 - val_loss: 1.1123\n",
            "Epoch 639/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.4581 - val_accuracy: 0.6293 - val_loss: 1.0900\n",
            "Epoch 640/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.4634 - val_accuracy: 0.6552 - val_loss: 1.0824\n",
            "Epoch 641/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.4554 - val_accuracy: 0.6379 - val_loss: 1.0943\n",
            "Epoch 642/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9817 - loss: 0.4594 - val_accuracy: 0.6293 - val_loss: 1.0875\n",
            "Epoch 643/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.4664 - val_accuracy: 0.6638 - val_loss: 1.0812\n",
            "Epoch 644/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.4591 - val_accuracy: 0.6552 - val_loss: 1.0827\n",
            "Epoch 645/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.4738 - val_accuracy: 0.6466 - val_loss: 1.0881\n",
            "Epoch 646/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.4581 - val_accuracy: 0.6897 - val_loss: 1.0825\n",
            "Epoch 647/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9862 - loss: 0.4629 - val_accuracy: 0.6552 - val_loss: 1.0999\n",
            "Epoch 648/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.4546 - val_accuracy: 0.6638 - val_loss: 1.0808\n",
            "Epoch 649/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.4596 - val_accuracy: 0.6638 - val_loss: 1.0870\n",
            "Epoch 650/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9796 - loss: 0.4623 - val_accuracy: 0.6638 - val_loss: 1.0664\n",
            "Epoch 651/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.4585 - val_accuracy: 0.6293 - val_loss: 1.0785\n",
            "Epoch 652/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9866 - loss: 0.4520 - val_accuracy: 0.6379 - val_loss: 1.0869\n",
            "Epoch 653/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.4533 - val_accuracy: 0.6379 - val_loss: 1.0994\n",
            "Epoch 654/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.4426 - val_accuracy: 0.6379 - val_loss: 1.1074\n",
            "Epoch 655/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.4648 - val_accuracy: 0.5776 - val_loss: 1.1187\n",
            "Epoch 656/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.4568 - val_accuracy: 0.6466 - val_loss: 1.0965\n",
            "Epoch 657/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.4541 - val_accuracy: 0.6207 - val_loss: 1.0984\n",
            "Epoch 658/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.4590 - val_accuracy: 0.6466 - val_loss: 1.1067\n",
            "Epoch 659/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.4417 - val_accuracy: 0.6379 - val_loss: 1.0874\n",
            "Epoch 660/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.4537 - val_accuracy: 0.6121 - val_loss: 1.0932\n",
            "Epoch 661/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9779 - loss: 0.4571 - val_accuracy: 0.6379 - val_loss: 1.0759\n",
            "Epoch 662/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.4612 - val_accuracy: 0.6724 - val_loss: 1.0753\n",
            "Epoch 663/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9959 - loss: 0.4439 - val_accuracy: 0.6810 - val_loss: 1.0825\n",
            "Epoch 664/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.4658 - val_accuracy: 0.6724 - val_loss: 1.0847\n",
            "Epoch 665/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.4504 - val_accuracy: 0.6552 - val_loss: 1.0705\n",
            "Epoch 666/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9785 - loss: 0.4613 - val_accuracy: 0.6293 - val_loss: 1.0747\n",
            "Epoch 667/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.4518 - val_accuracy: 0.6552 - val_loss: 1.0686\n",
            "Epoch 668/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9944 - loss: 0.4468 - val_accuracy: 0.6121 - val_loss: 1.1063\n",
            "Epoch 669/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9868 - loss: 0.4471 - val_accuracy: 0.6810 - val_loss: 1.0831\n",
            "Epoch 670/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.4475 - val_accuracy: 0.6638 - val_loss: 1.0940\n",
            "Epoch 671/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9901 - loss: 0.4484 - val_accuracy: 0.6379 - val_loss: 1.0623\n",
            "Epoch 672/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.4492 - val_accuracy: 0.6638 - val_loss: 1.0669\n",
            "Epoch 673/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.4379 - val_accuracy: 0.6466 - val_loss: 1.0789\n",
            "Epoch 674/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.4492 - val_accuracy: 0.6897 - val_loss: 1.0724\n",
            "Epoch 675/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.4436 - val_accuracy: 0.6552 - val_loss: 1.0626\n",
            "Epoch 676/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.4420 - val_accuracy: 0.6638 - val_loss: 1.0630\n",
            "Epoch 677/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.4329 - val_accuracy: 0.6810 - val_loss: 1.0858\n",
            "Epoch 678/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.4458 - val_accuracy: 0.6724 - val_loss: 1.0725\n",
            "Epoch 679/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.4432 - val_accuracy: 0.6466 - val_loss: 1.0901\n",
            "Epoch 680/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9826 - loss: 0.4471 - val_accuracy: 0.6379 - val_loss: 1.0880\n",
            "Epoch 681/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9866 - loss: 0.4459 - val_accuracy: 0.6207 - val_loss: 1.0832\n",
            "Epoch 682/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.4372 - val_accuracy: 0.6810 - val_loss: 1.0560\n",
            "Epoch 683/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.4483 - val_accuracy: 0.6638 - val_loss: 1.0891\n",
            "Epoch 684/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.4444 - val_accuracy: 0.6724 - val_loss: 1.0821\n",
            "Epoch 685/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.4426 - val_accuracy: 0.6638 - val_loss: 1.0670\n",
            "Epoch 686/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9862 - loss: 0.4372 - val_accuracy: 0.6466 - val_loss: 1.0806\n",
            "Epoch 687/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.4373 - val_accuracy: 0.6466 - val_loss: 1.0895\n",
            "Epoch 688/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.4400 - val_accuracy: 0.6293 - val_loss: 1.0858\n",
            "Epoch 689/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9832 - loss: 0.4384 - val_accuracy: 0.6724 - val_loss: 1.0691\n",
            "Epoch 690/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.4382 - val_accuracy: 0.6552 - val_loss: 1.0814\n",
            "Epoch 691/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.4367 - val_accuracy: 0.6466 - val_loss: 1.0907\n",
            "Epoch 692/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.4357 - val_accuracy: 0.6293 - val_loss: 1.0894\n",
            "Epoch 693/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.4380 - val_accuracy: 0.6638 - val_loss: 1.0822\n",
            "Epoch 694/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.4349 - val_accuracy: 0.6552 - val_loss: 1.0760\n",
            "Epoch 695/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.4330 - val_accuracy: 0.6121 - val_loss: 1.0883\n",
            "Epoch 696/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.4433 - val_accuracy: 0.6638 - val_loss: 1.0828\n",
            "Epoch 697/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.4228 - val_accuracy: 0.6810 - val_loss: 1.0849\n",
            "Epoch 698/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.4244 - val_accuracy: 0.6810 - val_loss: 1.0730\n",
            "Epoch 699/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.4368 - val_accuracy: 0.6466 - val_loss: 1.0759\n",
            "Epoch 700/700\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.4359 - val_accuracy: 0.6466 - val_loss: 1.0853\n",
            "\n",
            "--- FINAL EVALUATION ---\n",
            "Test Accuracy: 66.67%\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step  \n",
            "Test F1-Score: 0.6603\n",
            "\n",
            "Confusion Matrix:\n",
            "[[30  0  3  0  1  0  0  1]\n",
            " [ 1 35  2  0  1  2  0  0]\n",
            " [ 2  0 20  2  1  1  1  5]\n",
            " [ 2  0  2 29  0  2  7  4]\n",
            " [ 3  1  1  2 19  1  2 11]\n",
            " [ 0  5  0  2  0  7  2  3]\n",
            " [ 0  6  5  1  1  2 19  3]\n",
            " [ 0  0  1  2  0  0  2 33]]\n",
            "Class Order: ['angry' 'calm' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "\n",
            "Target to beat: ~71.61% (Paper Result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "# --- Configuration (from Issa et al. 2020) ---\n",
        "BATCH_SIZE = 32 # Not specified, 32 is standard\n",
        "LEARNING_RATE = 0.00001 # Specified in paper\n",
        "DECAY = 1e-6 # Specified in paper\n",
        "EPOCHS = 700 # Specified in paper (It's a lot, but required for replication)\n",
        "DATA_PATH = \"/content/drive/MyDrive/DeepLearning/Paper_9_Replication_Features/\"\n",
        "\n",
        "# Set seeds\n",
        "def set_seed(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ==========================================\n",
        "# 1. MODEL ARCHITECTURE (Baseline 1D-CNN)\n",
        "# ==========================================\n",
        "# Based on Section 3.3 and Fig 2 of Issa et al. (2020)\n",
        "def build_baseline_model(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Layer 1: Conv(256) -> BN -> ReLU\n",
        "    x = layers.Conv1D(256, 5, strides=1, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Layer 2: Conv(128) -> ReLU -> Dropout(0.1) -> BN -> MaxPool(8)\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=8)(x)\n",
        "\n",
        "    # Layer 3: Conv(128) -> ReLU\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Layer 4: Conv(128) -> ReLU\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Layer 5: Conv(128) -> BN -> ReLU -> Dropout(0.2)\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Layer 6: Conv(128) -> Flatten -> Dropout(0.2)\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Output: Dense(8) -> BN -> Softmax\n",
        "    x = layers.Dense(num_classes)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.Activation('softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs, name=\"Issa_Baseline_RAVDESS\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# 2. DATA LOADING & EXPERIMENT SWITCH\n",
        "# ==========================================\n",
        "print(\"Loading RAVDESS data...\")\n",
        "X = np.load(os.path.join(DATA_PATH, 'RAVDESS_X.npy'))\n",
        "y = np.load(os.path.join(DATA_PATH, 'RAVDESS_y.npy'))\n",
        "groups = np.load(os.path.join(DATA_PATH, 'RAVDESS_groups.npy'))\n",
        "\n",
        "# Encode Labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "classes = le.classes_\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "# Reshape for 1D CNN: (N, 193) -> (N, 193, 1)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# [THE CONTROL SWITCH]\n",
        "# 'REPLICATION' = Random 80/20 Split (Try to match ~71%)\n",
        "# 'DISPROVE'    = Hold out Actors 21-24 (Test Generalization)\n",
        "EXPERIMENT_MODE = 'DISPROVE'\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "if EXPERIMENT_MODE == 'REPLICATION':\n",
        "    print(f\"\\n>>> MODE: REPLICATION (Random Split) <<<\")\n",
        "    # Paper uses 5-fold cross val, but for quick check we use single 80/20 random split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42, shuffle=True)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42) # Create Val set\n",
        "\n",
        "elif EXPERIMENT_MODE == 'DISPROVE':\n",
        "    print(f\"\\n>>> MODE: DISPROVE (Speaker Strict) <<<\")\n",
        "    # Hold out the last 4 actors (21, 22, 23, 24)\n",
        "    # Note: IDs in groups are strings like '21', '22'\n",
        "    test_actors = ['21', '22', '23', '24']\n",
        "    print(f\"Testing on Actors: {test_actors}\")\n",
        "\n",
        "    test_mask = np.isin(groups, test_actors)\n",
        "\n",
        "    X_test = X[test_mask]\n",
        "    y_test = y_enc[test_mask]\n",
        "\n",
        "    X_train_full = X[~test_mask]\n",
        "    y_train_full = y_enc[~test_mask]\n",
        "\n",
        "    # Create Val set from Train\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING\n",
        "# ==========================================\n",
        "\n",
        "model = build_baseline_model(input_shape=(193, 1), num_classes=len(classes))\n",
        "\n",
        "# Optimizer from paper: RMSProp, lr=0.00001\n",
        "opt = optimizers.RMSprop(learning_rate=LEARNING_RATE) # Decay is deprecated in new Keras, handled by scheduling if needed\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True)\n",
        "\n",
        "print(\"\\nStarting Training...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_val, y_val),\n",
        "\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 4. EVALUATION\n",
        "# ==========================================\n",
        "print(\"\\n--- FINAL EVALUATION ---\")\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Detailed Metrics\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Test F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(f\"Class Order: {classes}\")\n",
        "\n",
        "if EXPERIMENT_MODE == 'REPLICATION':\n",
        "    print(f\"\\nTarget to beat: ~71.61% (Paper Result)\")\n",
        "elif EXPERIMENT_MODE == 'DISPROVE':\n",
        "    print(f\"\\nIf this is significantly lower than 71%, you have successfully disproven the model's generalization.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmCKLdhZ2mjT",
        "outputId": "d4daed2d-3451-4f8e-b67d-56171998762b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading RAVDESS data...\n",
            "Classes: ['angry' 'calm' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "\n",
            ">>> MODE: DISPROVE (Speaker Strict) <<<\n",
            "Testing on Actors: ['21', '22', '23', '24']\n",
            "Train: (1080, 193, 1), Val: (120, 193, 1), Test: (240, 193, 1)\n",
            "\n",
            "Starting Training...\n",
            "Epoch 1/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 214ms/step - accuracy: 0.1293 - loss: 2.5307 - val_accuracy: 0.1667 - val_loss: 2.1266\n",
            "Epoch 2/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1462 - loss: 2.3651 - val_accuracy: 0.1667 - val_loss: 2.1113\n",
            "Epoch 3/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1814 - loss: 2.2076 - val_accuracy: 0.1583 - val_loss: 2.0824\n",
            "Epoch 4/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2003 - loss: 2.1517 - val_accuracy: 0.1833 - val_loss: 2.0525\n",
            "Epoch 5/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1933 - loss: 2.1176 - val_accuracy: 0.2000 - val_loss: 2.0176\n",
            "Epoch 6/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1945 - loss: 2.0925 - val_accuracy: 0.2333 - val_loss: 1.9940\n",
            "Epoch 7/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2124 - loss: 2.0528 - val_accuracy: 0.2583 - val_loss: 1.9730\n",
            "Epoch 8/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2140 - loss: 2.0558 - val_accuracy: 0.2583 - val_loss: 1.9342\n",
            "Epoch 9/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2087 - loss: 2.0669 - val_accuracy: 0.3167 - val_loss: 1.9094\n",
            "Epoch 10/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2387 - loss: 2.0262 - val_accuracy: 0.3000 - val_loss: 1.8956\n",
            "Epoch 11/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2396 - loss: 1.9794 - val_accuracy: 0.2917 - val_loss: 1.8831\n",
            "Epoch 12/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2258 - loss: 1.9743 - val_accuracy: 0.3167 - val_loss: 1.8670\n",
            "Epoch 13/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2463 - loss: 1.9338 - val_accuracy: 0.3333 - val_loss: 1.8539\n",
            "Epoch 14/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2552 - loss: 1.9022 - val_accuracy: 0.3250 - val_loss: 1.8389\n",
            "Epoch 15/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2433 - loss: 1.9376 - val_accuracy: 0.3417 - val_loss: 1.8208\n",
            "Epoch 16/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2542 - loss: 1.9150 - val_accuracy: 0.3500 - val_loss: 1.8072\n",
            "Epoch 17/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2667 - loss: 1.9073 - val_accuracy: 0.3250 - val_loss: 1.7908\n",
            "Epoch 18/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2576 - loss: 1.8873 - val_accuracy: 0.3500 - val_loss: 1.7896\n",
            "Epoch 19/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2718 - loss: 1.8722 - val_accuracy: 0.3250 - val_loss: 1.7693\n",
            "Epoch 20/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2799 - loss: 1.8526 - val_accuracy: 0.3333 - val_loss: 1.7660\n",
            "Epoch 21/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2781 - loss: 1.8486 - val_accuracy: 0.3417 - val_loss: 1.7494\n",
            "Epoch 22/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2531 - loss: 1.8882 - val_accuracy: 0.3417 - val_loss: 1.7270\n",
            "Epoch 23/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3127 - loss: 1.7909 - val_accuracy: 0.4000 - val_loss: 1.7139\n",
            "Epoch 24/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2949 - loss: 1.8264 - val_accuracy: 0.3833 - val_loss: 1.7094\n",
            "Epoch 25/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2891 - loss: 1.8093 - val_accuracy: 0.3750 - val_loss: 1.6982\n",
            "Epoch 26/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3196 - loss: 1.7943 - val_accuracy: 0.3750 - val_loss: 1.6997\n",
            "Epoch 27/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3127 - loss: 1.7797 - val_accuracy: 0.3750 - val_loss: 1.6976\n",
            "Epoch 28/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3200 - loss: 1.7683 - val_accuracy: 0.3833 - val_loss: 1.6718\n",
            "Epoch 29/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3095 - loss: 1.7570 - val_accuracy: 0.3833 - val_loss: 1.6797\n",
            "Epoch 30/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3556 - loss: 1.7283 - val_accuracy: 0.4000 - val_loss: 1.6664\n",
            "Epoch 31/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3216 - loss: 1.7393 - val_accuracy: 0.4000 - val_loss: 1.6607\n",
            "Epoch 32/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3271 - loss: 1.7009 - val_accuracy: 0.4000 - val_loss: 1.6549\n",
            "Epoch 33/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3408 - loss: 1.7155 - val_accuracy: 0.3917 - val_loss: 1.6628\n",
            "Epoch 34/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3351 - loss: 1.6971 - val_accuracy: 0.4083 - val_loss: 1.6352\n",
            "Epoch 35/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3439 - loss: 1.6953 - val_accuracy: 0.4000 - val_loss: 1.6325\n",
            "Epoch 36/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3527 - loss: 1.6779 - val_accuracy: 0.4083 - val_loss: 1.6317\n",
            "Epoch 37/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3750 - loss: 1.6651 - val_accuracy: 0.4333 - val_loss: 1.6189\n",
            "Epoch 38/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3599 - loss: 1.6666 - val_accuracy: 0.4333 - val_loss: 1.6228\n",
            "Epoch 39/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3783 - loss: 1.6474 - val_accuracy: 0.4583 - val_loss: 1.6103\n",
            "Epoch 40/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3475 - loss: 1.6696 - val_accuracy: 0.4500 - val_loss: 1.6070\n",
            "Epoch 41/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3746 - loss: 1.6259 - val_accuracy: 0.4417 - val_loss: 1.5992\n",
            "Epoch 42/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3909 - loss: 1.6040 - val_accuracy: 0.4500 - val_loss: 1.5975\n",
            "Epoch 43/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3570 - loss: 1.6357 - val_accuracy: 0.4417 - val_loss: 1.5770\n",
            "Epoch 44/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4192 - loss: 1.5917 - val_accuracy: 0.4333 - val_loss: 1.5905\n",
            "Epoch 45/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3921 - loss: 1.6029 - val_accuracy: 0.4417 - val_loss: 1.6016\n",
            "Epoch 46/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3839 - loss: 1.5739 - val_accuracy: 0.4250 - val_loss: 1.5787\n",
            "Epoch 47/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4207 - loss: 1.5827 - val_accuracy: 0.4500 - val_loss: 1.5780\n",
            "Epoch 48/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4020 - loss: 1.5818 - val_accuracy: 0.5083 - val_loss: 1.5549\n",
            "Epoch 49/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4200 - loss: 1.5890 - val_accuracy: 0.4250 - val_loss: 1.5705\n",
            "Epoch 50/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3835 - loss: 1.5925 - val_accuracy: 0.4417 - val_loss: 1.5720\n",
            "Epoch 51/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3886 - loss: 1.5471 - val_accuracy: 0.4833 - val_loss: 1.5567\n",
            "Epoch 52/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4296 - loss: 1.5384 - val_accuracy: 0.4750 - val_loss: 1.5460\n",
            "Epoch 53/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4191 - loss: 1.5470 - val_accuracy: 0.4500 - val_loss: 1.5529\n",
            "Epoch 54/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4168 - loss: 1.5427 - val_accuracy: 0.4667 - val_loss: 1.5439\n",
            "Epoch 55/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4249 - loss: 1.5275 - val_accuracy: 0.4417 - val_loss: 1.5452\n",
            "Epoch 56/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4266 - loss: 1.4901 - val_accuracy: 0.4250 - val_loss: 1.5654\n",
            "Epoch 57/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4390 - loss: 1.5112 - val_accuracy: 0.4833 - val_loss: 1.5410\n",
            "Epoch 58/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4376 - loss: 1.5122 - val_accuracy: 0.4417 - val_loss: 1.5383\n",
            "Epoch 59/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4505 - loss: 1.5065 - val_accuracy: 0.4750 - val_loss: 1.5245\n",
            "Epoch 60/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4443 - loss: 1.5058 - val_accuracy: 0.5083 - val_loss: 1.5291\n",
            "Epoch 61/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4521 - loss: 1.4728 - val_accuracy: 0.4833 - val_loss: 1.5298\n",
            "Epoch 62/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4519 - loss: 1.4563 - val_accuracy: 0.5000 - val_loss: 1.5111\n",
            "Epoch 63/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4789 - loss: 1.4564 - val_accuracy: 0.5000 - val_loss: 1.5057\n",
            "Epoch 64/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4391 - loss: 1.5025 - val_accuracy: 0.5167 - val_loss: 1.5068\n",
            "Epoch 65/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4411 - loss: 1.4701 - val_accuracy: 0.4833 - val_loss: 1.5161\n",
            "Epoch 66/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4883 - loss: 1.4575 - val_accuracy: 0.5250 - val_loss: 1.5088\n",
            "Epoch 67/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4841 - loss: 1.4483 - val_accuracy: 0.5083 - val_loss: 1.4960\n",
            "Epoch 68/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4860 - loss: 1.4175 - val_accuracy: 0.5083 - val_loss: 1.5041\n",
            "Epoch 69/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4791 - loss: 1.4251 - val_accuracy: 0.5333 - val_loss: 1.4972\n",
            "Epoch 70/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4888 - loss: 1.4093 - val_accuracy: 0.5083 - val_loss: 1.4853\n",
            "Epoch 71/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4854 - loss: 1.4358 - val_accuracy: 0.5167 - val_loss: 1.5021\n",
            "Epoch 72/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4924 - loss: 1.4174 - val_accuracy: 0.4750 - val_loss: 1.5128\n",
            "Epoch 73/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5011 - loss: 1.4237 - val_accuracy: 0.5083 - val_loss: 1.4806\n",
            "Epoch 74/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4922 - loss: 1.3971 - val_accuracy: 0.5500 - val_loss: 1.4811\n",
            "Epoch 75/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5194 - loss: 1.3856 - val_accuracy: 0.5417 - val_loss: 1.4529\n",
            "Epoch 76/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5230 - loss: 1.3893 - val_accuracy: 0.5667 - val_loss: 1.4614\n",
            "Epoch 77/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5145 - loss: 1.3912 - val_accuracy: 0.5583 - val_loss: 1.4530\n",
            "Epoch 78/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5178 - loss: 1.3727 - val_accuracy: 0.5250 - val_loss: 1.4585\n",
            "Epoch 79/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4940 - loss: 1.3733 - val_accuracy: 0.5417 - val_loss: 1.4519\n",
            "Epoch 80/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5155 - loss: 1.3953 - val_accuracy: 0.5417 - val_loss: 1.4438\n",
            "Epoch 81/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5288 - loss: 1.3583 - val_accuracy: 0.5250 - val_loss: 1.4394\n",
            "Epoch 82/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5337 - loss: 1.3370 - val_accuracy: 0.5167 - val_loss: 1.4482\n",
            "Epoch 83/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5103 - loss: 1.3596 - val_accuracy: 0.5500 - val_loss: 1.4342\n",
            "Epoch 84/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5200 - loss: 1.3459 - val_accuracy: 0.5417 - val_loss: 1.4511\n",
            "Epoch 85/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5281 - loss: 1.3474 - val_accuracy: 0.5167 - val_loss: 1.4655\n",
            "Epoch 86/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5318 - loss: 1.3285 - val_accuracy: 0.5083 - val_loss: 1.4651\n",
            "Epoch 87/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5482 - loss: 1.3365 - val_accuracy: 0.5583 - val_loss: 1.4295\n",
            "Epoch 88/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5412 - loss: 1.3362 - val_accuracy: 0.5417 - val_loss: 1.4369\n",
            "Epoch 89/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5555 - loss: 1.3052 - val_accuracy: 0.5167 - val_loss: 1.4306\n",
            "Epoch 90/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5668 - loss: 1.3159 - val_accuracy: 0.4833 - val_loss: 1.4489\n",
            "Epoch 91/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5530 - loss: 1.3065 - val_accuracy: 0.5250 - val_loss: 1.4370\n",
            "Epoch 92/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5758 - loss: 1.2955 - val_accuracy: 0.5500 - val_loss: 1.4297\n",
            "Epoch 93/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5719 - loss: 1.2913 - val_accuracy: 0.5833 - val_loss: 1.4194\n",
            "Epoch 94/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5894 - loss: 1.2908 - val_accuracy: 0.5250 - val_loss: 1.4373\n",
            "Epoch 95/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5709 - loss: 1.2951 - val_accuracy: 0.5167 - val_loss: 1.4201\n",
            "Epoch 96/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6067 - loss: 1.2688 - val_accuracy: 0.5250 - val_loss: 1.4296\n",
            "Epoch 97/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6241 - loss: 1.2466 - val_accuracy: 0.5417 - val_loss: 1.4047\n",
            "Epoch 98/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6000 - loss: 1.2808 - val_accuracy: 0.5500 - val_loss: 1.4193\n",
            "Epoch 99/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6032 - loss: 1.2402 - val_accuracy: 0.5667 - val_loss: 1.4071\n",
            "Epoch 100/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5897 - loss: 1.2394 - val_accuracy: 0.6083 - val_loss: 1.3846\n",
            "Epoch 101/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5764 - loss: 1.2755 - val_accuracy: 0.5750 - val_loss: 1.3871\n",
            "Epoch 102/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5966 - loss: 1.2569 - val_accuracy: 0.6083 - val_loss: 1.3789\n",
            "Epoch 103/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6059 - loss: 1.2224 - val_accuracy: 0.5500 - val_loss: 1.4015\n",
            "Epoch 104/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5949 - loss: 1.2547 - val_accuracy: 0.5750 - val_loss: 1.4071\n",
            "Epoch 105/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6002 - loss: 1.2402 - val_accuracy: 0.5583 - val_loss: 1.3894\n",
            "Epoch 106/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6156 - loss: 1.2336 - val_accuracy: 0.5583 - val_loss: 1.4002\n",
            "Epoch 107/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6055 - loss: 1.2330 - val_accuracy: 0.5667 - val_loss: 1.4010\n",
            "Epoch 108/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6045 - loss: 1.2084 - val_accuracy: 0.6000 - val_loss: 1.3782\n",
            "Epoch 109/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6478 - loss: 1.2081 - val_accuracy: 0.6000 - val_loss: 1.3762\n",
            "Epoch 110/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6098 - loss: 1.2248 - val_accuracy: 0.5250 - val_loss: 1.3963\n",
            "Epoch 111/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6163 - loss: 1.2125 - val_accuracy: 0.5417 - val_loss: 1.3859\n",
            "Epoch 112/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6460 - loss: 1.2058 - val_accuracy: 0.5667 - val_loss: 1.3774\n",
            "Epoch 113/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6271 - loss: 1.2124 - val_accuracy: 0.5833 - val_loss: 1.3660\n",
            "Epoch 114/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6129 - loss: 1.2001 - val_accuracy: 0.6167 - val_loss: 1.3593\n",
            "Epoch 115/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6468 - loss: 1.1824 - val_accuracy: 0.6000 - val_loss: 1.3702\n",
            "Epoch 116/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6707 - loss: 1.1703 - val_accuracy: 0.5750 - val_loss: 1.3688\n",
            "Epoch 117/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6037 - loss: 1.2149 - val_accuracy: 0.5583 - val_loss: 1.3623\n",
            "Epoch 118/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6496 - loss: 1.1879 - val_accuracy: 0.5750 - val_loss: 1.3733\n",
            "Epoch 119/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6195 - loss: 1.1775 - val_accuracy: 0.5833 - val_loss: 1.3692\n",
            "Epoch 120/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6511 - loss: 1.1600 - val_accuracy: 0.6083 - val_loss: 1.3630\n",
            "Epoch 121/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6489 - loss: 1.1602 - val_accuracy: 0.5583 - val_loss: 1.3682\n",
            "Epoch 122/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6390 - loss: 1.1681 - val_accuracy: 0.5750 - val_loss: 1.3494\n",
            "Epoch 123/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6463 - loss: 1.1641 - val_accuracy: 0.5417 - val_loss: 1.3691\n",
            "Epoch 124/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6726 - loss: 1.1447 - val_accuracy: 0.5667 - val_loss: 1.3511\n",
            "Epoch 125/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6624 - loss: 1.1700 - val_accuracy: 0.5833 - val_loss: 1.3504\n",
            "Epoch 126/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6556 - loss: 1.1608 - val_accuracy: 0.5750 - val_loss: 1.3558\n",
            "Epoch 127/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6751 - loss: 1.1420 - val_accuracy: 0.6083 - val_loss: 1.3448\n",
            "Epoch 128/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6582 - loss: 1.1703 - val_accuracy: 0.5583 - val_loss: 1.3605\n",
            "Epoch 129/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6596 - loss: 1.1416 - val_accuracy: 0.5833 - val_loss: 1.3522\n",
            "Epoch 130/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6728 - loss: 1.1124 - val_accuracy: 0.5833 - val_loss: 1.3690\n",
            "Epoch 131/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6627 - loss: 1.1491 - val_accuracy: 0.5917 - val_loss: 1.3474\n",
            "Epoch 132/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6592 - loss: 1.1221 - val_accuracy: 0.5833 - val_loss: 1.3385\n",
            "Epoch 133/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6828 - loss: 1.1213 - val_accuracy: 0.6083 - val_loss: 1.3186\n",
            "Epoch 134/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6753 - loss: 1.1088 - val_accuracy: 0.6167 - val_loss: 1.3267\n",
            "Epoch 135/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6912 - loss: 1.1060 - val_accuracy: 0.5583 - val_loss: 1.3431\n",
            "Epoch 136/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6822 - loss: 1.1141 - val_accuracy: 0.6000 - val_loss: 1.3315\n",
            "Epoch 137/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6939 - loss: 1.1113 - val_accuracy: 0.5917 - val_loss: 1.3313\n",
            "Epoch 138/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6823 - loss: 1.1182 - val_accuracy: 0.5583 - val_loss: 1.3188\n",
            "Epoch 139/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6600 - loss: 1.1028 - val_accuracy: 0.5833 - val_loss: 1.3254\n",
            "Epoch 140/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6526 - loss: 1.1139 - val_accuracy: 0.6000 - val_loss: 1.3246\n",
            "Epoch 141/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6914 - loss: 1.0900 - val_accuracy: 0.5667 - val_loss: 1.3389\n",
            "Epoch 142/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6806 - loss: 1.1044 - val_accuracy: 0.5917 - val_loss: 1.3230\n",
            "Epoch 143/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7075 - loss: 1.0854 - val_accuracy: 0.5750 - val_loss: 1.3368\n",
            "Epoch 144/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6937 - loss: 1.1023 - val_accuracy: 0.6333 - val_loss: 1.3109\n",
            "Epoch 145/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7132 - loss: 1.0907 - val_accuracy: 0.5833 - val_loss: 1.3301\n",
            "Epoch 146/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7039 - loss: 1.0744 - val_accuracy: 0.6000 - val_loss: 1.3190\n",
            "Epoch 147/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7085 - loss: 1.0752 - val_accuracy: 0.6000 - val_loss: 1.3174\n",
            "Epoch 148/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6818 - loss: 1.0739 - val_accuracy: 0.5333 - val_loss: 1.3413\n",
            "Epoch 149/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6999 - loss: 1.0571 - val_accuracy: 0.6250 - val_loss: 1.3190\n",
            "Epoch 150/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7180 - loss: 1.0576 - val_accuracy: 0.5917 - val_loss: 1.3200\n",
            "Epoch 151/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6948 - loss: 1.0878 - val_accuracy: 0.5917 - val_loss: 1.3189\n",
            "Epoch 152/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7181 - loss: 1.0552 - val_accuracy: 0.6000 - val_loss: 1.3030\n",
            "Epoch 153/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7330 - loss: 1.0451 - val_accuracy: 0.6333 - val_loss: 1.3123\n",
            "Epoch 154/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7249 - loss: 1.0403 - val_accuracy: 0.6167 - val_loss: 1.3140\n",
            "Epoch 155/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7026 - loss: 1.0517 - val_accuracy: 0.6417 - val_loss: 1.2940\n",
            "Epoch 156/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7435 - loss: 1.0375 - val_accuracy: 0.6167 - val_loss: 1.3085\n",
            "Epoch 157/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7289 - loss: 1.0447 - val_accuracy: 0.6083 - val_loss: 1.3208\n",
            "Epoch 158/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7418 - loss: 1.0290 - val_accuracy: 0.6083 - val_loss: 1.3211\n",
            "Epoch 159/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7503 - loss: 1.0138 - val_accuracy: 0.6583 - val_loss: 1.2895\n",
            "Epoch 160/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7134 - loss: 1.0527 - val_accuracy: 0.5917 - val_loss: 1.3052\n",
            "Epoch 161/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7324 - loss: 1.0297 - val_accuracy: 0.5917 - val_loss: 1.3051\n",
            "Epoch 162/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7216 - loss: 1.0119 - val_accuracy: 0.6250 - val_loss: 1.2968\n",
            "Epoch 163/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7431 - loss: 1.0185 - val_accuracy: 0.5833 - val_loss: 1.3084\n",
            "Epoch 164/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7375 - loss: 1.0198 - val_accuracy: 0.6167 - val_loss: 1.3090\n",
            "Epoch 165/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7440 - loss: 1.0163 - val_accuracy: 0.6417 - val_loss: 1.3101\n",
            "Epoch 166/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7469 - loss: 0.9895 - val_accuracy: 0.6000 - val_loss: 1.3036\n",
            "Epoch 167/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7187 - loss: 1.0360 - val_accuracy: 0.6083 - val_loss: 1.3065\n",
            "Epoch 168/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7451 - loss: 1.0095 - val_accuracy: 0.6250 - val_loss: 1.3010\n",
            "Epoch 169/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7444 - loss: 0.9990 - val_accuracy: 0.6083 - val_loss: 1.3161\n",
            "Epoch 170/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7508 - loss: 1.0076 - val_accuracy: 0.6417 - val_loss: 1.2922\n",
            "Epoch 171/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7603 - loss: 1.0054 - val_accuracy: 0.6083 - val_loss: 1.3173\n",
            "Epoch 172/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7562 - loss: 0.9912 - val_accuracy: 0.6000 - val_loss: 1.3085\n",
            "Epoch 173/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7410 - loss: 0.9953 - val_accuracy: 0.6417 - val_loss: 1.2829\n",
            "Epoch 174/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7493 - loss: 0.9843 - val_accuracy: 0.6083 - val_loss: 1.2969\n",
            "Epoch 175/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7535 - loss: 0.9926 - val_accuracy: 0.6417 - val_loss: 1.2827\n",
            "Epoch 176/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7683 - loss: 0.9717 - val_accuracy: 0.6000 - val_loss: 1.3046\n",
            "Epoch 177/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7679 - loss: 0.9707 - val_accuracy: 0.5833 - val_loss: 1.2994\n",
            "Epoch 178/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7366 - loss: 0.9651 - val_accuracy: 0.6333 - val_loss: 1.2824\n",
            "Epoch 179/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7544 - loss: 0.9716 - val_accuracy: 0.6000 - val_loss: 1.3006\n",
            "Epoch 180/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7704 - loss: 0.9741 - val_accuracy: 0.6333 - val_loss: 1.2958\n",
            "Epoch 181/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7833 - loss: 0.9381 - val_accuracy: 0.6333 - val_loss: 1.2896\n",
            "Epoch 182/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7664 - loss: 0.9556 - val_accuracy: 0.6583 - val_loss: 1.2734\n",
            "Epoch 183/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7676 - loss: 0.9662 - val_accuracy: 0.6333 - val_loss: 1.2949\n",
            "Epoch 184/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7692 - loss: 0.9586 - val_accuracy: 0.6167 - val_loss: 1.2815\n",
            "Epoch 185/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7825 - loss: 0.9497 - val_accuracy: 0.6083 - val_loss: 1.2840\n",
            "Epoch 186/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8011 - loss: 0.9416 - val_accuracy: 0.6250 - val_loss: 1.2942\n",
            "Epoch 187/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7841 - loss: 0.9293 - val_accuracy: 0.6500 - val_loss: 1.2820\n",
            "Epoch 188/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7804 - loss: 0.9339 - val_accuracy: 0.6500 - val_loss: 1.2749\n",
            "Epoch 189/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7899 - loss: 0.9516 - val_accuracy: 0.6167 - val_loss: 1.2807\n",
            "Epoch 190/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7932 - loss: 0.9188 - val_accuracy: 0.6083 - val_loss: 1.2878\n",
            "Epoch 191/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8126 - loss: 0.9259 - val_accuracy: 0.6083 - val_loss: 1.2882\n",
            "Epoch 192/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7709 - loss: 0.9438 - val_accuracy: 0.6333 - val_loss: 1.2730\n",
            "Epoch 193/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7867 - loss: 0.9243 - val_accuracy: 0.6333 - val_loss: 1.2618\n",
            "Epoch 194/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8046 - loss: 0.9186 - val_accuracy: 0.6167 - val_loss: 1.2876\n",
            "Epoch 195/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7837 - loss: 0.9349 - val_accuracy: 0.6417 - val_loss: 1.2761\n",
            "Epoch 196/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7941 - loss: 0.9221 - val_accuracy: 0.6083 - val_loss: 1.2939\n",
            "Epoch 197/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8243 - loss: 0.9063 - val_accuracy: 0.6250 - val_loss: 1.2878\n",
            "Epoch 198/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8049 - loss: 0.9144 - val_accuracy: 0.6000 - val_loss: 1.2984\n",
            "Epoch 199/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7972 - loss: 0.9135 - val_accuracy: 0.6250 - val_loss: 1.2832\n",
            "Epoch 200/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7745 - loss: 0.9175 - val_accuracy: 0.6250 - val_loss: 1.2679\n",
            "Epoch 201/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7968 - loss: 0.9086 - val_accuracy: 0.6083 - val_loss: 1.2987\n",
            "Epoch 202/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7861 - loss: 0.9222 - val_accuracy: 0.5833 - val_loss: 1.3053\n",
            "Epoch 203/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8027 - loss: 0.9206 - val_accuracy: 0.5833 - val_loss: 1.2748\n",
            "Epoch 204/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8012 - loss: 0.8853 - val_accuracy: 0.5917 - val_loss: 1.2902\n",
            "Epoch 205/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8131 - loss: 0.8882 - val_accuracy: 0.6333 - val_loss: 1.2815\n",
            "Epoch 206/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8211 - loss: 0.9091 - val_accuracy: 0.6083 - val_loss: 1.2758\n",
            "Epoch 207/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8061 - loss: 0.8883 - val_accuracy: 0.6250 - val_loss: 1.2919\n",
            "Epoch 208/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8059 - loss: 0.8902 - val_accuracy: 0.6417 - val_loss: 1.2750\n",
            "Epoch 209/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7997 - loss: 0.9092 - val_accuracy: 0.6250 - val_loss: 1.2839\n",
            "Epoch 210/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.8940 - val_accuracy: 0.6500 - val_loss: 1.2708\n",
            "Epoch 211/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8181 - loss: 0.8838 - val_accuracy: 0.5833 - val_loss: 1.2824\n",
            "Epoch 212/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8217 - loss: 0.8951 - val_accuracy: 0.6417 - val_loss: 1.2760\n",
            "Epoch 213/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8258 - loss: 0.8751 - val_accuracy: 0.6333 - val_loss: 1.2716\n",
            "Epoch 214/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8054 - loss: 0.8860 - val_accuracy: 0.6250 - val_loss: 1.2757\n",
            "Epoch 215/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8047 - loss: 0.8855 - val_accuracy: 0.6583 - val_loss: 1.2640\n",
            "Epoch 216/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8029 - loss: 0.8864 - val_accuracy: 0.6250 - val_loss: 1.2811\n",
            "Epoch 217/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8284 - loss: 0.8775 - val_accuracy: 0.6333 - val_loss: 1.2659\n",
            "Epoch 218/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8082 - loss: 0.8869 - val_accuracy: 0.6333 - val_loss: 1.2585\n",
            "Epoch 219/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7911 - loss: 0.8973 - val_accuracy: 0.6417 - val_loss: 1.2617\n",
            "Epoch 220/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8165 - loss: 0.8668 - val_accuracy: 0.6167 - val_loss: 1.2484\n",
            "Epoch 221/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8287 - loss: 0.8694 - val_accuracy: 0.6333 - val_loss: 1.2573\n",
            "Epoch 222/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8103 - loss: 0.8760 - val_accuracy: 0.6250 - val_loss: 1.2778\n",
            "Epoch 223/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8285 - loss: 0.8872 - val_accuracy: 0.6417 - val_loss: 1.2747\n",
            "Epoch 224/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8227 - loss: 0.8774 - val_accuracy: 0.6500 - val_loss: 1.2638\n",
            "Epoch 225/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8373 - loss: 0.8700 - val_accuracy: 0.6417 - val_loss: 1.2689\n",
            "Epoch 226/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8044 - loss: 0.8807 - val_accuracy: 0.6167 - val_loss: 1.2586\n",
            "Epoch 227/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8562 - loss: 0.8621 - val_accuracy: 0.6167 - val_loss: 1.2652\n",
            "Epoch 228/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8384 - loss: 0.8458 - val_accuracy: 0.6417 - val_loss: 1.2706\n",
            "Epoch 229/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8463 - loss: 0.8385 - val_accuracy: 0.6167 - val_loss: 1.2861\n",
            "Epoch 230/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8448 - loss: 0.8298 - val_accuracy: 0.6167 - val_loss: 1.2694\n",
            "Epoch 231/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8078 - loss: 0.8622 - val_accuracy: 0.6250 - val_loss: 1.2724\n",
            "Epoch 232/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8323 - loss: 0.8543 - val_accuracy: 0.6250 - val_loss: 1.2510\n",
            "Epoch 233/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8303 - loss: 0.8465 - val_accuracy: 0.6250 - val_loss: 1.2547\n",
            "Epoch 234/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8545 - loss: 0.8345 - val_accuracy: 0.6500 - val_loss: 1.2641\n",
            "Epoch 235/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8543 - loss: 0.8261 - val_accuracy: 0.6333 - val_loss: 1.2624\n",
            "Epoch 236/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8287 - loss: 0.8402 - val_accuracy: 0.6250 - val_loss: 1.2607\n",
            "Epoch 237/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8310 - loss: 0.8326 - val_accuracy: 0.6500 - val_loss: 1.2614\n",
            "Epoch 238/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8393 - loss: 0.8394 - val_accuracy: 0.6250 - val_loss: 1.2774\n",
            "Epoch 239/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8707 - loss: 0.8137 - val_accuracy: 0.6333 - val_loss: 1.2524\n",
            "Epoch 240/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8813 - loss: 0.8056 - val_accuracy: 0.6250 - val_loss: 1.2398\n",
            "Epoch 241/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8547 - loss: 0.8257 - val_accuracy: 0.6417 - val_loss: 1.2464\n",
            "Epoch 242/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8463 - loss: 0.8249 - val_accuracy: 0.6500 - val_loss: 1.2586\n",
            "Epoch 243/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8454 - loss: 0.8145 - val_accuracy: 0.6667 - val_loss: 1.2475\n",
            "Epoch 244/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8561 - loss: 0.8268 - val_accuracy: 0.6250 - val_loss: 1.2476\n",
            "Epoch 245/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8505 - loss: 0.8151 - val_accuracy: 0.6583 - val_loss: 1.2457\n",
            "Epoch 246/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8703 - loss: 0.7966 - val_accuracy: 0.6750 - val_loss: 1.2318\n",
            "Epoch 247/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8616 - loss: 0.8008 - val_accuracy: 0.6417 - val_loss: 1.2400\n",
            "Epoch 248/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8602 - loss: 0.7973 - val_accuracy: 0.6417 - val_loss: 1.2390\n",
            "Epoch 249/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8561 - loss: 0.8166 - val_accuracy: 0.6500 - val_loss: 1.2476\n",
            "Epoch 250/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8691 - loss: 0.8128 - val_accuracy: 0.6167 - val_loss: 1.2324\n",
            "Epoch 251/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8719 - loss: 0.7972 - val_accuracy: 0.6333 - val_loss: 1.2390\n",
            "Epoch 252/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8573 - loss: 0.8085 - val_accuracy: 0.6333 - val_loss: 1.2347\n",
            "Epoch 253/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8544 - loss: 0.8102 - val_accuracy: 0.6500 - val_loss: 1.2342\n",
            "Epoch 254/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8601 - loss: 0.7951 - val_accuracy: 0.6500 - val_loss: 1.2452\n",
            "Epoch 255/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8684 - loss: 0.8051 - val_accuracy: 0.6333 - val_loss: 1.2424\n",
            "Epoch 256/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8630 - loss: 0.7864 - val_accuracy: 0.6417 - val_loss: 1.2627\n",
            "Epoch 257/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8725 - loss: 0.7762 - val_accuracy: 0.6333 - val_loss: 1.2479\n",
            "Epoch 258/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8536 - loss: 0.8017 - val_accuracy: 0.6417 - val_loss: 1.2415\n",
            "Epoch 259/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8763 - loss: 0.7753 - val_accuracy: 0.6417 - val_loss: 1.2187\n",
            "Epoch 260/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8691 - loss: 0.7944 - val_accuracy: 0.6417 - val_loss: 1.2468\n",
            "Epoch 261/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8795 - loss: 0.7850 - val_accuracy: 0.6417 - val_loss: 1.2489\n",
            "Epoch 262/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8816 - loss: 0.7856 - val_accuracy: 0.6333 - val_loss: 1.2193\n",
            "Epoch 263/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8900 - loss: 0.7686 - val_accuracy: 0.6333 - val_loss: 1.2282\n",
            "Epoch 264/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8628 - loss: 0.7850 - val_accuracy: 0.6333 - val_loss: 1.2370\n",
            "Epoch 265/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8843 - loss: 0.7827 - val_accuracy: 0.6250 - val_loss: 1.2521\n",
            "Epoch 266/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8805 - loss: 0.7624 - val_accuracy: 0.6417 - val_loss: 1.2338\n",
            "Epoch 267/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8753 - loss: 0.7693 - val_accuracy: 0.6500 - val_loss: 1.2409\n",
            "Epoch 268/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8753 - loss: 0.7761 - val_accuracy: 0.6167 - val_loss: 1.2346\n",
            "Epoch 269/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8798 - loss: 0.7756 - val_accuracy: 0.6417 - val_loss: 1.2309\n",
            "Epoch 270/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8714 - loss: 0.7718 - val_accuracy: 0.6333 - val_loss: 1.2291\n",
            "Epoch 271/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8816 - loss: 0.7709 - val_accuracy: 0.6167 - val_loss: 1.2495\n",
            "Epoch 272/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8697 - loss: 0.7676 - val_accuracy: 0.6500 - val_loss: 1.2315\n",
            "Epoch 273/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8833 - loss: 0.7729 - val_accuracy: 0.6500 - val_loss: 1.2268\n",
            "Epoch 274/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8863 - loss: 0.7690 - val_accuracy: 0.6333 - val_loss: 1.2407\n",
            "Epoch 275/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8887 - loss: 0.7555 - val_accuracy: 0.6500 - val_loss: 1.2390\n",
            "Epoch 276/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.7558 - val_accuracy: 0.6500 - val_loss: 1.2450\n",
            "Epoch 277/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8930 - loss: 0.7600 - val_accuracy: 0.6417 - val_loss: 1.2298\n",
            "Epoch 278/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8955 - loss: 0.7632 - val_accuracy: 0.6667 - val_loss: 1.2190\n",
            "Epoch 279/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8931 - loss: 0.7562 - val_accuracy: 0.6500 - val_loss: 1.2172\n",
            "Epoch 280/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8961 - loss: 0.7431 - val_accuracy: 0.6417 - val_loss: 1.2267\n",
            "Epoch 281/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8880 - loss: 0.7450 - val_accuracy: 0.6333 - val_loss: 1.2198\n",
            "Epoch 282/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8841 - loss: 0.7480 - val_accuracy: 0.6333 - val_loss: 1.2455\n",
            "Epoch 283/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8871 - loss: 0.7446 - val_accuracy: 0.6500 - val_loss: 1.2122\n",
            "Epoch 284/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8814 - loss: 0.7559 - val_accuracy: 0.6500 - val_loss: 1.2098\n",
            "Epoch 285/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8932 - loss: 0.7557 - val_accuracy: 0.6417 - val_loss: 1.2279\n",
            "Epoch 286/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8883 - loss: 0.7486 - val_accuracy: 0.6500 - val_loss: 1.2418\n",
            "Epoch 287/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8853 - loss: 0.7598 - val_accuracy: 0.6500 - val_loss: 1.2267\n",
            "Epoch 288/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8912 - loss: 0.7319 - val_accuracy: 0.6250 - val_loss: 1.2449\n",
            "Epoch 289/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9093 - loss: 0.7523 - val_accuracy: 0.6417 - val_loss: 1.2343\n",
            "Epoch 290/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.7347 - val_accuracy: 0.6417 - val_loss: 1.2320\n",
            "Epoch 291/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8949 - loss: 0.7367 - val_accuracy: 0.6500 - val_loss: 1.2241\n",
            "Epoch 292/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9060 - loss: 0.7305 - val_accuracy: 0.6333 - val_loss: 1.2260\n",
            "Epoch 293/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8890 - loss: 0.7408 - val_accuracy: 0.6250 - val_loss: 1.2222\n",
            "Epoch 294/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8666 - loss: 0.7585 - val_accuracy: 0.6667 - val_loss: 1.2070\n",
            "Epoch 295/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8844 - loss: 0.7386 - val_accuracy: 0.6500 - val_loss: 1.2149\n",
            "Epoch 296/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8871 - loss: 0.7274 - val_accuracy: 0.6000 - val_loss: 1.2228\n",
            "Epoch 297/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9106 - loss: 0.7345 - val_accuracy: 0.6417 - val_loss: 1.2215\n",
            "Epoch 298/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9099 - loss: 0.7249 - val_accuracy: 0.6333 - val_loss: 1.2209\n",
            "Epoch 299/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9049 - loss: 0.7299 - val_accuracy: 0.6333 - val_loss: 1.2229\n",
            "Epoch 300/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9228 - loss: 0.7155 - val_accuracy: 0.6250 - val_loss: 1.2175\n",
            "Epoch 301/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9055 - loss: 0.7189 - val_accuracy: 0.6417 - val_loss: 1.2143\n",
            "Epoch 302/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8926 - loss: 0.7131 - val_accuracy: 0.6583 - val_loss: 1.2182\n",
            "Epoch 303/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9048 - loss: 0.7211 - val_accuracy: 0.6417 - val_loss: 1.2092\n",
            "Epoch 304/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8967 - loss: 0.7252 - val_accuracy: 0.6583 - val_loss: 1.1965\n",
            "Epoch 305/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9029 - loss: 0.7076 - val_accuracy: 0.6667 - val_loss: 1.2189\n",
            "Epoch 306/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8928 - loss: 0.7286 - val_accuracy: 0.6333 - val_loss: 1.2211\n",
            "Epoch 307/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8893 - loss: 0.7231 - val_accuracy: 0.6500 - val_loss: 1.2017\n",
            "Epoch 308/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9019 - loss: 0.7172 - val_accuracy: 0.6417 - val_loss: 1.2073\n",
            "Epoch 309/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9026 - loss: 0.7227 - val_accuracy: 0.6417 - val_loss: 1.1994\n",
            "Epoch 310/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9348 - loss: 0.6946 - val_accuracy: 0.6583 - val_loss: 1.2082\n",
            "Epoch 311/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9294 - loss: 0.6948 - val_accuracy: 0.6500 - val_loss: 1.1977\n",
            "Epoch 312/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9059 - loss: 0.7066 - val_accuracy: 0.6833 - val_loss: 1.1807\n",
            "Epoch 313/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9065 - loss: 0.7068 - val_accuracy: 0.6667 - val_loss: 1.2076\n",
            "Epoch 314/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9150 - loss: 0.6984 - val_accuracy: 0.6583 - val_loss: 1.2022\n",
            "Epoch 315/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9013 - loss: 0.7182 - val_accuracy: 0.6583 - val_loss: 1.2167\n",
            "Epoch 316/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9157 - loss: 0.6969 - val_accuracy: 0.6667 - val_loss: 1.2082\n",
            "Epoch 317/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9196 - loss: 0.6921 - val_accuracy: 0.6500 - val_loss: 1.2066\n",
            "Epoch 318/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9135 - loss: 0.6992 - val_accuracy: 0.6583 - val_loss: 1.2094\n",
            "Epoch 319/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9079 - loss: 0.6961 - val_accuracy: 0.6417 - val_loss: 1.2103\n",
            "Epoch 320/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9311 - loss: 0.6878 - val_accuracy: 0.6500 - val_loss: 1.2024\n",
            "Epoch 321/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9041 - loss: 0.7088 - val_accuracy: 0.6583 - val_loss: 1.2022\n",
            "Epoch 322/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9132 - loss: 0.7008 - val_accuracy: 0.6750 - val_loss: 1.1888\n",
            "Epoch 323/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9239 - loss: 0.6917 - val_accuracy: 0.6667 - val_loss: 1.1981\n",
            "Epoch 324/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9083 - loss: 0.7095 - val_accuracy: 0.6333 - val_loss: 1.2024\n",
            "Epoch 325/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9112 - loss: 0.7012 - val_accuracy: 0.6417 - val_loss: 1.2108\n",
            "Epoch 326/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9271 - loss: 0.6924 - val_accuracy: 0.6417 - val_loss: 1.2167\n",
            "Epoch 327/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9242 - loss: 0.6893 - val_accuracy: 0.6417 - val_loss: 1.2183\n",
            "Epoch 328/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9016 - loss: 0.6882 - val_accuracy: 0.6417 - val_loss: 1.2031\n",
            "Epoch 329/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9291 - loss: 0.6752 - val_accuracy: 0.6417 - val_loss: 1.2043\n",
            "Epoch 330/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9066 - loss: 0.6993 - val_accuracy: 0.6500 - val_loss: 1.2144\n",
            "Epoch 331/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9119 - loss: 0.6856 - val_accuracy: 0.6583 - val_loss: 1.2092\n",
            "Epoch 332/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9140 - loss: 0.6727 - val_accuracy: 0.6333 - val_loss: 1.2077\n",
            "Epoch 333/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9312 - loss: 0.6798 - val_accuracy: 0.6583 - val_loss: 1.2025\n",
            "Epoch 334/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9115 - loss: 0.6799 - val_accuracy: 0.6500 - val_loss: 1.2056\n",
            "Epoch 335/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9359 - loss: 0.6663 - val_accuracy: 0.6583 - val_loss: 1.2016\n",
            "Epoch 336/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9240 - loss: 0.6752 - val_accuracy: 0.6583 - val_loss: 1.1905\n",
            "Epoch 337/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9296 - loss: 0.6805 - val_accuracy: 0.6083 - val_loss: 1.2066\n",
            "Epoch 338/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9197 - loss: 0.6788 - val_accuracy: 0.6500 - val_loss: 1.1999\n",
            "Epoch 339/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9308 - loss: 0.6651 - val_accuracy: 0.6667 - val_loss: 1.2013\n",
            "Epoch 340/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9303 - loss: 0.6671 - val_accuracy: 0.6750 - val_loss: 1.2057\n",
            "Epoch 341/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9120 - loss: 0.6779 - val_accuracy: 0.6750 - val_loss: 1.1980\n",
            "Epoch 342/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9135 - loss: 0.6605 - val_accuracy: 0.6500 - val_loss: 1.2123\n",
            "Epoch 343/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9395 - loss: 0.6498 - val_accuracy: 0.6667 - val_loss: 1.1999\n",
            "Epoch 344/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9175 - loss: 0.6681 - val_accuracy: 0.6500 - val_loss: 1.2149\n",
            "Epoch 345/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9241 - loss: 0.6684 - val_accuracy: 0.6750 - val_loss: 1.2065\n",
            "Epoch 346/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9208 - loss: 0.6559 - val_accuracy: 0.6417 - val_loss: 1.2136\n",
            "Epoch 347/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9281 - loss: 0.6469 - val_accuracy: 0.6833 - val_loss: 1.2053\n",
            "Epoch 348/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9282 - loss: 0.6638 - val_accuracy: 0.6667 - val_loss: 1.1959\n",
            "Epoch 349/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.6593 - val_accuracy: 0.6583 - val_loss: 1.1974\n",
            "Epoch 350/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9148 - loss: 0.6866 - val_accuracy: 0.6750 - val_loss: 1.1858\n",
            "Epoch 351/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9310 - loss: 0.6594 - val_accuracy: 0.6750 - val_loss: 1.1697\n",
            "Epoch 352/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9195 - loss: 0.6667 - val_accuracy: 0.6500 - val_loss: 1.1932\n",
            "Epoch 353/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.6610 - val_accuracy: 0.6583 - val_loss: 1.1701\n",
            "Epoch 354/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9335 - loss: 0.6469 - val_accuracy: 0.6667 - val_loss: 1.1854\n",
            "Epoch 355/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9423 - loss: 0.6543 - val_accuracy: 0.6583 - val_loss: 1.1835\n",
            "Epoch 356/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9228 - loss: 0.6760 - val_accuracy: 0.6667 - val_loss: 1.1737\n",
            "Epoch 357/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9413 - loss: 0.6428 - val_accuracy: 0.6583 - val_loss: 1.2017\n",
            "Epoch 358/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9402 - loss: 0.6703 - val_accuracy: 0.6417 - val_loss: 1.2010\n",
            "Epoch 359/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9426 - loss: 0.6396 - val_accuracy: 0.6500 - val_loss: 1.1867\n",
            "Epoch 360/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9359 - loss: 0.6475 - val_accuracy: 0.6500 - val_loss: 1.1897\n",
            "Epoch 361/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9433 - loss: 0.6454 - val_accuracy: 0.6583 - val_loss: 1.1844\n",
            "Epoch 362/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9468 - loss: 0.6469 - val_accuracy: 0.6750 - val_loss: 1.1908\n",
            "Epoch 363/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9350 - loss: 0.6405 - val_accuracy: 0.6333 - val_loss: 1.1840\n",
            "Epoch 364/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.6330 - val_accuracy: 0.6583 - val_loss: 1.1741\n",
            "Epoch 365/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9317 - loss: 0.6459 - val_accuracy: 0.6667 - val_loss: 1.1796\n",
            "Epoch 366/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9446 - loss: 0.6435 - val_accuracy: 0.6667 - val_loss: 1.1634\n",
            "Epoch 367/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9532 - loss: 0.6301 - val_accuracy: 0.6583 - val_loss: 1.1800\n",
            "Epoch 368/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9477 - loss: 0.6275 - val_accuracy: 0.6417 - val_loss: 1.1685\n",
            "Epoch 369/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9465 - loss: 0.6333 - val_accuracy: 0.6750 - val_loss: 1.1841\n",
            "Epoch 370/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9519 - loss: 0.6352 - val_accuracy: 0.6333 - val_loss: 1.1918\n",
            "Epoch 371/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9417 - loss: 0.6301 - val_accuracy: 0.6333 - val_loss: 1.2026\n",
            "Epoch 372/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9392 - loss: 0.6317 - val_accuracy: 0.6417 - val_loss: 1.1709\n",
            "Epoch 373/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9411 - loss: 0.6236 - val_accuracy: 0.6667 - val_loss: 1.1558\n",
            "Epoch 374/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9337 - loss: 0.6253 - val_accuracy: 0.6333 - val_loss: 1.1777\n",
            "Epoch 375/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9513 - loss: 0.6246 - val_accuracy: 0.6583 - val_loss: 1.1783\n",
            "Epoch 376/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9469 - loss: 0.6302 - val_accuracy: 0.6583 - val_loss: 1.1709\n",
            "Epoch 377/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9438 - loss: 0.6193 - val_accuracy: 0.6833 - val_loss: 1.1702\n",
            "Epoch 378/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9432 - loss: 0.6279 - val_accuracy: 0.6667 - val_loss: 1.1790\n",
            "Epoch 379/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9527 - loss: 0.6226 - val_accuracy: 0.6500 - val_loss: 1.1633\n",
            "Epoch 380/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9365 - loss: 0.6327 - val_accuracy: 0.6667 - val_loss: 1.1661\n",
            "Epoch 381/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9221 - loss: 0.6404 - val_accuracy: 0.6667 - val_loss: 1.1768\n",
            "Epoch 382/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9476 - loss: 0.6238 - val_accuracy: 0.6500 - val_loss: 1.1793\n",
            "Epoch 383/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.6068 - val_accuracy: 0.6417 - val_loss: 1.1836\n",
            "Epoch 384/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.6195 - val_accuracy: 0.6750 - val_loss: 1.1545\n",
            "Epoch 385/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9563 - loss: 0.6239 - val_accuracy: 0.6583 - val_loss: 1.1774\n",
            "Epoch 386/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9613 - loss: 0.6074 - val_accuracy: 0.6417 - val_loss: 1.1821\n",
            "Epoch 387/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9567 - loss: 0.6156 - val_accuracy: 0.6583 - val_loss: 1.1924\n",
            "Epoch 388/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9395 - loss: 0.6401 - val_accuracy: 0.6583 - val_loss: 1.1753\n",
            "Epoch 389/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9394 - loss: 0.6116 - val_accuracy: 0.6417 - val_loss: 1.1792\n",
            "Epoch 390/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9379 - loss: 0.6179 - val_accuracy: 0.6583 - val_loss: 1.1578\n",
            "Epoch 391/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.6212 - val_accuracy: 0.6667 - val_loss: 1.1737\n",
            "Epoch 392/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9388 - loss: 0.6197 - val_accuracy: 0.6583 - val_loss: 1.1644\n",
            "Epoch 393/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9325 - loss: 0.6138 - val_accuracy: 0.6500 - val_loss: 1.1603\n",
            "Epoch 394/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9273 - loss: 0.6050 - val_accuracy: 0.6417 - val_loss: 1.1624\n",
            "Epoch 395/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9469 - loss: 0.6205 - val_accuracy: 0.6500 - val_loss: 1.1642\n",
            "Epoch 396/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9554 - loss: 0.6090 - val_accuracy: 0.6583 - val_loss: 1.1827\n",
            "Epoch 397/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9554 - loss: 0.5992 - val_accuracy: 0.6750 - val_loss: 1.1614\n",
            "Epoch 398/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9500 - loss: 0.6024 - val_accuracy: 0.6583 - val_loss: 1.1601\n",
            "Epoch 399/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9466 - loss: 0.5975 - val_accuracy: 0.6333 - val_loss: 1.1802\n",
            "Epoch 400/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.5922 - val_accuracy: 0.6500 - val_loss: 1.1684\n",
            "Epoch 401/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9514 - loss: 0.6085 - val_accuracy: 0.6500 - val_loss: 1.1454\n",
            "Epoch 402/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9644 - loss: 0.5957 - val_accuracy: 0.6500 - val_loss: 1.1645\n",
            "Epoch 403/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9468 - loss: 0.5964 - val_accuracy: 0.6667 - val_loss: 1.1523\n",
            "Epoch 404/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9451 - loss: 0.6066 - val_accuracy: 0.6833 - val_loss: 1.1582\n",
            "Epoch 405/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9580 - loss: 0.5942 - val_accuracy: 0.6667 - val_loss: 1.1629\n",
            "Epoch 406/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.6010 - val_accuracy: 0.6417 - val_loss: 1.1672\n",
            "Epoch 407/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9433 - loss: 0.5964 - val_accuracy: 0.6417 - val_loss: 1.1622\n",
            "Epoch 408/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.6064 - val_accuracy: 0.6500 - val_loss: 1.1721\n",
            "Epoch 409/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9610 - loss: 0.5962 - val_accuracy: 0.6583 - val_loss: 1.1665\n",
            "Epoch 410/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.6007 - val_accuracy: 0.6500 - val_loss: 1.1762\n",
            "Epoch 411/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9557 - loss: 0.5950 - val_accuracy: 0.6583 - val_loss: 1.1688\n",
            "Epoch 412/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9668 - loss: 0.5943 - val_accuracy: 0.6667 - val_loss: 1.1827\n",
            "Epoch 413/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9502 - loss: 0.5901 - val_accuracy: 0.6667 - val_loss: 1.1543\n",
            "Epoch 414/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9550 - loss: 0.5980 - val_accuracy: 0.6667 - val_loss: 1.1676\n",
            "Epoch 415/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9640 - loss: 0.5852 - val_accuracy: 0.6583 - val_loss: 1.1695\n",
            "Epoch 416/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9480 - loss: 0.5925 - val_accuracy: 0.6583 - val_loss: 1.1746\n",
            "Epoch 417/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9582 - loss: 0.5821 - val_accuracy: 0.6500 - val_loss: 1.1580\n",
            "Epoch 418/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9462 - loss: 0.5864 - val_accuracy: 0.6583 - val_loss: 1.1655\n",
            "Epoch 419/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9519 - loss: 0.5909 - val_accuracy: 0.6833 - val_loss: 1.1569\n",
            "Epoch 420/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9572 - loss: 0.5913 - val_accuracy: 0.6583 - val_loss: 1.1597\n",
            "Epoch 421/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9584 - loss: 0.5781 - val_accuracy: 0.6667 - val_loss: 1.1492\n",
            "Epoch 422/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9543 - loss: 0.5702 - val_accuracy: 0.6583 - val_loss: 1.1599\n",
            "Epoch 423/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9483 - loss: 0.5820 - val_accuracy: 0.6750 - val_loss: 1.1694\n",
            "Epoch 424/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9693 - loss: 0.5687 - val_accuracy: 0.6917 - val_loss: 1.1499\n",
            "Epoch 425/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9718 - loss: 0.5762 - val_accuracy: 0.6667 - val_loss: 1.1552\n",
            "Epoch 426/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.5753 - val_accuracy: 0.6833 - val_loss: 1.1502\n",
            "Epoch 427/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9728 - loss: 0.5693 - val_accuracy: 0.6833 - val_loss: 1.1371\n",
            "Epoch 428/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.5727 - val_accuracy: 0.6667 - val_loss: 1.1514\n",
            "Epoch 429/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9578 - loss: 0.5798 - val_accuracy: 0.6750 - val_loss: 1.1432\n",
            "Epoch 430/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.5793 - val_accuracy: 0.6583 - val_loss: 1.1526\n",
            "Epoch 431/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9620 - loss: 0.5673 - val_accuracy: 0.6667 - val_loss: 1.1540\n",
            "Epoch 432/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9645 - loss: 0.5723 - val_accuracy: 0.6583 - val_loss: 1.1520\n",
            "Epoch 433/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9633 - loss: 0.5674 - val_accuracy: 0.6917 - val_loss: 1.1477\n",
            "Epoch 434/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.5744 - val_accuracy: 0.6667 - val_loss: 1.1606\n",
            "Epoch 435/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9584 - loss: 0.5752 - val_accuracy: 0.6583 - val_loss: 1.1482\n",
            "Epoch 436/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9693 - loss: 0.5604 - val_accuracy: 0.6667 - val_loss: 1.1350\n",
            "Epoch 437/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9657 - loss: 0.5639 - val_accuracy: 0.6750 - val_loss: 1.1545\n",
            "Epoch 438/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9765 - loss: 0.5636 - val_accuracy: 0.6750 - val_loss: 1.1456\n",
            "Epoch 439/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9539 - loss: 0.5653 - val_accuracy: 0.6417 - val_loss: 1.1486\n",
            "Epoch 440/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.5679 - val_accuracy: 0.6667 - val_loss: 1.1482\n",
            "Epoch 441/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9672 - loss: 0.5545 - val_accuracy: 0.6833 - val_loss: 1.1497\n",
            "Epoch 442/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.5678 - val_accuracy: 0.6917 - val_loss: 1.1413\n",
            "Epoch 443/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9650 - loss: 0.5746 - val_accuracy: 0.6667 - val_loss: 1.1448\n",
            "Epoch 444/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9700 - loss: 0.5678 - val_accuracy: 0.6583 - val_loss: 1.1493\n",
            "Epoch 445/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9668 - loss: 0.5523 - val_accuracy: 0.6833 - val_loss: 1.1324\n",
            "Epoch 446/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9581 - loss: 0.5634 - val_accuracy: 0.6583 - val_loss: 1.1522\n",
            "Epoch 447/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9569 - loss: 0.5607 - val_accuracy: 0.6333 - val_loss: 1.1638\n",
            "Epoch 448/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9662 - loss: 0.5573 - val_accuracy: 0.6583 - val_loss: 1.1510\n",
            "Epoch 449/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.5587 - val_accuracy: 0.6667 - val_loss: 1.1275\n",
            "Epoch 450/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9613 - loss: 0.5633 - val_accuracy: 0.6750 - val_loss: 1.1315\n",
            "Epoch 451/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9524 - loss: 0.5671 - val_accuracy: 0.6583 - val_loss: 1.1418\n",
            "Epoch 452/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9599 - loss: 0.5583 - val_accuracy: 0.6583 - val_loss: 1.1428\n",
            "Epoch 453/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9603 - loss: 0.5563 - val_accuracy: 0.6500 - val_loss: 1.1393\n",
            "Epoch 454/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9693 - loss: 0.5454 - val_accuracy: 0.6750 - val_loss: 1.1503\n",
            "Epoch 455/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9631 - loss: 0.5461 - val_accuracy: 0.6750 - val_loss: 1.1412\n",
            "Epoch 456/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9611 - loss: 0.5527 - val_accuracy: 0.6500 - val_loss: 1.1445\n",
            "Epoch 457/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.5524 - val_accuracy: 0.6500 - val_loss: 1.1349\n",
            "Epoch 458/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9745 - loss: 0.5524 - val_accuracy: 0.6667 - val_loss: 1.1458\n",
            "Epoch 459/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9624 - loss: 0.5568 - val_accuracy: 0.6500 - val_loss: 1.1409\n",
            "Epoch 460/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.5451 - val_accuracy: 0.6833 - val_loss: 1.1522\n",
            "Epoch 461/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9737 - loss: 0.5389 - val_accuracy: 0.6833 - val_loss: 1.1544\n",
            "Epoch 462/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.5384 - val_accuracy: 0.6833 - val_loss: 1.1384\n",
            "Epoch 463/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9663 - loss: 0.5517 - val_accuracy: 0.6667 - val_loss: 1.1331\n",
            "Epoch 464/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9728 - loss: 0.5434 - val_accuracy: 0.6583 - val_loss: 1.1309\n",
            "Epoch 465/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.5449 - val_accuracy: 0.6833 - val_loss: 1.1375\n",
            "Epoch 466/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9797 - loss: 0.5370 - val_accuracy: 0.6583 - val_loss: 1.1355\n",
            "Epoch 467/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9774 - loss: 0.5390 - val_accuracy: 0.6583 - val_loss: 1.1290\n",
            "Epoch 468/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9713 - loss: 0.5436 - val_accuracy: 0.6833 - val_loss: 1.1274\n",
            "Epoch 469/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9691 - loss: 0.5515 - val_accuracy: 0.6583 - val_loss: 1.1281\n",
            "Epoch 470/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9789 - loss: 0.5384 - val_accuracy: 0.6583 - val_loss: 1.1400\n",
            "Epoch 471/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.5358 - val_accuracy: 0.6750 - val_loss: 1.1279\n",
            "Epoch 472/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9721 - loss: 0.5442 - val_accuracy: 0.6750 - val_loss: 1.1239\n",
            "Epoch 473/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9682 - loss: 0.5384 - val_accuracy: 0.6667 - val_loss: 1.1235\n",
            "Epoch 474/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.5295 - val_accuracy: 0.7000 - val_loss: 1.1100\n",
            "Epoch 475/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9752 - loss: 0.5370 - val_accuracy: 0.6917 - val_loss: 1.1295\n",
            "Epoch 476/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9691 - loss: 0.5374 - val_accuracy: 0.6667 - val_loss: 1.1207\n",
            "Epoch 477/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9677 - loss: 0.5333 - val_accuracy: 0.7000 - val_loss: 1.1285\n",
            "Epoch 478/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9726 - loss: 0.5348 - val_accuracy: 0.6833 - val_loss: 1.1459\n",
            "Epoch 479/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9677 - loss: 0.5373 - val_accuracy: 0.6833 - val_loss: 1.1377\n",
            "Epoch 480/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9739 - loss: 0.5253 - val_accuracy: 0.6500 - val_loss: 1.1305\n",
            "Epoch 481/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9677 - loss: 0.5264 - val_accuracy: 0.6667 - val_loss: 1.1327\n",
            "Epoch 482/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9744 - loss: 0.5243 - val_accuracy: 0.6750 - val_loss: 1.1326\n",
            "Epoch 483/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9707 - loss: 0.5378 - val_accuracy: 0.6500 - val_loss: 1.1233\n",
            "Epoch 484/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9746 - loss: 0.5314 - val_accuracy: 0.6583 - val_loss: 1.1280\n",
            "Epoch 485/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.5310 - val_accuracy: 0.6667 - val_loss: 1.1410\n",
            "Epoch 486/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9762 - loss: 0.5288 - val_accuracy: 0.6667 - val_loss: 1.1234\n",
            "Epoch 487/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9763 - loss: 0.5318 - val_accuracy: 0.6667 - val_loss: 1.1105\n",
            "Epoch 488/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.5311 - val_accuracy: 0.6750 - val_loss: 1.1207\n",
            "Epoch 489/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9768 - loss: 0.5261 - val_accuracy: 0.6583 - val_loss: 1.1172\n",
            "Epoch 490/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9780 - loss: 0.5191 - val_accuracy: 0.6750 - val_loss: 1.1319\n",
            "Epoch 491/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.5206 - val_accuracy: 0.6833 - val_loss: 1.1357\n",
            "Epoch 492/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.5390 - val_accuracy: 0.6750 - val_loss: 1.1500\n",
            "Epoch 493/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.5071 - val_accuracy: 0.6667 - val_loss: 1.1370\n",
            "Epoch 494/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.5121 - val_accuracy: 0.6833 - val_loss: 1.1204\n",
            "Epoch 495/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.5186 - val_accuracy: 0.6583 - val_loss: 1.1182\n",
            "Epoch 496/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9761 - loss: 0.5172 - val_accuracy: 0.6667 - val_loss: 1.1344\n",
            "Epoch 497/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9801 - loss: 0.5228 - val_accuracy: 0.6750 - val_loss: 1.1289\n",
            "Epoch 498/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.5222 - val_accuracy: 0.6500 - val_loss: 1.1268\n",
            "Epoch 499/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9760 - loss: 0.5151 - val_accuracy: 0.6750 - val_loss: 1.1326\n",
            "Epoch 500/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.5199 - val_accuracy: 0.6417 - val_loss: 1.1326\n",
            "Epoch 501/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9763 - loss: 0.5171 - val_accuracy: 0.6667 - val_loss: 1.1368\n",
            "Epoch 502/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9745 - loss: 0.5235 - val_accuracy: 0.6750 - val_loss: 1.1219\n",
            "Epoch 503/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.5209 - val_accuracy: 0.6667 - val_loss: 1.1163\n",
            "Epoch 504/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9730 - loss: 0.5217 - val_accuracy: 0.6583 - val_loss: 1.1296\n",
            "Epoch 505/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9763 - loss: 0.5122 - val_accuracy: 0.6667 - val_loss: 1.1219\n",
            "Epoch 506/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9682 - loss: 0.5230 - val_accuracy: 0.6667 - val_loss: 1.1180\n",
            "Epoch 507/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9827 - loss: 0.5156 - val_accuracy: 0.6667 - val_loss: 1.1368\n",
            "Epoch 508/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9775 - loss: 0.5219 - val_accuracy: 0.6667 - val_loss: 1.1205\n",
            "Epoch 509/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9827 - loss: 0.5112 - val_accuracy: 0.6917 - val_loss: 1.1096\n",
            "Epoch 510/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.4991 - val_accuracy: 0.6917 - val_loss: 1.1006\n",
            "Epoch 511/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9727 - loss: 0.5108 - val_accuracy: 0.6833 - val_loss: 1.1011\n",
            "Epoch 512/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9803 - loss: 0.5114 - val_accuracy: 0.6833 - val_loss: 1.1139\n",
            "Epoch 513/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9804 - loss: 0.5107 - val_accuracy: 0.6750 - val_loss: 1.0942\n",
            "Epoch 514/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9705 - loss: 0.5158 - val_accuracy: 0.6917 - val_loss: 1.1111\n",
            "Epoch 515/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9746 - loss: 0.5046 - val_accuracy: 0.6833 - val_loss: 1.1076\n",
            "Epoch 516/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.5061 - val_accuracy: 0.6833 - val_loss: 1.1157\n",
            "Epoch 517/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.5022 - val_accuracy: 0.6750 - val_loss: 1.1328\n",
            "Epoch 518/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9800 - loss: 0.5043 - val_accuracy: 0.6833 - val_loss: 1.1230\n",
            "Epoch 519/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9776 - loss: 0.5100 - val_accuracy: 0.6833 - val_loss: 1.1151\n",
            "Epoch 520/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9766 - loss: 0.5059 - val_accuracy: 0.6833 - val_loss: 1.1292\n",
            "Epoch 521/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9753 - loss: 0.5020 - val_accuracy: 0.6750 - val_loss: 1.1420\n",
            "Epoch 522/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.4973 - val_accuracy: 0.6667 - val_loss: 1.1270\n",
            "Epoch 523/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.5002 - val_accuracy: 0.7000 - val_loss: 1.1087\n",
            "Epoch 524/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9811 - loss: 0.5019 - val_accuracy: 0.6750 - val_loss: 1.1072\n",
            "Epoch 525/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9771 - loss: 0.4984 - val_accuracy: 0.6917 - val_loss: 1.1128\n",
            "Epoch 526/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9745 - loss: 0.5057 - val_accuracy: 0.6750 - val_loss: 1.1175\n",
            "Epoch 527/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.5055 - val_accuracy: 0.6833 - val_loss: 1.1254\n",
            "Epoch 528/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.5043 - val_accuracy: 0.6750 - val_loss: 1.1207\n",
            "Epoch 529/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.4964 - val_accuracy: 0.6750 - val_loss: 1.1119\n",
            "Epoch 530/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.5004 - val_accuracy: 0.6583 - val_loss: 1.1335\n",
            "Epoch 531/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9675 - loss: 0.5025 - val_accuracy: 0.6583 - val_loss: 1.1100\n",
            "Epoch 532/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.5010 - val_accuracy: 0.6917 - val_loss: 1.1016\n",
            "Epoch 533/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9816 - loss: 0.4904 - val_accuracy: 0.6750 - val_loss: 1.1161\n",
            "Epoch 534/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.4971 - val_accuracy: 0.6667 - val_loss: 1.1228\n",
            "Epoch 535/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9687 - loss: 0.5099 - val_accuracy: 0.6750 - val_loss: 1.1330\n",
            "Epoch 536/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9767 - loss: 0.4968 - val_accuracy: 0.6750 - val_loss: 1.1290\n",
            "Epoch 537/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.4976 - val_accuracy: 0.6667 - val_loss: 1.1096\n",
            "Epoch 538/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9795 - loss: 0.4915 - val_accuracy: 0.7000 - val_loss: 1.1121\n",
            "Epoch 539/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.4890 - val_accuracy: 0.6833 - val_loss: 1.1127\n",
            "Epoch 540/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.4909 - val_accuracy: 0.6833 - val_loss: 1.1235\n",
            "Epoch 541/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9903 - loss: 0.4861 - val_accuracy: 0.6833 - val_loss: 1.1323\n",
            "Epoch 542/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.4917 - val_accuracy: 0.6750 - val_loss: 1.1200\n",
            "Epoch 543/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9756 - loss: 0.4895 - val_accuracy: 0.6917 - val_loss: 1.1290\n",
            "Epoch 544/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.4829 - val_accuracy: 0.6500 - val_loss: 1.1332\n",
            "Epoch 545/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.4899 - val_accuracy: 0.6667 - val_loss: 1.1363\n",
            "Epoch 546/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9884 - loss: 0.4876 - val_accuracy: 0.7000 - val_loss: 1.1120\n",
            "Epoch 547/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.4892 - val_accuracy: 0.6667 - val_loss: 1.1416\n",
            "Epoch 548/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9784 - loss: 0.4872 - val_accuracy: 0.6417 - val_loss: 1.1215\n",
            "Epoch 549/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.4761 - val_accuracy: 0.6833 - val_loss: 1.1281\n",
            "Epoch 550/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.4782 - val_accuracy: 0.6667 - val_loss: 1.1352\n",
            "Epoch 551/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.4785 - val_accuracy: 0.6833 - val_loss: 1.1247\n",
            "Epoch 552/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9747 - loss: 0.4877 - val_accuracy: 0.6500 - val_loss: 1.1259\n",
            "Epoch 553/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.4897 - val_accuracy: 0.7250 - val_loss: 1.0974\n",
            "Epoch 554/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.4735 - val_accuracy: 0.7083 - val_loss: 1.1316\n",
            "Epoch 555/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.4917 - val_accuracy: 0.6750 - val_loss: 1.1251\n",
            "Epoch 556/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.4900 - val_accuracy: 0.6750 - val_loss: 1.1125\n",
            "Epoch 557/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9797 - loss: 0.4871 - val_accuracy: 0.6667 - val_loss: 1.1204\n",
            "Epoch 558/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.4766 - val_accuracy: 0.6750 - val_loss: 1.1076\n",
            "Epoch 559/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9757 - loss: 0.4820 - val_accuracy: 0.6917 - val_loss: 1.1046\n",
            "Epoch 560/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9891 - loss: 0.4793 - val_accuracy: 0.6917 - val_loss: 1.0975\n",
            "Epoch 561/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 0.4780 - val_accuracy: 0.7000 - val_loss: 1.1182\n",
            "Epoch 562/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 0.4733 - val_accuracy: 0.6667 - val_loss: 1.1116\n",
            "Epoch 563/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9811 - loss: 0.4733 - val_accuracy: 0.7000 - val_loss: 1.1070\n",
            "Epoch 564/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9762 - loss: 0.4766 - val_accuracy: 0.7000 - val_loss: 1.0876\n",
            "Epoch 565/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.4788 - val_accuracy: 0.6833 - val_loss: 1.1021\n",
            "Epoch 566/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.4817 - val_accuracy: 0.6833 - val_loss: 1.1154\n",
            "Epoch 567/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9771 - loss: 0.4818 - val_accuracy: 0.7000 - val_loss: 1.1021\n",
            "Epoch 568/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9775 - loss: 0.4786 - val_accuracy: 0.6833 - val_loss: 1.1065\n",
            "Epoch 569/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.4728 - val_accuracy: 0.6917 - val_loss: 1.1095\n",
            "Epoch 570/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9795 - loss: 0.4771 - val_accuracy: 0.7083 - val_loss: 1.1044\n",
            "Epoch 571/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9827 - loss: 0.4758 - val_accuracy: 0.6667 - val_loss: 1.0927\n",
            "Epoch 572/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9897 - loss: 0.4800 - val_accuracy: 0.6667 - val_loss: 1.0918\n",
            "Epoch 573/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9807 - loss: 0.4762 - val_accuracy: 0.6750 - val_loss: 1.0881\n",
            "Epoch 574/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.4613 - val_accuracy: 0.6833 - val_loss: 1.0894\n",
            "Epoch 575/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9799 - loss: 0.4641 - val_accuracy: 0.6833 - val_loss: 1.0793\n",
            "Epoch 576/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.4664 - val_accuracy: 0.6583 - val_loss: 1.0973\n",
            "Epoch 577/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9871 - loss: 0.4681 - val_accuracy: 0.6750 - val_loss: 1.0875\n",
            "Epoch 578/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.4684 - val_accuracy: 0.6750 - val_loss: 1.1081\n",
            "Epoch 579/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9858 - loss: 0.4664 - val_accuracy: 0.6417 - val_loss: 1.1102\n",
            "Epoch 580/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 0.4791 - val_accuracy: 0.6500 - val_loss: 1.1052\n",
            "Epoch 581/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.4699 - val_accuracy: 0.6750 - val_loss: 1.1072\n",
            "Epoch 582/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.4578 - val_accuracy: 0.6750 - val_loss: 1.0971\n",
            "Epoch 583/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.4636 - val_accuracy: 0.6833 - val_loss: 1.0990\n",
            "Epoch 584/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 0.4716 - val_accuracy: 0.6833 - val_loss: 1.0920\n",
            "Epoch 585/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9826 - loss: 0.4589 - val_accuracy: 0.6583 - val_loss: 1.0962\n",
            "Epoch 586/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.4691 - val_accuracy: 0.6667 - val_loss: 1.1104\n",
            "Epoch 587/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.4635 - val_accuracy: 0.6667 - val_loss: 1.1069\n",
            "Epoch 588/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.4592 - val_accuracy: 0.6750 - val_loss: 1.0920\n",
            "Epoch 589/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.4656 - val_accuracy: 0.6583 - val_loss: 1.0950\n",
            "Epoch 590/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.4629 - val_accuracy: 0.6750 - val_loss: 1.0875\n",
            "Epoch 591/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.4611 - val_accuracy: 0.6500 - val_loss: 1.0990\n",
            "Epoch 592/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.4690 - val_accuracy: 0.6750 - val_loss: 1.0876\n",
            "Epoch 593/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.4660 - val_accuracy: 0.6750 - val_loss: 1.0822\n",
            "Epoch 594/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.4590 - val_accuracy: 0.6667 - val_loss: 1.0872\n",
            "Epoch 595/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9754 - loss: 0.4666 - val_accuracy: 0.6750 - val_loss: 1.0910\n",
            "Epoch 596/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.4600 - val_accuracy: 0.6917 - val_loss: 1.0873\n",
            "Epoch 597/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.4612 - val_accuracy: 0.6750 - val_loss: 1.0976\n",
            "Epoch 598/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9866 - loss: 0.4626 - val_accuracy: 0.6583 - val_loss: 1.1040\n",
            "Epoch 599/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.4572 - val_accuracy: 0.7083 - val_loss: 1.0849\n",
            "Epoch 600/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.4514 - val_accuracy: 0.6667 - val_loss: 1.0864\n",
            "Epoch 601/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.4500 - val_accuracy: 0.6667 - val_loss: 1.0948\n",
            "Epoch 602/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.4546 - val_accuracy: 0.6833 - val_loss: 1.1006\n",
            "Epoch 603/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.4607 - val_accuracy: 0.6917 - val_loss: 1.0997\n",
            "Epoch 604/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9847 - loss: 0.4473 - val_accuracy: 0.7000 - val_loss: 1.0952\n",
            "Epoch 605/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.4573 - val_accuracy: 0.6750 - val_loss: 1.0966\n",
            "Epoch 606/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.4526 - val_accuracy: 0.6750 - val_loss: 1.0819\n",
            "Epoch 607/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9891 - loss: 0.4454 - val_accuracy: 0.6917 - val_loss: 1.0875\n",
            "Epoch 608/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.4541 - val_accuracy: 0.6917 - val_loss: 1.1038\n",
            "Epoch 609/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.4513 - val_accuracy: 0.7000 - val_loss: 1.0929\n",
            "Epoch 610/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.4503 - val_accuracy: 0.6833 - val_loss: 1.0939\n",
            "Epoch 611/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.4416 - val_accuracy: 0.6667 - val_loss: 1.1105\n",
            "Epoch 612/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.4466 - val_accuracy: 0.6833 - val_loss: 1.0866\n",
            "Epoch 613/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.4417 - val_accuracy: 0.6833 - val_loss: 1.1138\n",
            "Epoch 614/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.4467 - val_accuracy: 0.6917 - val_loss: 1.0950\n",
            "Epoch 615/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.4491 - val_accuracy: 0.6917 - val_loss: 1.1069\n",
            "Epoch 616/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.4575 - val_accuracy: 0.7000 - val_loss: 1.1030\n",
            "Epoch 617/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.4444 - val_accuracy: 0.6833 - val_loss: 1.0854\n",
            "Epoch 618/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.4513 - val_accuracy: 0.6583 - val_loss: 1.1020\n",
            "Epoch 619/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.4458 - val_accuracy: 0.6833 - val_loss: 1.0944\n",
            "Epoch 620/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.4418 - val_accuracy: 0.6750 - val_loss: 1.0973\n",
            "Epoch 621/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.4505 - val_accuracy: 0.6833 - val_loss: 1.1002\n",
            "Epoch 622/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.4476 - val_accuracy: 0.6750 - val_loss: 1.0976\n",
            "Epoch 623/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.4562 - val_accuracy: 0.7000 - val_loss: 1.0819\n",
            "Epoch 624/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.4462 - val_accuracy: 0.6500 - val_loss: 1.0639\n",
            "Epoch 625/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 0.4495 - val_accuracy: 0.6833 - val_loss: 1.0710\n",
            "Epoch 626/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9836 - loss: 0.4553 - val_accuracy: 0.6750 - val_loss: 1.0884\n",
            "Epoch 627/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9945 - loss: 0.4422 - val_accuracy: 0.7250 - val_loss: 1.0813\n",
            "Epoch 628/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.4403 - val_accuracy: 0.6500 - val_loss: 1.1413\n",
            "Epoch 629/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9928 - loss: 0.4368 - val_accuracy: 0.6667 - val_loss: 1.0983\n",
            "Epoch 630/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.4465 - val_accuracy: 0.7167 - val_loss: 1.0728\n",
            "Epoch 631/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.4464 - val_accuracy: 0.6750 - val_loss: 1.0991\n",
            "Epoch 632/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.4342 - val_accuracy: 0.6750 - val_loss: 1.0805\n",
            "Epoch 633/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.4455 - val_accuracy: 0.6750 - val_loss: 1.0920\n",
            "Epoch 634/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.4379 - val_accuracy: 0.6833 - val_loss: 1.1076\n",
            "Epoch 635/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9875 - loss: 0.4369 - val_accuracy: 0.7083 - val_loss: 1.0793\n",
            "Epoch 636/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.4479 - val_accuracy: 0.7000 - val_loss: 1.0747\n",
            "Epoch 637/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.4408 - val_accuracy: 0.6917 - val_loss: 1.0796\n",
            "Epoch 638/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.4421 - val_accuracy: 0.7083 - val_loss: 1.0710\n",
            "Epoch 639/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.4379 - val_accuracy: 0.6500 - val_loss: 1.0848\n",
            "Epoch 640/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.4360 - val_accuracy: 0.6667 - val_loss: 1.0858\n",
            "Epoch 641/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9900 - loss: 0.4304 - val_accuracy: 0.6667 - val_loss: 1.0871\n",
            "Epoch 642/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.4361 - val_accuracy: 0.6417 - val_loss: 1.0974\n",
            "Epoch 643/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 0.4415 - val_accuracy: 0.6583 - val_loss: 1.0840\n",
            "Epoch 644/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.4292 - val_accuracy: 0.6917 - val_loss: 1.0822\n",
            "Epoch 645/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.4358 - val_accuracy: 0.6500 - val_loss: 1.0902\n",
            "Epoch 646/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.4354 - val_accuracy: 0.6833 - val_loss: 1.0997\n",
            "Epoch 647/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9847 - loss: 0.4362 - val_accuracy: 0.6750 - val_loss: 1.0923\n",
            "Epoch 648/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9821 - loss: 0.4425 - val_accuracy: 0.6750 - val_loss: 1.0954\n",
            "Epoch 649/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.4353 - val_accuracy: 0.6583 - val_loss: 1.0969\n",
            "Epoch 650/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.4337 - val_accuracy: 0.6667 - val_loss: 1.1052\n",
            "Epoch 651/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9825 - loss: 0.4369 - val_accuracy: 0.6833 - val_loss: 1.0898\n",
            "Epoch 652/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.4290 - val_accuracy: 0.7083 - val_loss: 1.0908\n",
            "Epoch 653/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.4238 - val_accuracy: 0.7167 - val_loss: 1.0727\n",
            "Epoch 654/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.4393 - val_accuracy: 0.6750 - val_loss: 1.0797\n",
            "Epoch 655/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.4276 - val_accuracy: 0.6833 - val_loss: 1.0782\n",
            "Epoch 656/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.4322 - val_accuracy: 0.6667 - val_loss: 1.0769\n",
            "Epoch 657/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.4238 - val_accuracy: 0.6667 - val_loss: 1.0841\n",
            "Epoch 658/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.4319 - val_accuracy: 0.6583 - val_loss: 1.1091\n",
            "Epoch 659/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9906 - loss: 0.4323 - val_accuracy: 0.6750 - val_loss: 1.0816\n",
            "Epoch 660/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9901 - loss: 0.4301 - val_accuracy: 0.6583 - val_loss: 1.0920\n",
            "Epoch 661/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.4200 - val_accuracy: 0.6667 - val_loss: 1.0913\n",
            "Epoch 662/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9907 - loss: 0.4312 - val_accuracy: 0.6917 - val_loss: 1.0859\n",
            "Epoch 663/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.4206 - val_accuracy: 0.6750 - val_loss: 1.0753\n",
            "Epoch 664/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9783 - loss: 0.4382 - val_accuracy: 0.6583 - val_loss: 1.0821\n",
            "Epoch 665/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.4349 - val_accuracy: 0.6833 - val_loss: 1.0870\n",
            "Epoch 666/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.4246 - val_accuracy: 0.6833 - val_loss: 1.0615\n",
            "Epoch 667/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.4172 - val_accuracy: 0.7083 - val_loss: 1.0589\n",
            "Epoch 668/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9895 - loss: 0.4328 - val_accuracy: 0.6500 - val_loss: 1.0908\n",
            "Epoch 669/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.4223 - val_accuracy: 0.6917 - val_loss: 1.0761\n",
            "Epoch 670/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9870 - loss: 0.4252 - val_accuracy: 0.6833 - val_loss: 1.0804\n",
            "Epoch 671/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9883 - loss: 0.4309 - val_accuracy: 0.6583 - val_loss: 1.0826\n",
            "Epoch 672/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.4248 - val_accuracy: 0.6333 - val_loss: 1.0835\n",
            "Epoch 673/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9895 - loss: 0.4239 - val_accuracy: 0.6833 - val_loss: 1.0748\n",
            "Epoch 674/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.4190 - val_accuracy: 0.7167 - val_loss: 1.0673\n",
            "Epoch 675/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.4144 - val_accuracy: 0.6500 - val_loss: 1.0817\n",
            "Epoch 676/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.4173 - val_accuracy: 0.6917 - val_loss: 1.0700\n",
            "Epoch 677/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.4185 - val_accuracy: 0.6833 - val_loss: 1.0910\n",
            "Epoch 678/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.4222 - val_accuracy: 0.6417 - val_loss: 1.0998\n",
            "Epoch 679/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.4219 - val_accuracy: 0.6667 - val_loss: 1.0931\n",
            "Epoch 680/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.4188 - val_accuracy: 0.6750 - val_loss: 1.0728\n",
            "Epoch 681/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.4123 - val_accuracy: 0.7000 - val_loss: 1.0743\n",
            "Epoch 682/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.4189 - val_accuracy: 0.6833 - val_loss: 1.0761\n",
            "Epoch 683/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.4234 - val_accuracy: 0.6583 - val_loss: 1.0942\n",
            "Epoch 684/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.4162 - val_accuracy: 0.6833 - val_loss: 1.0700\n",
            "Epoch 685/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9839 - loss: 0.4216 - val_accuracy: 0.6583 - val_loss: 1.0936\n",
            "Epoch 686/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.4203 - val_accuracy: 0.6833 - val_loss: 1.0734\n",
            "Epoch 687/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.4185 - val_accuracy: 0.6583 - val_loss: 1.0790\n",
            "Epoch 688/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.4113 - val_accuracy: 0.6833 - val_loss: 1.0668\n",
            "Epoch 689/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9860 - loss: 0.4199 - val_accuracy: 0.6750 - val_loss: 1.0781\n",
            "Epoch 690/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.4136 - val_accuracy: 0.6667 - val_loss: 1.0857\n",
            "Epoch 691/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.4143 - val_accuracy: 0.6917 - val_loss: 1.0691\n",
            "Epoch 692/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.4150 - val_accuracy: 0.6667 - val_loss: 1.0768\n",
            "Epoch 693/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.4123 - val_accuracy: 0.6667 - val_loss: 1.0764\n",
            "Epoch 694/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.4080 - val_accuracy: 0.7000 - val_loss: 1.0645\n",
            "Epoch 695/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.4128 - val_accuracy: 0.6583 - val_loss: 1.0861\n",
            "Epoch 696/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.4115 - val_accuracy: 0.6750 - val_loss: 1.0726\n",
            "Epoch 697/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.4086 - val_accuracy: 0.6833 - val_loss: 1.0690\n",
            "Epoch 698/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.4092 - val_accuracy: 0.6500 - val_loss: 1.0802\n",
            "Epoch 699/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9897 - loss: 0.4230 - val_accuracy: 0.6667 - val_loss: 1.0677\n",
            "Epoch 700/700\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.4112 - val_accuracy: 0.6417 - val_loss: 1.0846\n",
            "\n",
            "--- FINAL EVALUATION ---\n",
            "Test Accuracy: 40.42%\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n",
            "Test F1-Score: 0.3809\n",
            "\n",
            "Confusion Matrix:\n",
            "[[24  0  6  1  0  0  0  1]\n",
            " [ 0  5  9  1  3  8  4  2]\n",
            " [ 8  0 16  1  3  1  1  2]\n",
            " [ 3  0  1 17  6  0  0  5]\n",
            " [ 7  1  5  4  4  0  2  9]\n",
            " [ 2  1  3  0  2  4  3  1]\n",
            " [ 8  0  7  4  4  2  7  0]\n",
            " [ 6  0  2  0  3  0  1 20]]\n",
            "Class Order: ['angry' 'calm' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "\n",
            "If this is significantly lower than 71%, you have successfully disproven the model's generalization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EMO-DB**"
      ],
      "metadata": {
        "id": "svRbGYbC6yRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "# --- Configuration (Issa et al. 2020) ---\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.00001\n",
        "EPOCHS = 300 # Paper mentions 300 for Model A/B [cite: 258]\n",
        "DATA_PATH = \"/content/drive/MyDrive/DeepLearning/Paper_9_Replication_Features/\"\n",
        "\n",
        "# Set seeds\n",
        "def set_seed(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ==========================================\n",
        "# 1. MODEL B ARCHITECTURE\n",
        "# ==========================================\n",
        "# [cite_start]Based on Section 4.2.2 [cite: 260-262, 348]\n",
        "def build_model_b(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # [cite_start]Block 1 (from Model A base) [cite: 257]\n",
        "    x = layers.Conv1D(256, 5, strides=1, padding='same')(inputs)\n",
        "    # [cite_start]Note: Model A removed BN here [cite: 257]\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.MaxPooling1D(pool_size=8)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # [cite_start]Modification for Model B: \"Additional convolution layer before flattening\" [cite: 348]\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Flatten & Dropout\n",
        "    x = layers.Flatten()(x)\n",
        "    # [cite_start]Model A had dropout 0.2 here [cite: 257]\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Output Layer (5 Classes)\n",
        "    x = layers.Dense(num_classes)(x)\n",
        "\n",
        "    # [cite_start]Modification for Model B: \"Dropout 0.25 after fully connected layer\" [cite: 348]\n",
        "    # This is unusual, but we place it before Softmax to match description\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    outputs = layers.Activation('softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs, name=\"Issa_Model_B_EMODB\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# 2. DATA LOADING\n",
        "# ==========================================\n",
        "print(\"Loading EMO-DB data...\")\n",
        "X = np.load(os.path.join(DATA_PATH, 'EMODB_X.npy'))\n",
        "y = np.load(os.path.join(DATA_PATH, 'EMODB_y.npy'))\n",
        "groups = np.load(os.path.join(DATA_PATH, 'EMODB_groups.npy'))\n",
        "\n",
        "# Encode Labels (Should be 5 classes: Angry, Fear, Happiness, Neutral, Sadness)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "classes = le.classes_\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "# Reshape for 1D CNN: (N, 193) -> (N, 193, 1)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# [THE CONTROL SWITCH]\n",
        "# 'REPLICATION' = Random Split (Replicating the 96% claim)\n",
        "# 'DISPROVE'    = Speaker Strict (Holding out Actors 13 & 14)\n",
        "EXPERIMENT_MODE = 'REPLICATION'\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "if EXPERIMENT_MODE == 'REPLICATION':\n",
        "    print(f\"\\n>>> MODE: REPLICATION (Random Split) <<<\")\n",
        "    print(\"Warning: This allows Data Leakage (Augmented versions of Test files are in Train).\")\n",
        "    # Random split matching paper's likely method\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42, shuffle=True)\n",
        "    # Create tiny Val set from Train\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "elif EXPERIMENT_MODE == 'DISPROVE':\n",
        "    print(f\"\\n>>> MODE: DISPROVE (Speaker Strict) <<<\")\n",
        "    # Hold out Speakers 13 and 14 (Arbitrary choice, but consistent)\n",
        "    # Note: IDs are strings \"03\", \"13\", etc.\n",
        "    test_actors = ['13', '14']\n",
        "    print(f\"Testing on Actors: {test_actors}\")\n",
        "\n",
        "    test_mask = np.isin(groups, test_actors)\n",
        "\n",
        "    X_test = X[test_mask]\n",
        "    y_test = y_enc[test_mask]\n",
        "\n",
        "    X_train_full = X[~test_mask]\n",
        "    y_train_full = y_enc[~test_mask]\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING\n",
        "# ==========================================\n",
        "\n",
        "model = build_model_b(input_shape=(193, 1), num_classes=len(classes))\n",
        "\n",
        "# [cite_start]Optimizer: RMSProp, lr=0.00001 [cite: 232]\n",
        "opt = optimizers.RMSprop(learning_rate=LEARNING_RATE)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
        "\n",
        "print(\"\\nStarting Training...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 4. EVALUATION\n",
        "# ==========================================\n",
        "print(\"\\n--- FINAL EVALUATION ---\")\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Detailed Metrics\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Test F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(f\"Class Order: {classes}\")\n",
        "\n",
        "if EXPERIMENT_MODE == 'REPLICATION':\n",
        "    print(f\"\\nTarget to match: ~96.34% (Paper Result) [cite: 349]\")\n",
        "elif EXPERIMENT_MODE == 'DISPROVE':\n",
        "    print(f\"\\nIf this is significantly lower than 96%, you have successfully invalidated Model B.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ksWJN5W61Do",
        "outputId": "16aecccb-8267-4db7-cbe0-d7b3d5291f94"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading EMO-DB data...\n",
            "Classes: ['Angry' 'Fear' 'Happiness' 'Neutral' 'Sadness']\n",
            "\n",
            ">>> MODE: REPLICATION (Random Split) <<<\n",
            "Warning: This allows Data Leakage (Augmented versions of Test files are in Train).\n",
            "Train: (1468, 193, 1), Val: (164, 193, 1), Test: (408, 193, 1)\n",
            "\n",
            "Starting Training...\n",
            "Epoch 1/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.2577 - loss: 2.0371 - val_accuracy: 0.4024 - val_loss: 1.3791\n",
            "Epoch 2/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3748 - loss: 1.5054 - val_accuracy: 0.5000 - val_loss: 1.2255\n",
            "Epoch 3/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4443 - loss: 1.3529 - val_accuracy: 0.5671 - val_loss: 1.1272\n",
            "Epoch 4/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4975 - loss: 1.2172 - val_accuracy: 0.5976 - val_loss: 1.0634\n",
            "Epoch 5/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5135 - loss: 1.1876 - val_accuracy: 0.6463 - val_loss: 0.9970\n",
            "Epoch 6/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5932 - loss: 1.0734 - val_accuracy: 0.6890 - val_loss: 0.9549\n",
            "Epoch 7/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5469 - loss: 1.0710 - val_accuracy: 0.7134 - val_loss: 0.9187\n",
            "Epoch 8/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5439 - loss: 1.0692 - val_accuracy: 0.7073 - val_loss: 0.8853\n",
            "Epoch 9/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5768 - loss: 1.0067 - val_accuracy: 0.7134 - val_loss: 0.8575\n",
            "Epoch 10/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5953 - loss: 0.9725 - val_accuracy: 0.7561 - val_loss: 0.8278\n",
            "Epoch 11/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5974 - loss: 0.9859 - val_accuracy: 0.7195 - val_loss: 0.8134\n",
            "Epoch 12/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6011 - loss: 0.9458 - val_accuracy: 0.7683 - val_loss: 0.7807\n",
            "Epoch 13/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6113 - loss: 0.9624 - val_accuracy: 0.7378 - val_loss: 0.7664\n",
            "Epoch 14/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6467 - loss: 0.9142 - val_accuracy: 0.7805 - val_loss: 0.7408\n",
            "Epoch 15/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5987 - loss: 0.9262 - val_accuracy: 0.7500 - val_loss: 0.7355\n",
            "Epoch 16/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6207 - loss: 0.8799 - val_accuracy: 0.7744 - val_loss: 0.7141\n",
            "Epoch 17/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6295 - loss: 0.8951 - val_accuracy: 0.7927 - val_loss: 0.6982\n",
            "Epoch 18/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6439 - loss: 0.8561 - val_accuracy: 0.8049 - val_loss: 0.6850\n",
            "Epoch 19/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6618 - loss: 0.8296 - val_accuracy: 0.7927 - val_loss: 0.6720\n",
            "Epoch 20/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6722 - loss: 0.8181 - val_accuracy: 0.7988 - val_loss: 0.6584\n",
            "Epoch 21/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6603 - loss: 0.8280 - val_accuracy: 0.8049 - val_loss: 0.6431\n",
            "Epoch 22/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6619 - loss: 0.8128 - val_accuracy: 0.8110 - val_loss: 0.6434\n",
            "Epoch 23/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6612 - loss: 0.8119 - val_accuracy: 0.8110 - val_loss: 0.6265\n",
            "Epoch 24/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6691 - loss: 0.7640 - val_accuracy: 0.8171 - val_loss: 0.6164\n",
            "Epoch 25/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7066 - loss: 0.7692 - val_accuracy: 0.8293 - val_loss: 0.6021\n",
            "Epoch 26/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6996 - loss: 0.7633 - val_accuracy: 0.8293 - val_loss: 0.5955\n",
            "Epoch 27/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6581 - loss: 0.7977 - val_accuracy: 0.8293 - val_loss: 0.5886\n",
            "Epoch 28/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6898 - loss: 0.7804 - val_accuracy: 0.8476 - val_loss: 0.5779\n",
            "Epoch 29/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6950 - loss: 0.7442 - val_accuracy: 0.8354 - val_loss: 0.5709\n",
            "Epoch 30/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6890 - loss: 0.7423 - val_accuracy: 0.8415 - val_loss: 0.5583\n",
            "Epoch 31/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6851 - loss: 0.7346 - val_accuracy: 0.8232 - val_loss: 0.5522\n",
            "Epoch 32/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6838 - loss: 0.7349 - val_accuracy: 0.8293 - val_loss: 0.5457\n",
            "Epoch 33/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7041 - loss: 0.7314 - val_accuracy: 0.8537 - val_loss: 0.5318\n",
            "Epoch 34/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6971 - loss: 0.7108 - val_accuracy: 0.8232 - val_loss: 0.5380\n",
            "Epoch 35/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7099 - loss: 0.6861 - val_accuracy: 0.8659 - val_loss: 0.5153\n",
            "Epoch 36/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7045 - loss: 0.7161 - val_accuracy: 0.8659 - val_loss: 0.5110\n",
            "Epoch 37/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6915 - loss: 0.7094 - val_accuracy: 0.8720 - val_loss: 0.5056\n",
            "Epoch 38/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7152 - loss: 0.6949 - val_accuracy: 0.8720 - val_loss: 0.4947\n",
            "Epoch 39/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7262 - loss: 0.6815 - val_accuracy: 0.8659 - val_loss: 0.4879\n",
            "Epoch 40/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7071 - loss: 0.6862 - val_accuracy: 0.8720 - val_loss: 0.4822\n",
            "Epoch 41/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7385 - loss: 0.6519 - val_accuracy: 0.8720 - val_loss: 0.4827\n",
            "Epoch 42/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7520 - loss: 0.6480 - val_accuracy: 0.8598 - val_loss: 0.4780\n",
            "Epoch 43/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7332 - loss: 0.6742 - val_accuracy: 0.8780 - val_loss: 0.4670\n",
            "Epoch 44/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7160 - loss: 0.6729 - val_accuracy: 0.8476 - val_loss: 0.4565\n",
            "Epoch 45/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7320 - loss: 0.6622 - val_accuracy: 0.8598 - val_loss: 0.4579\n",
            "Epoch 46/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7377 - loss: 0.6383 - val_accuracy: 0.8720 - val_loss: 0.4490\n",
            "Epoch 47/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7315 - loss: 0.6375 - val_accuracy: 0.8780 - val_loss: 0.4417\n",
            "Epoch 48/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7315 - loss: 0.6524 - val_accuracy: 0.8780 - val_loss: 0.4338\n",
            "Epoch 49/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7504 - loss: 0.6360 - val_accuracy: 0.8720 - val_loss: 0.4327\n",
            "Epoch 50/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7464 - loss: 0.6400 - val_accuracy: 0.8659 - val_loss: 0.4274\n",
            "Epoch 51/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7399 - loss: 0.6052 - val_accuracy: 0.8720 - val_loss: 0.4176\n",
            "Epoch 52/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7537 - loss: 0.5849 - val_accuracy: 0.8841 - val_loss: 0.4152\n",
            "Epoch 53/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7395 - loss: 0.6222 - val_accuracy: 0.8902 - val_loss: 0.4102\n",
            "Epoch 54/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7710 - loss: 0.5694 - val_accuracy: 0.8720 - val_loss: 0.4020\n",
            "Epoch 55/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7366 - loss: 0.6153 - val_accuracy: 0.8963 - val_loss: 0.4014\n",
            "Epoch 56/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7606 - loss: 0.5951 - val_accuracy: 0.8780 - val_loss: 0.3906\n",
            "Epoch 57/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7518 - loss: 0.5982 - val_accuracy: 0.8902 - val_loss: 0.3906\n",
            "Epoch 58/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7525 - loss: 0.5986 - val_accuracy: 0.8902 - val_loss: 0.3830\n",
            "Epoch 59/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7633 - loss: 0.5992 - val_accuracy: 0.9085 - val_loss: 0.3766\n",
            "Epoch 60/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7520 - loss: 0.5980 - val_accuracy: 0.8963 - val_loss: 0.3833\n",
            "Epoch 61/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7552 - loss: 0.5727 - val_accuracy: 0.8963 - val_loss: 0.3731\n",
            "Epoch 62/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7767 - loss: 0.5633 - val_accuracy: 0.9024 - val_loss: 0.3711\n",
            "Epoch 63/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7684 - loss: 0.5627 - val_accuracy: 0.8902 - val_loss: 0.3625\n",
            "Epoch 64/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7642 - loss: 0.5463 - val_accuracy: 0.9146 - val_loss: 0.3533\n",
            "Epoch 65/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7677 - loss: 0.5619 - val_accuracy: 0.9146 - val_loss: 0.3515\n",
            "Epoch 66/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7750 - loss: 0.5399 - val_accuracy: 0.9085 - val_loss: 0.3479\n",
            "Epoch 67/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7768 - loss: 0.5483 - val_accuracy: 0.9085 - val_loss: 0.3416\n",
            "Epoch 68/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7683 - loss: 0.5501 - val_accuracy: 0.9207 - val_loss: 0.3346\n",
            "Epoch 69/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7783 - loss: 0.5583 - val_accuracy: 0.9329 - val_loss: 0.3343\n",
            "Epoch 70/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8039 - loss: 0.4987 - val_accuracy: 0.9146 - val_loss: 0.3283\n",
            "Epoch 71/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7764 - loss: 0.5469 - val_accuracy: 0.9207 - val_loss: 0.3257\n",
            "Epoch 72/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7745 - loss: 0.5388 - val_accuracy: 0.9268 - val_loss: 0.3212\n",
            "Epoch 73/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7857 - loss: 0.5174 - val_accuracy: 0.9390 - val_loss: 0.3188\n",
            "Epoch 74/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8077 - loss: 0.5135 - val_accuracy: 0.9268 - val_loss: 0.3168\n",
            "Epoch 75/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8102 - loss: 0.5214 - val_accuracy: 0.9268 - val_loss: 0.3126\n",
            "Epoch 76/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7938 - loss: 0.5008 - val_accuracy: 0.9268 - val_loss: 0.3133\n",
            "Epoch 77/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7942 - loss: 0.4975 - val_accuracy: 0.9268 - val_loss: 0.3068\n",
            "Epoch 78/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7961 - loss: 0.4984 - val_accuracy: 0.9329 - val_loss: 0.3004\n",
            "Epoch 79/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7796 - loss: 0.4967 - val_accuracy: 0.9268 - val_loss: 0.2997\n",
            "Epoch 80/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7919 - loss: 0.5158 - val_accuracy: 0.9451 - val_loss: 0.2926\n",
            "Epoch 81/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8077 - loss: 0.5045 - val_accuracy: 0.9329 - val_loss: 0.2942\n",
            "Epoch 82/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7939 - loss: 0.5027 - val_accuracy: 0.9390 - val_loss: 0.2931\n",
            "Epoch 83/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8059 - loss: 0.4812 - val_accuracy: 0.9268 - val_loss: 0.2900\n",
            "Epoch 84/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8058 - loss: 0.4741 - val_accuracy: 0.9390 - val_loss: 0.2876\n",
            "Epoch 85/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7862 - loss: 0.5012 - val_accuracy: 0.9390 - val_loss: 0.2794\n",
            "Epoch 86/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8041 - loss: 0.4979 - val_accuracy: 0.9451 - val_loss: 0.2734\n",
            "Epoch 87/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8064 - loss: 0.4683 - val_accuracy: 0.9390 - val_loss: 0.2754\n",
            "Epoch 88/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7877 - loss: 0.4807 - val_accuracy: 0.9329 - val_loss: 0.2700\n",
            "Epoch 89/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8176 - loss: 0.4624 - val_accuracy: 0.9329 - val_loss: 0.2692\n",
            "Epoch 90/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7958 - loss: 0.4627 - val_accuracy: 0.9390 - val_loss: 0.2757\n",
            "Epoch 91/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8173 - loss: 0.4637 - val_accuracy: 0.9329 - val_loss: 0.2649\n",
            "Epoch 92/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8211 - loss: 0.4395 - val_accuracy: 0.9329 - val_loss: 0.2668\n",
            "Epoch 93/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8023 - loss: 0.4649 - val_accuracy: 0.9512 - val_loss: 0.2535\n",
            "Epoch 94/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8001 - loss: 0.4686 - val_accuracy: 0.9451 - val_loss: 0.2504\n",
            "Epoch 95/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8115 - loss: 0.4624 - val_accuracy: 0.9390 - val_loss: 0.2566\n",
            "Epoch 96/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8083 - loss: 0.4647 - val_accuracy: 0.9390 - val_loss: 0.2510\n",
            "Epoch 97/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.4657 - val_accuracy: 0.9390 - val_loss: 0.2441\n",
            "Epoch 98/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8023 - loss: 0.4583 - val_accuracy: 0.9512 - val_loss: 0.2404\n",
            "Epoch 99/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8345 - loss: 0.4446 - val_accuracy: 0.9573 - val_loss: 0.2347\n",
            "Epoch 100/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.4284 - val_accuracy: 0.9634 - val_loss: 0.2356\n",
            "Epoch 101/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8188 - loss: 0.4557 - val_accuracy: 0.9573 - val_loss: 0.2343\n",
            "Epoch 102/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8100 - loss: 0.4565 - val_accuracy: 0.9573 - val_loss: 0.2274\n",
            "Epoch 103/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8047 - loss: 0.4706 - val_accuracy: 0.9512 - val_loss: 0.2314\n",
            "Epoch 104/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8152 - loss: 0.4418 - val_accuracy: 0.9512 - val_loss: 0.2282\n",
            "Epoch 105/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8313 - loss: 0.4182 - val_accuracy: 0.9634 - val_loss: 0.2211\n",
            "Epoch 106/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7988 - loss: 0.4472 - val_accuracy: 0.9573 - val_loss: 0.2177\n",
            "Epoch 107/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8470 - loss: 0.4173 - val_accuracy: 0.9634 - val_loss: 0.2161\n",
            "Epoch 108/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.4388 - val_accuracy: 0.9512 - val_loss: 0.2181\n",
            "Epoch 109/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8347 - loss: 0.4285 - val_accuracy: 0.9512 - val_loss: 0.2122\n",
            "Epoch 110/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8178 - loss: 0.4244 - val_accuracy: 0.9512 - val_loss: 0.2135\n",
            "Epoch 111/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 0.4269 - val_accuracy: 0.9634 - val_loss: 0.2057\n",
            "Epoch 112/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8249 - loss: 0.4311 - val_accuracy: 0.9573 - val_loss: 0.2062\n",
            "Epoch 113/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8297 - loss: 0.3904 - val_accuracy: 0.9634 - val_loss: 0.2055\n",
            "Epoch 114/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8362 - loss: 0.3994 - val_accuracy: 0.9634 - val_loss: 0.2026\n",
            "Epoch 115/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8268 - loss: 0.4013 - val_accuracy: 0.9512 - val_loss: 0.2032\n",
            "Epoch 116/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8472 - loss: 0.3970 - val_accuracy: 0.9634 - val_loss: 0.1972\n",
            "Epoch 117/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8350 - loss: 0.4055 - val_accuracy: 0.9634 - val_loss: 0.1941\n",
            "Epoch 118/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8293 - loss: 0.4159 - val_accuracy: 0.9573 - val_loss: 0.1938\n",
            "Epoch 119/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8321 - loss: 0.4106 - val_accuracy: 0.9634 - val_loss: 0.1898\n",
            "Epoch 120/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 0.3872 - val_accuracy: 0.9756 - val_loss: 0.1876\n",
            "Epoch 121/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8235 - loss: 0.4108 - val_accuracy: 0.9634 - val_loss: 0.1901\n",
            "Epoch 122/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.3963 - val_accuracy: 0.9695 - val_loss: 0.1860\n",
            "Epoch 123/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8308 - loss: 0.3868 - val_accuracy: 0.9695 - val_loss: 0.1828\n",
            "Epoch 124/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8383 - loss: 0.3775 - val_accuracy: 0.9634 - val_loss: 0.1794\n",
            "Epoch 125/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8448 - loss: 0.3718 - val_accuracy: 0.9756 - val_loss: 0.1782\n",
            "Epoch 126/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8587 - loss: 0.3970 - val_accuracy: 0.9634 - val_loss: 0.1787\n",
            "Epoch 127/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8496 - loss: 0.3794 - val_accuracy: 0.9695 - val_loss: 0.1773\n",
            "Epoch 128/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8540 - loss: 0.3712 - val_accuracy: 0.9695 - val_loss: 0.1761\n",
            "Epoch 129/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8389 - loss: 0.3854 - val_accuracy: 0.9634 - val_loss: 0.1740\n",
            "Epoch 130/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8442 - loss: 0.3658 - val_accuracy: 0.9695 - val_loss: 0.1724\n",
            "Epoch 131/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8358 - loss: 0.3760 - val_accuracy: 0.9756 - val_loss: 0.1687\n",
            "Epoch 132/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8446 - loss: 0.3854 - val_accuracy: 0.9817 - val_loss: 0.1654\n",
            "Epoch 133/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8406 - loss: 0.3688 - val_accuracy: 0.9695 - val_loss: 0.1673\n",
            "Epoch 134/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8617 - loss: 0.3852 - val_accuracy: 0.9573 - val_loss: 0.1662\n",
            "Epoch 135/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8302 - loss: 0.3812 - val_accuracy: 0.9756 - val_loss: 0.1627\n",
            "Epoch 136/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8542 - loss: 0.3626 - val_accuracy: 0.9817 - val_loss: 0.1575\n",
            "Epoch 137/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8552 - loss: 0.3763 - val_accuracy: 0.9817 - val_loss: 0.1596\n",
            "Epoch 138/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8462 - loss: 0.3654 - val_accuracy: 0.9756 - val_loss: 0.1569\n",
            "Epoch 139/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8276 - loss: 0.3900 - val_accuracy: 0.9817 - val_loss: 0.1548\n",
            "Epoch 140/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - loss: 0.3486 - val_accuracy: 0.9878 - val_loss: 0.1505\n",
            "Epoch 141/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.3697 - val_accuracy: 0.9878 - val_loss: 0.1519\n",
            "Epoch 142/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8542 - loss: 0.3485 - val_accuracy: 0.9878 - val_loss: 0.1516\n",
            "Epoch 143/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8521 - loss: 0.3614 - val_accuracy: 0.9878 - val_loss: 0.1504\n",
            "Epoch 144/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8390 - loss: 0.3759 - val_accuracy: 0.9817 - val_loss: 0.1487\n",
            "Epoch 145/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.3507 - val_accuracy: 0.9878 - val_loss: 0.1465\n",
            "Epoch 146/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8524 - loss: 0.3409 - val_accuracy: 0.9817 - val_loss: 0.1430\n",
            "Epoch 147/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8614 - loss: 0.3497 - val_accuracy: 0.9817 - val_loss: 0.1448\n",
            "Epoch 148/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8576 - loss: 0.3431 - val_accuracy: 0.9817 - val_loss: 0.1445\n",
            "Epoch 149/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8542 - loss: 0.3607 - val_accuracy: 0.9817 - val_loss: 0.1392\n",
            "Epoch 150/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8460 - loss: 0.3363 - val_accuracy: 0.9878 - val_loss: 0.1381\n",
            "Epoch 151/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8424 - loss: 0.3377 - val_accuracy: 0.9756 - val_loss: 0.1358\n",
            "Epoch 152/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8524 - loss: 0.3632 - val_accuracy: 0.9756 - val_loss: 0.1374\n",
            "Epoch 153/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - loss: 0.3320 - val_accuracy: 0.9817 - val_loss: 0.1350\n",
            "Epoch 154/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8569 - loss: 0.3392 - val_accuracy: 0.9817 - val_loss: 0.1308\n",
            "Epoch 155/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8461 - loss: 0.3476 - val_accuracy: 0.9817 - val_loss: 0.1317\n",
            "Epoch 156/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8371 - loss: 0.3711 - val_accuracy: 0.9817 - val_loss: 0.1270\n",
            "Epoch 157/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8755 - loss: 0.3106 - val_accuracy: 0.9756 - val_loss: 0.1305\n",
            "Epoch 158/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8641 - loss: 0.3492 - val_accuracy: 0.9817 - val_loss: 0.1279\n",
            "Epoch 159/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8595 - loss: 0.3624 - val_accuracy: 0.9756 - val_loss: 0.1237\n",
            "Epoch 160/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8642 - loss: 0.3186 - val_accuracy: 0.9878 - val_loss: 0.1236\n",
            "Epoch 161/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8706 - loss: 0.3151 - val_accuracy: 0.9878 - val_loss: 0.1229\n",
            "Epoch 162/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8749 - loss: 0.3068 - val_accuracy: 0.9878 - val_loss: 0.1193\n",
            "Epoch 163/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8623 - loss: 0.3388 - val_accuracy: 0.9817 - val_loss: 0.1202\n",
            "Epoch 164/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8552 - loss: 0.3423 - val_accuracy: 0.9817 - val_loss: 0.1172\n",
            "Epoch 165/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8693 - loss: 0.3301 - val_accuracy: 0.9878 - val_loss: 0.1149\n",
            "Epoch 166/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8670 - loss: 0.3240 - val_accuracy: 0.9817 - val_loss: 0.1154\n",
            "Epoch 167/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8550 - loss: 0.3221 - val_accuracy: 0.9817 - val_loss: 0.1131\n",
            "Epoch 168/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8759 - loss: 0.3220 - val_accuracy: 0.9878 - val_loss: 0.1119\n",
            "Epoch 169/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8596 - loss: 0.3220 - val_accuracy: 0.9878 - val_loss: 0.1107\n",
            "Epoch 170/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8617 - loss: 0.3144 - val_accuracy: 0.9756 - val_loss: 0.1116\n",
            "Epoch 171/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8698 - loss: 0.3183 - val_accuracy: 0.9817 - val_loss: 0.1105\n",
            "Epoch 172/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8449 - loss: 0.3472 - val_accuracy: 0.9817 - val_loss: 0.1073\n",
            "Epoch 173/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8737 - loss: 0.3016 - val_accuracy: 0.9878 - val_loss: 0.1092\n",
            "Epoch 174/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8564 - loss: 0.3219 - val_accuracy: 0.9878 - val_loss: 0.1129\n",
            "Epoch 175/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8722 - loss: 0.2978 - val_accuracy: 0.9878 - val_loss: 0.1064\n",
            "Epoch 176/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8585 - loss: 0.3331 - val_accuracy: 0.9878 - val_loss: 0.1069\n",
            "Epoch 177/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8726 - loss: 0.3013 - val_accuracy: 0.9939 - val_loss: 0.1047\n",
            "Epoch 178/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8741 - loss: 0.2971 - val_accuracy: 0.9878 - val_loss: 0.1030\n",
            "Epoch 179/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8668 - loss: 0.3326 - val_accuracy: 0.9878 - val_loss: 0.1022\n",
            "Epoch 180/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8641 - loss: 0.2987 - val_accuracy: 0.9817 - val_loss: 0.0982\n",
            "Epoch 181/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8716 - loss: 0.2991 - val_accuracy: 0.9939 - val_loss: 0.0975\n",
            "Epoch 182/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8672 - loss: 0.3125 - val_accuracy: 0.9817 - val_loss: 0.1004\n",
            "Epoch 183/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8661 - loss: 0.3238 - val_accuracy: 0.9817 - val_loss: 0.0991\n",
            "Epoch 184/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8653 - loss: 0.3093 - val_accuracy: 0.9878 - val_loss: 0.0945\n",
            "Epoch 185/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8761 - loss: 0.2939 - val_accuracy: 0.9939 - val_loss: 0.0943\n",
            "Epoch 186/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8786 - loss: 0.2915 - val_accuracy: 0.9878 - val_loss: 0.0944\n",
            "Epoch 187/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8716 - loss: 0.2977 - val_accuracy: 0.9817 - val_loss: 0.0936\n",
            "Epoch 188/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8834 - loss: 0.3026 - val_accuracy: 0.9878 - val_loss: 0.0916\n",
            "Epoch 189/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.3017 - val_accuracy: 0.9817 - val_loss: 0.0915\n",
            "Epoch 190/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8897 - loss: 0.2719 - val_accuracy: 0.9817 - val_loss: 0.0912\n",
            "Epoch 191/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8755 - loss: 0.2924 - val_accuracy: 0.9817 - val_loss: 0.0915\n",
            "Epoch 192/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.2929 - val_accuracy: 0.9817 - val_loss: 0.0899\n",
            "Epoch 193/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8825 - loss: 0.2940 - val_accuracy: 0.9939 - val_loss: 0.0874\n",
            "Epoch 194/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8497 - loss: 0.3110 - val_accuracy: 0.9878 - val_loss: 0.0872\n",
            "Epoch 195/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8802 - loss: 0.2900 - val_accuracy: 0.9939 - val_loss: 0.0868\n",
            "Epoch 196/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8793 - loss: 0.2808 - val_accuracy: 0.9878 - val_loss: 0.0883\n",
            "Epoch 197/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8641 - loss: 0.3031 - val_accuracy: 0.9939 - val_loss: 0.0853\n",
            "Epoch 198/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8824 - loss: 0.2815 - val_accuracy: 0.9939 - val_loss: 0.0851\n",
            "Epoch 199/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8691 - loss: 0.3096 - val_accuracy: 0.9939 - val_loss: 0.0821\n",
            "Epoch 200/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8998 - loss: 0.2420 - val_accuracy: 0.9939 - val_loss: 0.0825\n",
            "Epoch 201/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8904 - loss: 0.2683 - val_accuracy: 0.9939 - val_loss: 0.0788\n",
            "Epoch 202/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8786 - loss: 0.2814 - val_accuracy: 0.9939 - val_loss: 0.0789\n",
            "Epoch 203/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8569 - loss: 0.3045 - val_accuracy: 0.9939 - val_loss: 0.0793\n",
            "Epoch 204/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8758 - loss: 0.2862 - val_accuracy: 0.9878 - val_loss: 0.0782\n",
            "Epoch 205/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8869 - loss: 0.2549 - val_accuracy: 0.9878 - val_loss: 0.0767\n",
            "Epoch 206/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8869 - loss: 0.2750 - val_accuracy: 0.9878 - val_loss: 0.0771\n",
            "Epoch 207/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.2768 - val_accuracy: 0.9878 - val_loss: 0.0780\n",
            "Epoch 208/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8808 - loss: 0.2963 - val_accuracy: 0.9939 - val_loss: 0.0729\n",
            "Epoch 209/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8718 - loss: 0.2724 - val_accuracy: 0.9939 - val_loss: 0.0734\n",
            "Epoch 210/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8840 - loss: 0.2615 - val_accuracy: 0.9939 - val_loss: 0.0712\n",
            "Epoch 211/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8833 - loss: 0.2763 - val_accuracy: 0.9939 - val_loss: 0.0746\n",
            "Epoch 212/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.2465 - val_accuracy: 0.9939 - val_loss: 0.0706\n",
            "Epoch 213/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8739 - loss: 0.2879 - val_accuracy: 0.9817 - val_loss: 0.0727\n",
            "Epoch 214/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8802 - loss: 0.2768 - val_accuracy: 0.9878 - val_loss: 0.0733\n",
            "Epoch 215/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8740 - loss: 0.2779 - val_accuracy: 0.9878 - val_loss: 0.0681\n",
            "Epoch 216/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8463 - loss: 0.2967 - val_accuracy: 0.9939 - val_loss: 0.0680\n",
            "Epoch 217/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8774 - loss: 0.2659 - val_accuracy: 0.9939 - val_loss: 0.0678\n",
            "Epoch 218/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8888 - loss: 0.2768 - val_accuracy: 0.9878 - val_loss: 0.0689\n",
            "Epoch 219/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8915 - loss: 0.2676 - val_accuracy: 0.9939 - val_loss: 0.0656\n",
            "Epoch 220/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8953 - loss: 0.2456 - val_accuracy: 1.0000 - val_loss: 0.0650\n",
            "Epoch 221/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8798 - loss: 0.2658 - val_accuracy: 0.9878 - val_loss: 0.0641\n",
            "Epoch 222/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8649 - loss: 0.2778 - val_accuracy: 0.9939 - val_loss: 0.0622\n",
            "Epoch 223/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8836 - loss: 0.2716 - val_accuracy: 0.9939 - val_loss: 0.0632\n",
            "Epoch 224/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8819 - loss: 0.2604 - val_accuracy: 1.0000 - val_loss: 0.0613\n",
            "Epoch 225/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8754 - loss: 0.2809 - val_accuracy: 0.9939 - val_loss: 0.0607\n",
            "Epoch 226/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8874 - loss: 0.2602 - val_accuracy: 1.0000 - val_loss: 0.0592\n",
            "Epoch 227/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8815 - loss: 0.2644 - val_accuracy: 0.9939 - val_loss: 0.0632\n",
            "Epoch 228/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8924 - loss: 0.2703 - val_accuracy: 0.9878 - val_loss: 0.0605\n",
            "Epoch 229/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8901 - loss: 0.2612 - val_accuracy: 1.0000 - val_loss: 0.0589\n",
            "Epoch 230/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8760 - loss: 0.2778 - val_accuracy: 1.0000 - val_loss: 0.0582\n",
            "Epoch 231/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8962 - loss: 0.2389 - val_accuracy: 1.0000 - val_loss: 0.0571\n",
            "Epoch 232/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8958 - loss: 0.2429 - val_accuracy: 1.0000 - val_loss: 0.0575\n",
            "Epoch 233/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8875 - loss: 0.2468 - val_accuracy: 1.0000 - val_loss: 0.0558\n",
            "Epoch 234/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9034 - loss: 0.2380 - val_accuracy: 1.0000 - val_loss: 0.0531\n",
            "Epoch 235/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8656 - loss: 0.2921 - val_accuracy: 1.0000 - val_loss: 0.0550\n",
            "Epoch 236/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8800 - loss: 0.2666 - val_accuracy: 1.0000 - val_loss: 0.0530\n",
            "Epoch 237/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8861 - loss: 0.2528 - val_accuracy: 1.0000 - val_loss: 0.0536\n",
            "Epoch 238/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8843 - loss: 0.2695 - val_accuracy: 1.0000 - val_loss: 0.0534\n",
            "Epoch 239/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8828 - loss: 0.2603 - val_accuracy: 1.0000 - val_loss: 0.0521\n",
            "Epoch 240/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8824 - loss: 0.2420 - val_accuracy: 1.0000 - val_loss: 0.0516\n",
            "Epoch 241/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8902 - loss: 0.2526 - val_accuracy: 1.0000 - val_loss: 0.0526\n",
            "Epoch 242/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8875 - loss: 0.2530 - val_accuracy: 0.9878 - val_loss: 0.0553\n",
            "Epoch 243/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8884 - loss: 0.2507 - val_accuracy: 1.0000 - val_loss: 0.0486\n",
            "Epoch 244/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9067 - loss: 0.2301 - val_accuracy: 1.0000 - val_loss: 0.0515\n",
            "Epoch 245/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8841 - loss: 0.2402 - val_accuracy: 1.0000 - val_loss: 0.0470\n",
            "Epoch 246/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8850 - loss: 0.2318 - val_accuracy: 1.0000 - val_loss: 0.0515\n",
            "Epoch 247/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8837 - loss: 0.2543 - val_accuracy: 1.0000 - val_loss: 0.0479\n",
            "Epoch 248/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9048 - loss: 0.2112 - val_accuracy: 1.0000 - val_loss: 0.0469\n",
            "Epoch 249/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8815 - loss: 0.2616 - val_accuracy: 1.0000 - val_loss: 0.0488\n",
            "Epoch 250/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8887 - loss: 0.2598 - val_accuracy: 1.0000 - val_loss: 0.0447\n",
            "Epoch 251/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9105 - loss: 0.2201 - val_accuracy: 1.0000 - val_loss: 0.0463\n",
            "Epoch 252/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.2611 - val_accuracy: 1.0000 - val_loss: 0.0443\n",
            "Epoch 253/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.2528 - val_accuracy: 0.9939 - val_loss: 0.0467\n",
            "Epoch 254/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8912 - loss: 0.2385 - val_accuracy: 1.0000 - val_loss: 0.0444\n",
            "Epoch 255/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8894 - loss: 0.2332 - val_accuracy: 1.0000 - val_loss: 0.0447\n",
            "Epoch 256/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8878 - loss: 0.2504 - val_accuracy: 1.0000 - val_loss: 0.0435\n",
            "Epoch 257/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8971 - loss: 0.2210 - val_accuracy: 1.0000 - val_loss: 0.0423\n",
            "Epoch 258/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8988 - loss: 0.2499 - val_accuracy: 1.0000 - val_loss: 0.0427\n",
            "Epoch 259/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8902 - loss: 0.2376 - val_accuracy: 1.0000 - val_loss: 0.0429\n",
            "Epoch 260/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8936 - loss: 0.2430 - val_accuracy: 1.0000 - val_loss: 0.0419\n",
            "Epoch 261/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 0.2165 - val_accuracy: 1.0000 - val_loss: 0.0388\n",
            "Epoch 262/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.2248 - val_accuracy: 1.0000 - val_loss: 0.0427\n",
            "Epoch 263/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8961 - loss: 0.2273 - val_accuracy: 1.0000 - val_loss: 0.0400\n",
            "Epoch 264/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9066 - loss: 0.2262 - val_accuracy: 1.0000 - val_loss: 0.0399\n",
            "Epoch 265/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8959 - loss: 0.2231 - val_accuracy: 1.0000 - val_loss: 0.0386\n",
            "Epoch 266/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8907 - loss: 0.2179 - val_accuracy: 1.0000 - val_loss: 0.0378\n",
            "Epoch 267/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.2267 - val_accuracy: 1.0000 - val_loss: 0.0382\n",
            "Epoch 268/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.2062 - val_accuracy: 1.0000 - val_loss: 0.0412\n",
            "Epoch 269/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9005 - loss: 0.2121 - val_accuracy: 1.0000 - val_loss: 0.0402\n",
            "Epoch 270/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8755 - loss: 0.2491 - val_accuracy: 1.0000 - val_loss: 0.0376\n",
            "Epoch 271/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8951 - loss: 0.2331 - val_accuracy: 1.0000 - val_loss: 0.0383\n",
            "Epoch 272/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8866 - loss: 0.2323 - val_accuracy: 1.0000 - val_loss: 0.0402\n",
            "Epoch 273/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9204 - loss: 0.2027 - val_accuracy: 1.0000 - val_loss: 0.0385\n",
            "Epoch 274/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8933 - loss: 0.2151 - val_accuracy: 1.0000 - val_loss: 0.0354\n",
            "Epoch 275/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8919 - loss: 0.2231 - val_accuracy: 1.0000 - val_loss: 0.0365\n",
            "Epoch 276/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9082 - loss: 0.2304 - val_accuracy: 1.0000 - val_loss: 0.0356\n",
            "Epoch 277/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8925 - loss: 0.2496 - val_accuracy: 1.0000 - val_loss: 0.0349\n",
            "Epoch 278/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8903 - loss: 0.2263 - val_accuracy: 1.0000 - val_loss: 0.0364\n",
            "Epoch 279/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8950 - loss: 0.2166 - val_accuracy: 1.0000 - val_loss: 0.0346\n",
            "Epoch 280/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8826 - loss: 0.2488 - val_accuracy: 1.0000 - val_loss: 0.0327\n",
            "Epoch 281/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9028 - loss: 0.2249 - val_accuracy: 1.0000 - val_loss: 0.0332\n",
            "Epoch 282/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8809 - loss: 0.2338 - val_accuracy: 1.0000 - val_loss: 0.0333\n",
            "Epoch 283/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9102 - loss: 0.1978 - val_accuracy: 1.0000 - val_loss: 0.0315\n",
            "Epoch 284/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.1945 - val_accuracy: 1.0000 - val_loss: 0.0308\n",
            "Epoch 285/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2231 - val_accuracy: 1.0000 - val_loss: 0.0340\n",
            "Epoch 286/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9019 - loss: 0.2061 - val_accuracy: 1.0000 - val_loss: 0.0310\n",
            "Epoch 287/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8709 - loss: 0.2338 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
            "Epoch 288/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8988 - loss: 0.2251 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
            "Epoch 289/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9100 - loss: 0.1982 - val_accuracy: 1.0000 - val_loss: 0.0303\n",
            "Epoch 290/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8902 - loss: 0.2185 - val_accuracy: 1.0000 - val_loss: 0.0287\n",
            "Epoch 291/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8982 - loss: 0.2180 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
            "Epoch 292/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9143 - loss: 0.2083 - val_accuracy: 1.0000 - val_loss: 0.0287\n",
            "Epoch 293/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.2080 - val_accuracy: 1.0000 - val_loss: 0.0316\n",
            "Epoch 294/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8923 - loss: 0.2316 - val_accuracy: 1.0000 - val_loss: 0.0293\n",
            "Epoch 295/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8889 - loss: 0.2189 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
            "Epoch 296/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9015 - loss: 0.2112 - val_accuracy: 1.0000 - val_loss: 0.0279\n",
            "Epoch 297/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9032 - loss: 0.2130 - val_accuracy: 1.0000 - val_loss: 0.0273\n",
            "Epoch 298/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8788 - loss: 0.2197 - val_accuracy: 1.0000 - val_loss: 0.0264\n",
            "Epoch 299/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9065 - loss: 0.2080 - val_accuracy: 1.0000 - val_loss: 0.0255\n",
            "Epoch 300/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.2141 - val_accuracy: 1.0000 - val_loss: 0.0261\n",
            "\n",
            "--- FINAL EVALUATION ---\n",
            "Test Accuracy: 99.26%\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "Test F1-Score: 0.9926\n",
            "\n",
            "Confusion Matrix:\n",
            "[[128   1   0   0   0]\n",
            " [  0  67   0   0   0]\n",
            " [  2   0  68   0   0]\n",
            " [  0   0   0  82   0]\n",
            " [  0   0   0   0  60]]\n",
            "Class Order: ['Angry' 'Fear' 'Happiness' 'Neutral' 'Sadness']\n",
            "\n",
            "Target to match: ~96.34% (Paper Result) [cite: 349]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "# --- Configuration (Issa et al. 2020) ---\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.00001\n",
        "EPOCHS = 300 # Paper mentions 300 for Model A/B [cite: 258]\n",
        "DATA_PATH = \"/content/drive/MyDrive/DeepLearning/Paper_9_Replication_Features/\"\n",
        "\n",
        "# Set seeds\n",
        "def set_seed(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ==========================================\n",
        "# 1. MODEL B ARCHITECTURE\n",
        "# ==========================================\n",
        "# [cite_start]Based on Section 4.2.2 [cite: 260-262, 348]\n",
        "def build_model_b(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # [cite_start]Block 1 (from Model A base) [cite: 257]\n",
        "    x = layers.Conv1D(256, 5, strides=1, padding='same')(inputs)\n",
        "    # [cite_start]Note: Model A removed BN here [cite: 257]\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.MaxPooling1D(pool_size=8)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # [cite_start]Modification for Model B: \"Additional convolution layer before flattening\" [cite: 348]\n",
        "    x = layers.Conv1D(128, 5, strides=1, padding='same')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Flatten & Dropout\n",
        "    x = layers.Flatten()(x)\n",
        "    # [cite_start]Model A had dropout 0.2 here [cite: 257]\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Output Layer (5 Classes)\n",
        "    x = layers.Dense(num_classes)(x)\n",
        "\n",
        "    # [cite_start]Modification for Model B: \"Dropout 0.25 after fully connected layer\" [cite: 348]\n",
        "    # This is unusual, but we place it before Softmax to match description\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    outputs = layers.Activation('softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs, name=\"Issa_Model_B_EMODB\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# 2. DATA LOADING\n",
        "# ==========================================\n",
        "print(\"Loading EMO-DB data...\")\n",
        "X = np.load(os.path.join(DATA_PATH, 'EMODB_X.npy'))\n",
        "y = np.load(os.path.join(DATA_PATH, 'EMODB_y.npy'))\n",
        "groups = np.load(os.path.join(DATA_PATH, 'EMODB_groups.npy'))\n",
        "\n",
        "# Encode Labels (Should be 5 classes: Angry, Fear, Happiness, Neutral, Sadness)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "classes = le.classes_\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "# Reshape for 1D CNN: (N, 193) -> (N, 193, 1)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# [THE CONTROL SWITCH]\n",
        "# 'REPLICATION' = Random Split (Replicating the 96% claim)\n",
        "# 'DISPROVE'    = Speaker Strict (Holding out Actors 13 & 14)\n",
        "EXPERIMENT_MODE = 'DISPROVE'\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "if EXPERIMENT_MODE == 'REPLICATION':\n",
        "    print(f\"\\n>>> MODE: REPLICATION (Random Split) <<<\")\n",
        "    print(\"Warning: This allows Data Leakage (Augmented versions of Test files are in Train).\")\n",
        "    # Random split matching paper's likely method\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42, shuffle=True)\n",
        "    # Create tiny Val set from Train\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "elif EXPERIMENT_MODE == 'DISPROVE':\n",
        "    print(f\"\\n>>> MODE: DISPROVE (Speaker Strict) <<<\")\n",
        "    # Hold out Speakers 13 and 14 (Arbitrary choice, but consistent)\n",
        "    # Note: IDs are strings \"03\", \"13\", etc.\n",
        "    test_actors = ['13', '14']\n",
        "    print(f\"Testing on Actors: {test_actors}\")\n",
        "\n",
        "    test_mask = np.isin(groups, test_actors)\n",
        "\n",
        "    X_test = X[test_mask]\n",
        "    y_test = y_enc[test_mask]\n",
        "\n",
        "    X_train_full = X[~test_mask]\n",
        "    y_train_full = y_enc[~test_mask]\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING\n",
        "# ==========================================\n",
        "\n",
        "model = build_model_b(input_shape=(193, 1), num_classes=len(classes))\n",
        "\n",
        "# [cite_start]Optimizer: RMSProp, lr=0.00001 [cite: 232]\n",
        "opt = optimizers.RMSprop(learning_rate=LEARNING_RATE)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
        "\n",
        "print(\"\\nStarting Training...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 4. EVALUATION\n",
        "# ==========================================\n",
        "print(\"\\n--- FINAL EVALUATION ---\")\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Detailed Metrics\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Test F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(f\"Class Order: {classes}\")\n",
        "\n",
        "if EXPERIMENT_MODE == 'REPLICATION':\n",
        "    print(f\"\\nTarget to match: ~96.34% (Paper Result) [cite: 349]\")\n",
        "elif EXPERIMENT_MODE == 'DISPROVE':\n",
        "    print(f\"\\nIf this is significantly lower than 96%, you have successfully invalidated Model B.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv_lOEh_70F7",
        "outputId": "6dc310ff-da86-4160-f3c2-15c5f3c245a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading EMO-DB data...\n",
            "Classes: ['Angry' 'Fear' 'Happiness' 'Neutral' 'Sadness']\n",
            "\n",
            ">>> MODE: DISPROVE (Speaker Strict) <<<\n",
            "Testing on Actors: ['13', '14']\n",
            "Train: (1404, 193, 1), Val: (156, 193, 1), Test: (480, 193, 1)\n",
            "\n",
            "Starting Training...\n",
            "Epoch 1/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - accuracy: 0.2878 - loss: 2.0067 - val_accuracy: 0.4551 - val_loss: 1.3736\n",
            "Epoch 2/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3793 - loss: 1.4595 - val_accuracy: 0.5321 - val_loss: 1.2175\n",
            "Epoch 3/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4611 - loss: 1.2959 - val_accuracy: 0.5513 - val_loss: 1.1283\n",
            "Epoch 4/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5047 - loss: 1.2108 - val_accuracy: 0.5641 - val_loss: 1.0665\n",
            "Epoch 5/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5222 - loss: 1.1290 - val_accuracy: 0.5897 - val_loss: 1.0206\n",
            "Epoch 6/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5683 - loss: 1.0683 - val_accuracy: 0.5962 - val_loss: 0.9714\n",
            "Epoch 7/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5812 - loss: 1.0420 - val_accuracy: 0.6282 - val_loss: 0.9255\n",
            "Epoch 8/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5766 - loss: 1.0335 - val_accuracy: 0.6154 - val_loss: 0.8919\n",
            "Epoch 9/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5830 - loss: 1.0103 - val_accuracy: 0.6346 - val_loss: 0.8757\n",
            "Epoch 10/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5988 - loss: 0.9717 - val_accuracy: 0.6346 - val_loss: 0.8512\n",
            "Epoch 11/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6051 - loss: 0.9685 - val_accuracy: 0.6603 - val_loss: 0.8165\n",
            "Epoch 12/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6369 - loss: 0.9091 - val_accuracy: 0.6795 - val_loss: 0.7905\n",
            "Epoch 13/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6264 - loss: 0.9073 - val_accuracy: 0.6667 - val_loss: 0.7696\n",
            "Epoch 14/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6232 - loss: 0.8903 - val_accuracy: 0.6603 - val_loss: 0.7554\n",
            "Epoch 15/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6498 - loss: 0.8833 - val_accuracy: 0.6859 - val_loss: 0.7438\n",
            "Epoch 16/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6475 - loss: 0.8910 - val_accuracy: 0.6859 - val_loss: 0.7213\n",
            "Epoch 17/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6591 - loss: 0.8513 - val_accuracy: 0.7115 - val_loss: 0.6955\n",
            "Epoch 18/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6485 - loss: 0.8645 - val_accuracy: 0.7051 - val_loss: 0.6981\n",
            "Epoch 19/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6661 - loss: 0.8412 - val_accuracy: 0.7372 - val_loss: 0.6724\n",
            "Epoch 20/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6780 - loss: 0.8291 - val_accuracy: 0.7244 - val_loss: 0.6527\n",
            "Epoch 21/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6749 - loss: 0.7869 - val_accuracy: 0.7179 - val_loss: 0.6422\n",
            "Epoch 22/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6921 - loss: 0.8025 - val_accuracy: 0.7115 - val_loss: 0.6424\n",
            "Epoch 23/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6913 - loss: 0.7679 - val_accuracy: 0.7500 - val_loss: 0.6258\n",
            "Epoch 24/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6683 - loss: 0.7819 - val_accuracy: 0.7500 - val_loss: 0.6110\n",
            "Epoch 25/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6963 - loss: 0.7462 - val_accuracy: 0.7436 - val_loss: 0.6008\n",
            "Epoch 26/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6779 - loss: 0.7504 - val_accuracy: 0.7564 - val_loss: 0.5892\n",
            "Epoch 27/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6981 - loss: 0.7364 - val_accuracy: 0.7500 - val_loss: 0.5766\n",
            "Epoch 28/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7060 - loss: 0.7377 - val_accuracy: 0.7628 - val_loss: 0.5642\n",
            "Epoch 29/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7003 - loss: 0.7356 - val_accuracy: 0.7885 - val_loss: 0.5558\n",
            "Epoch 30/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6694 - loss: 0.7453 - val_accuracy: 0.7821 - val_loss: 0.5416\n",
            "Epoch 31/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7147 - loss: 0.7031 - val_accuracy: 0.7628 - val_loss: 0.5381\n",
            "Epoch 32/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7095 - loss: 0.6891 - val_accuracy: 0.8013 - val_loss: 0.5293\n",
            "Epoch 33/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7010 - loss: 0.7044 - val_accuracy: 0.7885 - val_loss: 0.5237\n",
            "Epoch 34/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7027 - loss: 0.6993 - val_accuracy: 0.7885 - val_loss: 0.5162\n",
            "Epoch 35/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7274 - loss: 0.6672 - val_accuracy: 0.7885 - val_loss: 0.5125\n",
            "Epoch 36/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7254 - loss: 0.6683 - val_accuracy: 0.8077 - val_loss: 0.5014\n",
            "Epoch 37/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7161 - loss: 0.6923 - val_accuracy: 0.8077 - val_loss: 0.5007\n",
            "Epoch 38/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7330 - loss: 0.6522 - val_accuracy: 0.8269 - val_loss: 0.4854\n",
            "Epoch 39/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7706 - loss: 0.6036 - val_accuracy: 0.8269 - val_loss: 0.4777\n",
            "Epoch 40/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7260 - loss: 0.6433 - val_accuracy: 0.8205 - val_loss: 0.4710\n",
            "Epoch 41/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7271 - loss: 0.6296 - val_accuracy: 0.8205 - val_loss: 0.4664\n",
            "Epoch 42/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7498 - loss: 0.6296 - val_accuracy: 0.8333 - val_loss: 0.4631\n",
            "Epoch 43/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7387 - loss: 0.6411 - val_accuracy: 0.8333 - val_loss: 0.4477\n",
            "Epoch 44/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7553 - loss: 0.6224 - val_accuracy: 0.8269 - val_loss: 0.4434\n",
            "Epoch 45/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7215 - loss: 0.6358 - val_accuracy: 0.8205 - val_loss: 0.4406\n",
            "Epoch 46/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7398 - loss: 0.6354 - val_accuracy: 0.8269 - val_loss: 0.4376\n",
            "Epoch 47/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7533 - loss: 0.6335 - val_accuracy: 0.8333 - val_loss: 0.4303\n",
            "Epoch 48/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7559 - loss: 0.6084 - val_accuracy: 0.8269 - val_loss: 0.4267\n",
            "Epoch 49/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7746 - loss: 0.5765 - val_accuracy: 0.8526 - val_loss: 0.4167\n",
            "Epoch 50/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7317 - loss: 0.6134 - val_accuracy: 0.8526 - val_loss: 0.4109\n",
            "Epoch 51/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7484 - loss: 0.5842 - val_accuracy: 0.8526 - val_loss: 0.4075\n",
            "Epoch 52/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7453 - loss: 0.5757 - val_accuracy: 0.8526 - val_loss: 0.3974\n",
            "Epoch 53/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7595 - loss: 0.5948 - val_accuracy: 0.8590 - val_loss: 0.3926\n",
            "Epoch 54/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7492 - loss: 0.5805 - val_accuracy: 0.8590 - val_loss: 0.3900\n",
            "Epoch 55/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7592 - loss: 0.5811 - val_accuracy: 0.8462 - val_loss: 0.3859\n",
            "Epoch 56/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7847 - loss: 0.5668 - val_accuracy: 0.8590 - val_loss: 0.3756\n",
            "Epoch 57/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7876 - loss: 0.5397 - val_accuracy: 0.8718 - val_loss: 0.3712\n",
            "Epoch 58/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.5428 - val_accuracy: 0.8526 - val_loss: 0.3677\n",
            "Epoch 59/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7778 - loss: 0.5518 - val_accuracy: 0.8718 - val_loss: 0.3644\n",
            "Epoch 60/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7932 - loss: 0.5379 - val_accuracy: 0.8590 - val_loss: 0.3595\n",
            "Epoch 61/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7788 - loss: 0.5320 - val_accuracy: 0.8846 - val_loss: 0.3488\n",
            "Epoch 62/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8193 - loss: 0.5008 - val_accuracy: 0.8974 - val_loss: 0.3523\n",
            "Epoch 63/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8053 - loss: 0.4993 - val_accuracy: 0.8782 - val_loss: 0.3460\n",
            "Epoch 64/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7981 - loss: 0.5321 - val_accuracy: 0.8654 - val_loss: 0.3473\n",
            "Epoch 65/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7999 - loss: 0.5264 - val_accuracy: 0.9103 - val_loss: 0.3330\n",
            "Epoch 66/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.5281 - val_accuracy: 0.8846 - val_loss: 0.3341\n",
            "Epoch 67/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7943 - loss: 0.5188 - val_accuracy: 0.8974 - val_loss: 0.3252\n",
            "Epoch 68/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7976 - loss: 0.5005 - val_accuracy: 0.8846 - val_loss: 0.3234\n",
            "Epoch 69/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7867 - loss: 0.5162 - val_accuracy: 0.9038 - val_loss: 0.3140\n",
            "Epoch 70/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8111 - loss: 0.4735 - val_accuracy: 0.9038 - val_loss: 0.3138\n",
            "Epoch 71/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.4805 - val_accuracy: 0.8974 - val_loss: 0.3131\n",
            "Epoch 72/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7950 - loss: 0.5050 - val_accuracy: 0.9103 - val_loss: 0.3075\n",
            "Epoch 73/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8051 - loss: 0.4685 - val_accuracy: 0.9103 - val_loss: 0.2990\n",
            "Epoch 74/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7858 - loss: 0.5083 - val_accuracy: 0.9038 - val_loss: 0.3035\n",
            "Epoch 75/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8051 - loss: 0.4891 - val_accuracy: 0.9038 - val_loss: 0.2924\n",
            "Epoch 76/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8175 - loss: 0.4564 - val_accuracy: 0.9167 - val_loss: 0.2867\n",
            "Epoch 77/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8041 - loss: 0.4626 - val_accuracy: 0.9103 - val_loss: 0.2839\n",
            "Epoch 78/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8020 - loss: 0.4901 - val_accuracy: 0.9231 - val_loss: 0.2798\n",
            "Epoch 79/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8032 - loss: 0.4850 - val_accuracy: 0.9167 - val_loss: 0.2785\n",
            "Epoch 80/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8049 - loss: 0.4676 - val_accuracy: 0.9167 - val_loss: 0.2768\n",
            "Epoch 81/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8178 - loss: 0.4623 - val_accuracy: 0.9167 - val_loss: 0.2762\n",
            "Epoch 82/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8030 - loss: 0.4692 - val_accuracy: 0.9231 - val_loss: 0.2663\n",
            "Epoch 83/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8039 - loss: 0.4676 - val_accuracy: 0.9167 - val_loss: 0.2636\n",
            "Epoch 84/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8196 - loss: 0.4493 - val_accuracy: 0.9167 - val_loss: 0.2608\n",
            "Epoch 85/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8166 - loss: 0.4420 - val_accuracy: 0.9231 - val_loss: 0.2567\n",
            "Epoch 86/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8323 - loss: 0.4478 - val_accuracy: 0.9231 - val_loss: 0.2547\n",
            "Epoch 87/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8237 - loss: 0.4278 - val_accuracy: 0.9231 - val_loss: 0.2545\n",
            "Epoch 88/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8358 - loss: 0.4141 - val_accuracy: 0.9231 - val_loss: 0.2500\n",
            "Epoch 89/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8336 - loss: 0.4376 - val_accuracy: 0.9231 - val_loss: 0.2513\n",
            "Epoch 90/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8221 - loss: 0.4489 - val_accuracy: 0.9231 - val_loss: 0.2479\n",
            "Epoch 91/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8367 - loss: 0.4139 - val_accuracy: 0.9359 - val_loss: 0.2372\n",
            "Epoch 92/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8349 - loss: 0.4213 - val_accuracy: 0.9231 - val_loss: 0.2343\n",
            "Epoch 93/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8381 - loss: 0.4288 - val_accuracy: 0.9295 - val_loss: 0.2283\n",
            "Epoch 94/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8391 - loss: 0.3966 - val_accuracy: 0.9423 - val_loss: 0.2309\n",
            "Epoch 95/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8138 - loss: 0.4320 - val_accuracy: 0.9423 - val_loss: 0.2236\n",
            "Epoch 96/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8420 - loss: 0.4029 - val_accuracy: 0.9359 - val_loss: 0.2317\n",
            "Epoch 97/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8327 - loss: 0.4161 - val_accuracy: 0.9423 - val_loss: 0.2220\n",
            "Epoch 98/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8249 - loss: 0.4311 - val_accuracy: 0.9359 - val_loss: 0.2252\n",
            "Epoch 99/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8153 - loss: 0.4266 - val_accuracy: 0.9295 - val_loss: 0.2266\n",
            "Epoch 100/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8350 - loss: 0.4182 - val_accuracy: 0.9423 - val_loss: 0.2147\n",
            "Epoch 101/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8672 - loss: 0.3652 - val_accuracy: 0.9487 - val_loss: 0.2115\n",
            "Epoch 102/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8351 - loss: 0.4005 - val_accuracy: 0.9487 - val_loss: 0.2123\n",
            "Epoch 103/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.4167 - val_accuracy: 0.9359 - val_loss: 0.2084\n",
            "Epoch 104/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8411 - loss: 0.4064 - val_accuracy: 0.9423 - val_loss: 0.2021\n",
            "Epoch 105/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.3946 - val_accuracy: 0.9487 - val_loss: 0.1972\n",
            "Epoch 106/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8423 - loss: 0.4016 - val_accuracy: 0.9487 - val_loss: 0.1990\n",
            "Epoch 107/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - loss: 0.3858 - val_accuracy: 0.9487 - val_loss: 0.1946\n",
            "Epoch 108/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8384 - loss: 0.3918 - val_accuracy: 0.9487 - val_loss: 0.1902\n",
            "Epoch 109/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8607 - loss: 0.3377 - val_accuracy: 0.9423 - val_loss: 0.1922\n",
            "Epoch 110/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8331 - loss: 0.3972 - val_accuracy: 0.9551 - val_loss: 0.1909\n",
            "Epoch 111/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8596 - loss: 0.3653 - val_accuracy: 0.9551 - val_loss: 0.1879\n",
            "Epoch 112/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8532 - loss: 0.3714 - val_accuracy: 0.9423 - val_loss: 0.1877\n",
            "Epoch 113/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8553 - loss: 0.3717 - val_accuracy: 0.9551 - val_loss: 0.1853\n",
            "Epoch 114/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8587 - loss: 0.3478 - val_accuracy: 0.9551 - val_loss: 0.1822\n",
            "Epoch 115/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8445 - loss: 0.3798 - val_accuracy: 0.9551 - val_loss: 0.1769\n",
            "Epoch 116/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8723 - loss: 0.3319 - val_accuracy: 0.9551 - val_loss: 0.1772\n",
            "Epoch 117/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8539 - loss: 0.3622 - val_accuracy: 0.9679 - val_loss: 0.1731\n",
            "Epoch 118/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8715 - loss: 0.3391 - val_accuracy: 0.9615 - val_loss: 0.1676\n",
            "Epoch 119/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8647 - loss: 0.3208 - val_accuracy: 0.9615 - val_loss: 0.1645\n",
            "Epoch 120/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8676 - loss: 0.3273 - val_accuracy: 0.9679 - val_loss: 0.1685\n",
            "Epoch 121/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8522 - loss: 0.3375 - val_accuracy: 0.9679 - val_loss: 0.1619\n",
            "Epoch 122/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8630 - loss: 0.3346 - val_accuracy: 0.9679 - val_loss: 0.1599\n",
            "Epoch 123/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8581 - loss: 0.3448 - val_accuracy: 0.9679 - val_loss: 0.1605\n",
            "Epoch 124/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8630 - loss: 0.3390 - val_accuracy: 0.9615 - val_loss: 0.1609\n",
            "Epoch 125/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8536 - loss: 0.3546 - val_accuracy: 0.9615 - val_loss: 0.1564\n",
            "Epoch 126/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8689 - loss: 0.3431 - val_accuracy: 0.9679 - val_loss: 0.1631\n",
            "Epoch 127/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8692 - loss: 0.3414 - val_accuracy: 0.9679 - val_loss: 0.1517\n",
            "Epoch 128/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8661 - loss: 0.3380 - val_accuracy: 0.9679 - val_loss: 0.1470\n",
            "Epoch 129/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8504 - loss: 0.3404 - val_accuracy: 0.9679 - val_loss: 0.1445\n",
            "Epoch 130/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8601 - loss: 0.3276 - val_accuracy: 0.9679 - val_loss: 0.1456\n",
            "Epoch 131/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 0.3527 - val_accuracy: 0.9744 - val_loss: 0.1442\n",
            "Epoch 132/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8633 - loss: 0.3492 - val_accuracy: 0.9679 - val_loss: 0.1453\n",
            "Epoch 133/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8685 - loss: 0.3169 - val_accuracy: 0.9744 - val_loss: 0.1409\n",
            "Epoch 134/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8700 - loss: 0.3247 - val_accuracy: 0.9679 - val_loss: 0.1364\n",
            "Epoch 135/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8686 - loss: 0.3079 - val_accuracy: 0.9679 - val_loss: 0.1325\n",
            "Epoch 136/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8621 - loss: 0.3447 - val_accuracy: 0.9744 - val_loss: 0.1376\n",
            "Epoch 137/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8752 - loss: 0.3259 - val_accuracy: 0.9679 - val_loss: 0.1323\n",
            "Epoch 138/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8751 - loss: 0.3041 - val_accuracy: 0.9808 - val_loss: 0.1320\n",
            "Epoch 139/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8733 - loss: 0.3194 - val_accuracy: 0.9744 - val_loss: 0.1308\n",
            "Epoch 140/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8824 - loss: 0.3244 - val_accuracy: 0.9615 - val_loss: 0.1289\n",
            "Epoch 141/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8711 - loss: 0.3010 - val_accuracy: 0.9744 - val_loss: 0.1250\n",
            "Epoch 142/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8873 - loss: 0.2986 - val_accuracy: 0.9679 - val_loss: 0.1252\n",
            "Epoch 143/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8892 - loss: 0.3036 - val_accuracy: 0.9808 - val_loss: 0.1226\n",
            "Epoch 144/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8844 - loss: 0.2969 - val_accuracy: 0.9744 - val_loss: 0.1240\n",
            "Epoch 145/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8572 - loss: 0.3232 - val_accuracy: 0.9679 - val_loss: 0.1227\n",
            "Epoch 146/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8874 - loss: 0.2871 - val_accuracy: 0.9679 - val_loss: 0.1212\n",
            "Epoch 147/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8756 - loss: 0.3031 - val_accuracy: 0.9808 - val_loss: 0.1237\n",
            "Epoch 148/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8928 - loss: 0.2900 - val_accuracy: 0.9808 - val_loss: 0.1255\n",
            "Epoch 149/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8886 - loss: 0.2950 - val_accuracy: 0.9808 - val_loss: 0.1165\n",
            "Epoch 150/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8592 - loss: 0.3288 - val_accuracy: 0.9679 - val_loss: 0.1137\n",
            "Epoch 151/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8627 - loss: 0.3074 - val_accuracy: 0.9679 - val_loss: 0.1104\n",
            "Epoch 152/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8692 - loss: 0.3121 - val_accuracy: 0.9808 - val_loss: 0.1117\n",
            "Epoch 153/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8802 - loss: 0.3055 - val_accuracy: 0.9808 - val_loss: 0.1112\n",
            "Epoch 154/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8621 - loss: 0.3108 - val_accuracy: 0.9808 - val_loss: 0.1103\n",
            "Epoch 155/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8963 - loss: 0.2778 - val_accuracy: 0.9808 - val_loss: 0.1084\n",
            "Epoch 156/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8736 - loss: 0.2866 - val_accuracy: 0.9808 - val_loss: 0.1063\n",
            "Epoch 157/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8833 - loss: 0.2855 - val_accuracy: 0.9808 - val_loss: 0.1025\n",
            "Epoch 158/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8755 - loss: 0.2944 - val_accuracy: 0.9808 - val_loss: 0.0996\n",
            "Epoch 159/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8825 - loss: 0.2934 - val_accuracy: 0.9808 - val_loss: 0.1015\n",
            "Epoch 160/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8845 - loss: 0.2987 - val_accuracy: 0.9808 - val_loss: 0.0979\n",
            "Epoch 161/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8745 - loss: 0.2846 - val_accuracy: 0.9808 - val_loss: 0.1046\n",
            "Epoch 162/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8721 - loss: 0.2890 - val_accuracy: 0.9808 - val_loss: 0.1011\n",
            "Epoch 163/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 0.2763 - val_accuracy: 0.9808 - val_loss: 0.0968\n",
            "Epoch 164/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8812 - loss: 0.2820 - val_accuracy: 0.9872 - val_loss: 0.0941\n",
            "Epoch 165/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8964 - loss: 0.2713 - val_accuracy: 0.9808 - val_loss: 0.0957\n",
            "Epoch 166/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8772 - loss: 0.2841 - val_accuracy: 0.9808 - val_loss: 0.0955\n",
            "Epoch 167/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8821 - loss: 0.2670 - val_accuracy: 0.9872 - val_loss: 0.0907\n",
            "Epoch 168/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8725 - loss: 0.2910 - val_accuracy: 0.9808 - val_loss: 0.0907\n",
            "Epoch 169/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8868 - loss: 0.2755 - val_accuracy: 0.9808 - val_loss: 0.0872\n",
            "Epoch 170/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8947 - loss: 0.2517 - val_accuracy: 0.9808 - val_loss: 0.0906\n",
            "Epoch 171/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8877 - loss: 0.2769 - val_accuracy: 0.9808 - val_loss: 0.0871\n",
            "Epoch 172/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.2579 - val_accuracy: 0.9808 - val_loss: 0.0919\n",
            "Epoch 173/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8959 - loss: 0.2674 - val_accuracy: 0.9808 - val_loss: 0.0864\n",
            "Epoch 174/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8797 - loss: 0.2789 - val_accuracy: 0.9808 - val_loss: 0.0842\n",
            "Epoch 175/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8759 - loss: 0.2687 - val_accuracy: 0.9872 - val_loss: 0.0812\n",
            "Epoch 176/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8892 - loss: 0.2742 - val_accuracy: 0.9872 - val_loss: 0.0802\n",
            "Epoch 177/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8787 - loss: 0.2708 - val_accuracy: 0.9808 - val_loss: 0.0816\n",
            "Epoch 178/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.2705 - val_accuracy: 0.9872 - val_loss: 0.0793\n",
            "Epoch 179/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8797 - loss: 0.2697 - val_accuracy: 1.0000 - val_loss: 0.0747\n",
            "Epoch 180/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8988 - loss: 0.2438 - val_accuracy: 0.9872 - val_loss: 0.0770\n",
            "Epoch 181/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8994 - loss: 0.2523 - val_accuracy: 0.9808 - val_loss: 0.0784\n",
            "Epoch 182/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8845 - loss: 0.2602 - val_accuracy: 0.9872 - val_loss: 0.0771\n",
            "Epoch 183/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8867 - loss: 0.2749 - val_accuracy: 0.9872 - val_loss: 0.0749\n",
            "Epoch 184/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8859 - loss: 0.2735 - val_accuracy: 0.9808 - val_loss: 0.0764\n",
            "Epoch 185/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8911 - loss: 0.2683 - val_accuracy: 0.9808 - val_loss: 0.0836\n",
            "Epoch 186/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8878 - loss: 0.2746 - val_accuracy: 0.9872 - val_loss: 0.0710\n",
            "Epoch 187/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8862 - loss: 0.2561 - val_accuracy: 0.9936 - val_loss: 0.0695\n",
            "Epoch 188/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8803 - loss: 0.2799 - val_accuracy: 0.9936 - val_loss: 0.0679\n",
            "Epoch 189/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8910 - loss: 0.2428 - val_accuracy: 0.9872 - val_loss: 0.0692\n",
            "Epoch 190/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8945 - loss: 0.2590 - val_accuracy: 0.9936 - val_loss: 0.0669\n",
            "Epoch 191/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8955 - loss: 0.2500 - val_accuracy: 0.9872 - val_loss: 0.0657\n",
            "Epoch 192/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8973 - loss: 0.2386 - val_accuracy: 0.9936 - val_loss: 0.0665\n",
            "Epoch 193/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.2244 - val_accuracy: 0.9872 - val_loss: 0.0686\n",
            "Epoch 194/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8839 - loss: 0.2791 - val_accuracy: 0.9872 - val_loss: 0.0650\n",
            "Epoch 195/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8964 - loss: 0.2488 - val_accuracy: 0.9936 - val_loss: 0.0648\n",
            "Epoch 196/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8746 - loss: 0.2626 - val_accuracy: 0.9936 - val_loss: 0.0620\n",
            "Epoch 197/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8916 - loss: 0.2436 - val_accuracy: 0.9936 - val_loss: 0.0670\n",
            "Epoch 198/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8830 - loss: 0.2676 - val_accuracy: 0.9936 - val_loss: 0.0657\n",
            "Epoch 199/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9032 - loss: 0.2286 - val_accuracy: 0.9872 - val_loss: 0.0623\n",
            "Epoch 200/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8900 - loss: 0.2345 - val_accuracy: 0.9872 - val_loss: 0.0607\n",
            "Epoch 201/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8915 - loss: 0.2523 - val_accuracy: 1.0000 - val_loss: 0.0553\n",
            "Epoch 202/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9004 - loss: 0.2432 - val_accuracy: 0.9872 - val_loss: 0.0605\n",
            "Epoch 203/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8994 - loss: 0.2208 - val_accuracy: 0.9872 - val_loss: 0.0563\n",
            "Epoch 204/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9040 - loss: 0.2129 - val_accuracy: 0.9936 - val_loss: 0.0550\n",
            "Epoch 205/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8961 - loss: 0.2530 - val_accuracy: 0.9936 - val_loss: 0.0546\n",
            "Epoch 206/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8848 - loss: 0.2529 - val_accuracy: 0.9936 - val_loss: 0.0531\n",
            "Epoch 207/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8999 - loss: 0.2398 - val_accuracy: 0.9872 - val_loss: 0.0561\n",
            "Epoch 208/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9060 - loss: 0.2225 - val_accuracy: 0.9936 - val_loss: 0.0540\n",
            "Epoch 209/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9008 - loss: 0.2353 - val_accuracy: 0.9936 - val_loss: 0.0540\n",
            "Epoch 210/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.2261 - val_accuracy: 0.9936 - val_loss: 0.0542\n",
            "Epoch 211/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8922 - loss: 0.2238 - val_accuracy: 0.9872 - val_loss: 0.0545\n",
            "Epoch 212/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9077 - loss: 0.2491 - val_accuracy: 0.9872 - val_loss: 0.0539\n",
            "Epoch 213/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9061 - loss: 0.2261 - val_accuracy: 0.9936 - val_loss: 0.0513\n",
            "Epoch 214/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8912 - loss: 0.2274 - val_accuracy: 0.9936 - val_loss: 0.0511\n",
            "Epoch 215/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9121 - loss: 0.2253 - val_accuracy: 1.0000 - val_loss: 0.0490\n",
            "Epoch 216/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8937 - loss: 0.2285 - val_accuracy: 1.0000 - val_loss: 0.0490\n",
            "Epoch 217/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8924 - loss: 0.2303 - val_accuracy: 0.9936 - val_loss: 0.0492\n",
            "Epoch 218/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8964 - loss: 0.2321 - val_accuracy: 0.9872 - val_loss: 0.0490\n",
            "Epoch 219/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9096 - loss: 0.2198 - val_accuracy: 0.9936 - val_loss: 0.0458\n",
            "Epoch 220/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9075 - loss: 0.2202 - val_accuracy: 0.9936 - val_loss: 0.0468\n",
            "Epoch 221/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 0.2355 - val_accuracy: 0.9936 - val_loss: 0.0475\n",
            "Epoch 222/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8902 - loss: 0.2184 - val_accuracy: 0.9936 - val_loss: 0.0436\n",
            "Epoch 223/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8948 - loss: 0.2257 - val_accuracy: 0.9936 - val_loss: 0.0431\n",
            "Epoch 224/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9002 - loss: 0.2100 - val_accuracy: 0.9936 - val_loss: 0.0431\n",
            "Epoch 225/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8924 - loss: 0.2361 - val_accuracy: 0.9936 - val_loss: 0.0428\n",
            "Epoch 226/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9008 - loss: 0.2540 - val_accuracy: 0.9936 - val_loss: 0.0446\n",
            "Epoch 227/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9194 - loss: 0.1986 - val_accuracy: 0.9936 - val_loss: 0.0460\n",
            "Epoch 228/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8999 - loss: 0.2278 - val_accuracy: 0.9936 - val_loss: 0.0392\n",
            "Epoch 229/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8923 - loss: 0.2385 - val_accuracy: 0.9936 - val_loss: 0.0388\n",
            "Epoch 230/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9135 - loss: 0.2084 - val_accuracy: 0.9936 - val_loss: 0.0401\n",
            "Epoch 231/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8966 - loss: 0.2362 - val_accuracy: 0.9936 - val_loss: 0.0405\n",
            "Epoch 232/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9074 - loss: 0.2021 - val_accuracy: 0.9936 - val_loss: 0.0421\n",
            "Epoch 233/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8919 - loss: 0.2295 - val_accuracy: 1.0000 - val_loss: 0.0381\n",
            "Epoch 234/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8964 - loss: 0.2383 - val_accuracy: 0.9936 - val_loss: 0.0408\n",
            "Epoch 235/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9123 - loss: 0.2136 - val_accuracy: 0.9936 - val_loss: 0.0398\n",
            "Epoch 236/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2043 - val_accuracy: 0.9936 - val_loss: 0.0403\n",
            "Epoch 237/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9102 - loss: 0.2035 - val_accuracy: 0.9936 - val_loss: 0.0387\n",
            "Epoch 238/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9124 - loss: 0.2203 - val_accuracy: 0.9936 - val_loss: 0.0382\n",
            "Epoch 239/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9038 - loss: 0.2345 - val_accuracy: 0.9936 - val_loss: 0.0354\n",
            "Epoch 240/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9124 - loss: 0.1983 - val_accuracy: 1.0000 - val_loss: 0.0339\n",
            "Epoch 241/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9044 - loss: 0.2046 - val_accuracy: 0.9936 - val_loss: 0.0343\n",
            "Epoch 242/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9089 - loss: 0.2146 - val_accuracy: 0.9936 - val_loss: 0.0388\n",
            "Epoch 243/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9113 - loss: 0.2189 - val_accuracy: 0.9936 - val_loss: 0.0352\n",
            "Epoch 244/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9098 - loss: 0.2235 - val_accuracy: 0.9936 - val_loss: 0.0351\n",
            "Epoch 245/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9075 - loss: 0.2047 - val_accuracy: 0.9936 - val_loss: 0.0337\n",
            "Epoch 246/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8993 - loss: 0.2381 - val_accuracy: 0.9936 - val_loss: 0.0322\n",
            "Epoch 247/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9251 - loss: 0.1854 - val_accuracy: 1.0000 - val_loss: 0.0312\n",
            "Epoch 248/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8872 - loss: 0.2176 - val_accuracy: 1.0000 - val_loss: 0.0340\n",
            "Epoch 249/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9020 - loss: 0.2139 - val_accuracy: 1.0000 - val_loss: 0.0318\n",
            "Epoch 250/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9005 - loss: 0.1986 - val_accuracy: 1.0000 - val_loss: 0.0299\n",
            "Epoch 251/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.2068 - val_accuracy: 0.9936 - val_loss: 0.0292\n",
            "Epoch 252/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.2232 - val_accuracy: 1.0000 - val_loss: 0.0294\n",
            "Epoch 253/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9080 - loss: 0.2265 - val_accuracy: 0.9936 - val_loss: 0.0336\n",
            "Epoch 254/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9049 - loss: 0.2026 - val_accuracy: 1.0000 - val_loss: 0.0283\n",
            "Epoch 255/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9233 - loss: 0.1675 - val_accuracy: 0.9936 - val_loss: 0.0333\n",
            "Epoch 256/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9285 - loss: 0.1760 - val_accuracy: 0.9936 - val_loss: 0.0278\n",
            "Epoch 257/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9081 - loss: 0.1836 - val_accuracy: 1.0000 - val_loss: 0.0276\n",
            "Epoch 258/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.1952 - val_accuracy: 1.0000 - val_loss: 0.0273\n",
            "Epoch 259/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8974 - loss: 0.2098 - val_accuracy: 0.9936 - val_loss: 0.0283\n",
            "Epoch 260/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.2109 - val_accuracy: 0.9936 - val_loss: 0.0270\n",
            "Epoch 261/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.2128 - val_accuracy: 1.0000 - val_loss: 0.0248\n",
            "Epoch 262/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.1837 - val_accuracy: 0.9936 - val_loss: 0.0281\n",
            "Epoch 263/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9071 - loss: 0.1942 - val_accuracy: 0.9936 - val_loss: 0.0259\n",
            "Epoch 264/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9162 - loss: 0.1723 - val_accuracy: 1.0000 - val_loss: 0.0269\n",
            "Epoch 265/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8982 - loss: 0.2088 - val_accuracy: 0.9936 - val_loss: 0.0286\n",
            "Epoch 266/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9030 - loss: 0.2071 - val_accuracy: 1.0000 - val_loss: 0.0254\n",
            "Epoch 267/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8952 - loss: 0.2300 - val_accuracy: 1.0000 - val_loss: 0.0239\n",
            "Epoch 268/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.1858 - val_accuracy: 0.9936 - val_loss: 0.0249\n",
            "Epoch 269/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.1889 - val_accuracy: 0.9936 - val_loss: 0.0285\n",
            "Epoch 270/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9150 - loss: 0.1935 - val_accuracy: 1.0000 - val_loss: 0.0286\n",
            "Epoch 271/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9010 - loss: 0.2143 - val_accuracy: 1.0000 - val_loss: 0.0240\n",
            "Epoch 272/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9185 - loss: 0.1962 - val_accuracy: 1.0000 - val_loss: 0.0229\n",
            "Epoch 273/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.1835 - val_accuracy: 0.9936 - val_loss: 0.0249\n",
            "Epoch 274/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8965 - loss: 0.2082 - val_accuracy: 1.0000 - val_loss: 0.0237\n",
            "Epoch 275/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9186 - loss: 0.1706 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
            "Epoch 276/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8942 - loss: 0.2132 - val_accuracy: 1.0000 - val_loss: 0.0221\n",
            "Epoch 277/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9143 - loss: 0.1980 - val_accuracy: 1.0000 - val_loss: 0.0212\n",
            "Epoch 278/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9172 - loss: 0.1903 - val_accuracy: 0.9936 - val_loss: 0.0229\n",
            "Epoch 279/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9105 - loss: 0.1879 - val_accuracy: 0.9936 - val_loss: 0.0215\n",
            "Epoch 280/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9254 - loss: 0.1763 - val_accuracy: 0.9936 - val_loss: 0.0261\n",
            "Epoch 281/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9158 - loss: 0.1780 - val_accuracy: 0.9936 - val_loss: 0.0235\n",
            "Epoch 282/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9094 - loss: 0.2137 - val_accuracy: 1.0000 - val_loss: 0.0214\n",
            "Epoch 283/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8879 - loss: 0.2274 - val_accuracy: 0.9936 - val_loss: 0.0209\n",
            "Epoch 284/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9001 - loss: 0.2014 - val_accuracy: 1.0000 - val_loss: 0.0226\n",
            "Epoch 285/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9223 - loss: 0.1659 - val_accuracy: 1.0000 - val_loss: 0.0239\n",
            "Epoch 286/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9048 - loss: 0.1940 - val_accuracy: 1.0000 - val_loss: 0.0185\n",
            "Epoch 287/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9112 - loss: 0.1820 - val_accuracy: 1.0000 - val_loss: 0.0178\n",
            "Epoch 288/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9251 - loss: 0.1833 - val_accuracy: 1.0000 - val_loss: 0.0191\n",
            "Epoch 289/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9375 - loss: 0.1866 - val_accuracy: 1.0000 - val_loss: 0.0196\n",
            "Epoch 290/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8928 - loss: 0.1953 - val_accuracy: 0.9936 - val_loss: 0.0200\n",
            "Epoch 291/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9207 - loss: 0.1748 - val_accuracy: 1.0000 - val_loss: 0.0183\n",
            "Epoch 292/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8995 - loss: 0.1833 - val_accuracy: 1.0000 - val_loss: 0.0186\n",
            "Epoch 293/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9050 - loss: 0.1921 - val_accuracy: 1.0000 - val_loss: 0.0169\n",
            "Epoch 294/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9212 - loss: 0.1748 - val_accuracy: 1.0000 - val_loss: 0.0219\n",
            "Epoch 295/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9220 - loss: 0.1878 - val_accuracy: 1.0000 - val_loss: 0.0180\n",
            "Epoch 296/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9276 - loss: 0.1774 - val_accuracy: 1.0000 - val_loss: 0.0177\n",
            "Epoch 297/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9115 - loss: 0.1768 - val_accuracy: 0.9936 - val_loss: 0.0179\n",
            "Epoch 298/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9107 - loss: 0.1917 - val_accuracy: 0.9936 - val_loss: 0.0198\n",
            "Epoch 299/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9089 - loss: 0.1892 - val_accuracy: 0.9936 - val_loss: 0.0224\n",
            "Epoch 300/300\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9142 - loss: 0.1923 - val_accuracy: 0.9936 - val_loss: 0.0202\n",
            "\n",
            "--- FINAL EVALUATION ---\n",
            "Test Accuracy: 74.58%\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
            "Test F1-Score: 0.7436\n",
            "\n",
            "Confusion Matrix:\n",
            "[[111   6  23   0   0]\n",
            " [  0  59   8  21   7]\n",
            " [ 19  20  51   0   0]\n",
            " [  0   4   1  67   8]\n",
            " [  0   5   0   0  70]]\n",
            "Class Order: ['Angry' 'Fear' 'Happiness' 'Neutral' 'Sadness']\n",
            "\n",
            "If this is significantly lower than 96%, you have successfully invalidated Model B.\n"
          ]
        }
      ]
    }
  ]
}