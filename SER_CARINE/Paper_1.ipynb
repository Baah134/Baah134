{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhiFHCA0pAooP7jW7YIihv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/SER_CARINE/Paper_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa numpy scipy PyWavelets\n",
        "DATASET_PATH = \"/content/drive/MyDrive/DeepLearning/External/EMoDB/\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u07C48dbE7xq",
        "outputId": "8646a19f-02c3-4006-d3d2-6154504187ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (1.9.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.stats\n",
        "import pywt\n",
        "from scipy.signal import lfilter\n",
        "from tqdm import tqdm  # <--- NEW IMPORT\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP & CONFIGURATION\n",
        "# ==========================================\n",
        "DATASET_PATH = \"/content/drive/MyDrive/DeepLearning/External/EMoDB/\"\n",
        "OUTPUT_PATH = \"processed_data/\"\n",
        "\n",
        "CLASSES = ['Angry', 'Boredom', 'Disgust', 'Anxiety', 'Happiness', 'Sadness', 'Neutral']\n",
        "\n",
        "CODE_TO_EMOTION = {\n",
        "    'W': 'Angry',\n",
        "    'L': 'Boredom',\n",
        "    'E': 'Disgust',\n",
        "    'A': 'Anxiety',\n",
        "    'F': 'Happiness',\n",
        "    'T': 'Sadness',\n",
        "    'N': 'Neutral'\n",
        "}\n",
        "\n",
        "EMOTION_TO_INT = {label: i for i, label in enumerate(CLASSES)}\n",
        "\n",
        "# ==========================================\n",
        "# 2. FEATURE EXTRACTOR\n",
        "# ==========================================\n",
        "def extract_bhangale_features(audio_path):\n",
        "    \"\"\"\n",
        "    Extracts the exact 715-dim feature vector described in Bhangale et al. (2023).\n",
        "    \"\"\"\n",
        "    # [cite_start]Load audio, Resample to 16kHz [cite: 1795]\n",
        "    y, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "    # [cite_start]Standardize to 4 seconds (64000 samples) [cite: 1796]\n",
        "    target_length = 64000\n",
        "    if len(y) < target_length:\n",
        "        y = np.pad(y, (0, target_length - len(y)))\n",
        "    else:\n",
        "        y = y[:target_length]\n",
        "\n",
        "    # [cite_start]Pre-emphasis filter [cite: 1528]\n",
        "    y = lfilter([1, -0.97], [1], y)\n",
        "\n",
        "    # [cite_start]Frame Settings: 40ms window, 50% overlap [cite: 1529]\n",
        "    n_fft = 640\n",
        "    hop_length = 320\n",
        "\n",
        "    # --- A. TIME-SERIES FEATURES (Length 199 each) ---\n",
        "    zcr = _fix_length(librosa.feature.zero_crossing_rate(y, frame_length=n_fft, hop_length=hop_length)[0], 199)\n",
        "    centroid = _fix_length(librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)[0], 199)\n",
        "    S = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))\n",
        "    kurtosis = _fix_length(scipy.stats.kurtosis(S, axis=0), 199)\n",
        "\n",
        "    # --- B. STATIC FEATURES ---\n",
        "    # [cite_start]MFCC (39) [cite: 1553]\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=n_fft, hop_length=hop_length)\n",
        "    mfcc_combined = np.concatenate((mfcc, librosa.feature.delta(mfcc), librosa.feature.delta(mfcc, order=2)), axis=0)\n",
        "    mfcc_global = np.mean(mfcc_combined, axis=1)\n",
        "\n",
        "    # Scalars & Stats\n",
        "    rms_global = np.array([np.mean(librosa.feature.rms(y=y, frame_length=n_fft, hop_length=hop_length)[0])])\n",
        "    rolloff_global = np.array([np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)[0])])\n",
        "\n",
        "    # [cite_start]LPCC (13) [cite: 1599]\n",
        "    lpc_coeffs = librosa.lpc(y, order=13)\n",
        "    lpcc_global = lpc_coeffs[1:]\n",
        "    if len(lpcc_global) < 13: lpcc_global = np.pad(lpcc_global, (0, 13-len(lpcc_global)))\n",
        "\n",
        "    # [cite_start]Wavelet Packet Transform (56) [cite: 1668]\n",
        "    wp = pywt.WaveletPacket(data=y, wavelet='db2', mode='symmetric', maxlevel=3)\n",
        "    wpt_features = []\n",
        "    # Note: Loop is over only 8 nodes, so no tqdm needed here (too fast)\n",
        "    for node in wp.get_level(3, 'natural'):\n",
        "        d = node.data\n",
        "        wpt_features.extend([np.mean(d), np.median(d), np.std(d), np.var(d), scipy.stats.skew(d), scipy.stats.kurtosis(d), np.sum(d**2)])\n",
        "    wpt_global = np.array(wpt_features)\n",
        "\n",
        "    # [cite_start]Voice Quality (3) & Formants (5) [cite: 1614, 1629]\n",
        "    # PyIN is the slowest part of this function\n",
        "    f0, _, _ = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
        "    f0 = f0[~np.isnan(f0)]\n",
        "    pitch_val = np.mean(f0) if len(f0) > 0 else 0.0\n",
        "    jitter = (np.mean(np.abs(np.diff(f0))) / pitch_val) if pitch_val > 0 else 0.0\n",
        "    shimmer = 0.0\n",
        "    formants_vec = np.zeros(5)\n",
        "    vq_features = np.array([jitter, shimmer, pitch_val])\n",
        "\n",
        "    # [cite_start]Concatenate [cite: 1671]\n",
        "    return np.concatenate([mfcc_global, rms_global, zcr, centroid, lpcc_global, wpt_global, rolloff_global, kurtosis, vq_features, formants_vec])\n",
        "\n",
        "def _fix_length(arr, target_len):\n",
        "    if len(arr) < target_len: return np.pad(arr, (0, target_len - len(arr)))\n",
        "    return arr[:target_len]\n",
        "\n",
        "# ==========================================\n",
        "# 3. MAIN PROCESSING LOOP\n",
        "# ==========================================\n",
        "def process_emodb_data():\n",
        "    X_features = []\n",
        "    Y_labels = []\n",
        "    S_speakers = []\n",
        "\n",
        "    print(f\"Reading files from: {DATASET_PATH}\")\n",
        "\n",
        "    if not os.path.exists(DATASET_PATH):\n",
        "        print(\"Error: Dataset path does not exist.\")\n",
        "        return\n",
        "\n",
        "    files = [f for f in os.listdir(DATASET_PATH) if f.endswith('.wav')]\n",
        "    print(f\"Found {len(files)} .wav files.\")\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    # <--- TQDM ADDED HERE: This tracks the main bottleneck (file processing)\n",
        "    for file_name in tqdm(files, desc=\"Extracting Features\", unit=\"file\"):\n",
        "        file_path = os.path.join(DATASET_PATH, file_name)\n",
        "\n",
        "        try:\n",
        "            # 1. Extract Info from Filename\n",
        "            speaker_id = file_name[0:2]\n",
        "            emotion_code = file_name[5]\n",
        "\n",
        "            # 2. Validate Emotion Code\n",
        "            if emotion_code not in CODE_TO_EMOTION:\n",
        "                # Use tqdm.write so the print doesn't break the progress bar\n",
        "                tqdm.write(f\"Skipping {file_name}: Unknown code '{emotion_code}'\")\n",
        "                continue\n",
        "\n",
        "            emotion_name = CODE_TO_EMOTION[emotion_code]\n",
        "            label_int = EMOTION_TO_INT[emotion_name]\n",
        "\n",
        "            # 3. Extract Features (This takes the most time)\n",
        "            features = extract_bhangale_features(file_path)\n",
        "\n",
        "            # 4. Store\n",
        "            if features.shape[0] == 715:\n",
        "                X_features.append(features)\n",
        "                Y_labels.append(label_int)\n",
        "                S_speakers.append(speaker_id)\n",
        "                count += 1\n",
        "            else:\n",
        "                tqdm.write(f\"Error shape {features.shape} in {file_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 4. SAVE ARRAYS\n",
        "    # ==========================================\n",
        "    print(\"\\nConverting to Numpy Arrays...\")\n",
        "    X = np.array(X_features)\n",
        "    Y = np.array(Y_labels)\n",
        "    S = np.array(S_speakers)\n",
        "\n",
        "    # Reshape X for the 1D CNN: (Batch, 715, 1)\n",
        "    X = X[..., np.newaxis]\n",
        "\n",
        "    print(f\"Processed: {count} files\")\n",
        "    print(f\"X Shape: {X.shape}\")\n",
        "    print(f\"Y Shape: {Y.shape}\")\n",
        "    print(f\"Speakers: {len(np.unique(S))}\")\n",
        "\n",
        "    if not os.path.exists(OUTPUT_PATH):\n",
        "        os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "    print(f\"Saving .npy files to {OUTPUT_PATH}...\")\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"X_emodb.npy\"), X)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"Y_emodb.npy\"), Y)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"S_emodb.npy\"), S)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_emodb_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZobIGWKJxpw",
        "outputId": "c2253165-3d0d-4d55-ab87-2f3dc543f03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading files from: /content/drive/MyDrive/DeepLearning/External/EMoDB/\n",
            "Found 535 .wav files.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features:  16%|█▋        | 87/535 [02:01<09:01,  1.21s/file]/tmp/ipython-input-2224402440.py:57: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  kurtosis = _fix_length(scipy.stats.kurtosis(S, axis=0), 199)\n",
            "Extracting Features:  25%|██▌       | 135/535 [03:02<09:18,  1.40s/file]"
          ]
        }
      ]
    }
  ]
}