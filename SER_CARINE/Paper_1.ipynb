{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjpPxoiot1fqo/vtvONvyY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/SER_CARINE/Paper_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa numpy scipy PyWavelets\n",
        "DATASET_PATH = \"/content/drive/MyDrive/DeepLearning/External/EMoDB/\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u07C48dbE7xq",
        "outputId": "8646a19f-02c3-4006-d3d2-6154504187ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (1.9.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.stats\n",
        "import pywt\n",
        "from scipy.signal import lfilter\n",
        "from tqdm import tqdm  # <--- NEW IMPORT\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP & CONFIGURATION\n",
        "# ==========================================\n",
        "DATASET_PATH = \"/content/drive/MyDrive/DeepLearning/External/EMoDB/\"\n",
        "OUTPUT_PATH = \"processed_data/\"\n",
        "\n",
        "CLASSES = ['Angry', 'Boredom', 'Disgust', 'Anxiety', 'Happiness', 'Sadness', 'Neutral']\n",
        "\n",
        "CODE_TO_EMOTION = {\n",
        "    'W': 'Angry',\n",
        "    'L': 'Boredom',\n",
        "    'E': 'Disgust',\n",
        "    'A': 'Anxiety',\n",
        "    'F': 'Happiness',\n",
        "    'T': 'Sadness',\n",
        "    'N': 'Neutral'\n",
        "}\n",
        "\n",
        "EMOTION_TO_INT = {label: i for i, label in enumerate(CLASSES)}\n",
        "\n",
        "# ==========================================\n",
        "# 2. FEATURE EXTRACTOR\n",
        "# ==========================================\n",
        "def extract_bhangale_features(audio_path):\n",
        "    \"\"\"\n",
        "    Extracts the exact 715-dim feature vector described in Bhangale et al. (2023).\n",
        "    \"\"\"\n",
        "    # [cite_start]Load audio, Resample to 16kHz [cite: 1795]\n",
        "    y, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "    # [cite_start]Standardize to 4 seconds (64000 samples) [cite: 1796]\n",
        "    target_length = 64000\n",
        "    if len(y) < target_length:\n",
        "        y = np.pad(y, (0, target_length - len(y)))\n",
        "    else:\n",
        "        y = y[:target_length]\n",
        "\n",
        "    # [cite_start]Pre-emphasis filter [cite: 1528]\n",
        "    y = lfilter([1, -0.97], [1], y)\n",
        "\n",
        "    # [cite_start]Frame Settings: 40ms window, 50% overlap [cite: 1529]\n",
        "    n_fft = 640\n",
        "    hop_length = 320\n",
        "\n",
        "    # --- A. TIME-SERIES FEATURES (Length 199 each) ---\n",
        "    zcr = _fix_length(librosa.feature.zero_crossing_rate(y, frame_length=n_fft, hop_length=hop_length)[0], 199)\n",
        "    centroid = _fix_length(librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)[0], 199)\n",
        "    S = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))\n",
        "    kurtosis = _fix_length(scipy.stats.kurtosis(S, axis=0), 199)\n",
        "\n",
        "    # --- B. STATIC FEATURES ---\n",
        "    # [cite_start]MFCC (39) [cite: 1553]\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=n_fft, hop_length=hop_length)\n",
        "    mfcc_combined = np.concatenate((mfcc, librosa.feature.delta(mfcc), librosa.feature.delta(mfcc, order=2)), axis=0)\n",
        "    mfcc_global = np.mean(mfcc_combined, axis=1)\n",
        "\n",
        "    # Scalars & Stats\n",
        "    rms_global = np.array([np.mean(librosa.feature.rms(y=y, frame_length=n_fft, hop_length=hop_length)[0])])\n",
        "    rolloff_global = np.array([np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)[0])])\n",
        "\n",
        "    # [cite_start]LPCC (13) [cite: 1599]\n",
        "    lpc_coeffs = librosa.lpc(y, order=13)\n",
        "    lpcc_global = lpc_coeffs[1:]\n",
        "    if len(lpcc_global) < 13: lpcc_global = np.pad(lpcc_global, (0, 13-len(lpcc_global)))\n",
        "\n",
        "    # [cite_start]Wavelet Packet Transform (56) [cite: 1668]\n",
        "    wp = pywt.WaveletPacket(data=y, wavelet='db2', mode='symmetric', maxlevel=3)\n",
        "    wpt_features = []\n",
        "    # Note: Loop is over only 8 nodes, so no tqdm needed here (too fast)\n",
        "    for node in wp.get_level(3, 'natural'):\n",
        "        d = node.data\n",
        "        wpt_features.extend([np.mean(d), np.median(d), np.std(d), np.var(d), scipy.stats.skew(d), scipy.stats.kurtosis(d), np.sum(d**2)])\n",
        "    wpt_global = np.array(wpt_features)\n",
        "\n",
        "    # [cite_start]Voice Quality (3) & Formants (5) [cite: 1614, 1629]\n",
        "    # PyIN is the slowest part of this function\n",
        "    f0, _, _ = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
        "    f0 = f0[~np.isnan(f0)]\n",
        "    pitch_val = np.mean(f0) if len(f0) > 0 else 0.0\n",
        "    jitter = (np.mean(np.abs(np.diff(f0))) / pitch_val) if pitch_val > 0 else 0.0\n",
        "    shimmer = 0.0\n",
        "    formants_vec = np.zeros(5)\n",
        "    vq_features = np.array([jitter, shimmer, pitch_val])\n",
        "\n",
        "    # [cite_start]Concatenate [cite: 1671]\n",
        "    return np.concatenate([mfcc_global, rms_global, zcr, centroid, lpcc_global, wpt_global, rolloff_global, kurtosis, vq_features, formants_vec])\n",
        "\n",
        "def _fix_length(arr, target_len):\n",
        "    if len(arr) < target_len: return np.pad(arr, (0, target_len - len(arr)))\n",
        "    return arr[:target_len]\n",
        "\n",
        "# ==========================================\n",
        "# 3. MAIN PROCESSING LOOP\n",
        "# ==========================================\n",
        "def process_emodb_data():\n",
        "    X_features = []\n",
        "    Y_labels = []\n",
        "    S_speakers = []\n",
        "\n",
        "    print(f\"Reading files from: {DATASET_PATH}\")\n",
        "\n",
        "    if not os.path.exists(DATASET_PATH):\n",
        "        print(\"Error: Dataset path does not exist.\")\n",
        "        return\n",
        "\n",
        "    files = [f for f in os.listdir(DATASET_PATH) if f.endswith('.wav')]\n",
        "    print(f\"Found {len(files)} .wav files.\")\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    # <--- TQDM ADDED HERE: This tracks the main bottleneck (file processing)\n",
        "    for file_name in tqdm(files, desc=\"Extracting Features\", unit=\"file\"):\n",
        "        file_path = os.path.join(DATASET_PATH, file_name)\n",
        "\n",
        "        try:\n",
        "            # 1. Extract Info from Filename\n",
        "            speaker_id = file_name[0:2]\n",
        "            emotion_code = file_name[5]\n",
        "\n",
        "            # 2. Validate Emotion Code\n",
        "            if emotion_code not in CODE_TO_EMOTION:\n",
        "                # Use tqdm.write so the print doesn't break the progress bar\n",
        "                tqdm.write(f\"Skipping {file_name}: Unknown code '{emotion_code}'\")\n",
        "                continue\n",
        "\n",
        "            emotion_name = CODE_TO_EMOTION[emotion_code]\n",
        "            label_int = EMOTION_TO_INT[emotion_name]\n",
        "\n",
        "            # 3. Extract Features (This takes the most time)\n",
        "            features = extract_bhangale_features(file_path)\n",
        "\n",
        "            # 4. Store\n",
        "            if features.shape[0] == 715:\n",
        "                X_features.append(features)\n",
        "                Y_labels.append(label_int)\n",
        "                S_speakers.append(speaker_id)\n",
        "                count += 1\n",
        "            else:\n",
        "                tqdm.write(f\"Error shape {features.shape} in {file_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 4. SAVE ARRAYS\n",
        "    # ==========================================\n",
        "    print(\"\\nConverting to Numpy Arrays...\")\n",
        "    X = np.array(X_features)\n",
        "    Y = np.array(Y_labels)\n",
        "    S = np.array(S_speakers)\n",
        "\n",
        "    # Reshape X for the 1D CNN: (Batch, 715, 1)\n",
        "    X = X[..., np.newaxis]\n",
        "\n",
        "    print(f\"Processed: {count} files\")\n",
        "    print(f\"X Shape: {X.shape}\")\n",
        "    print(f\"Y Shape: {Y.shape}\")\n",
        "    print(f\"Speakers: {len(np.unique(S))}\")\n",
        "\n",
        "    if not os.path.exists(OUTPUT_PATH):\n",
        "        os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "    print(f\"Saving .npy files to {OUTPUT_PATH}...\")\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"X_emodb.npy\"), X)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"Y_emodb.npy\"), Y)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"S_emodb.npy\"), S)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_emodb_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZobIGWKJxpw",
        "outputId": "c2253165-3d0d-4d55-ab87-2f3dc543f03b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading files from: /content/drive/MyDrive/DeepLearning/External/EMoDB/\n",
            "Found 535 .wav files.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features:  16%|█▋        | 87/535 [02:01<09:01,  1.21s/file]/tmp/ipython-input-2224402440.py:57: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  kurtosis = _fix_length(scipy.stats.kurtosis(S, axis=0), 199)\n",
            "Extracting Features: 100%|██████████| 535/535 [11:27<00:00,  1.28s/file]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Converting to Numpy Arrays...\n",
            "Processed: 535 files\n",
            "X Shape: (535, 715, 1)\n",
            "Y Shape: (535,)\n",
            "Speakers: 10\n",
            "Saving .npy files to processed_data/...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Syntax: !zip -r <name_of_new_zip_file> <folder_to_zip>\n",
        "!zip -r processed_data.zip processed_data/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43DUM7ZBRtAn",
        "outputId": "7ca387c4-6f1d-4ac6-a6aa-ad8ff77b1131"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: processed_data/ (stored 0%)\n",
            "  adding: processed_data/Y_emodb.npy (deflated 88%)\n",
            "  adding: processed_data/X_emodb.npy (deflated 43%)\n",
            "  adding: processed_data/S_emodb.npy (deflated 90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q processed_data.zip -d ./"
      ],
      "metadata": {
        "id": "dIJFzFzX8Ho0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD DATA\n",
        "# ==========================================\n",
        "DATA_PATH = \"processed_data/\"\n",
        "\n",
        "print(\"Loading data...\")\n",
        "X = np.load(os.path.join(DATA_PATH, \"X_emodb.npy\"))\n",
        "Y = np.load(os.path.join(DATA_PATH, \"Y_emodb.npy\"))\n",
        "\n",
        "# Verify Shapes\n",
        "# Input should be (535, 715, 1)\n",
        "# Output should be (535,)\n",
        "print(f\"Features: {X.shape}\")\n",
        "print(f\"Labels: {Y.shape}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. REPLICATE PAPER SPLIT (70:30)\n",
        "# ==========================================\n",
        "# The paper states: \"The data is split in the ratio of 70:30 for training and testing\" [cite: 667]\n",
        "# We use 'stratify=Y' to ensure every emotion is represented fairly, just like a good paper would.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    stratify=Y\n",
        ")\n",
        "\n",
        "print(f\"Training Samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing Samples: {X_test.shape[0]}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. BUILD MODEL (Exact Architecture)\n",
        "# ==========================================\n",
        "# Reference: Table 1 and Section 3 [cite: 586-610, 626]\n",
        "\n",
        "def build_bhangale_1d_cnn():\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # --- Conv Block 1 ---\n",
        "    # \"Conv1 (Filters: 32, Filter Size: 1x3, Stride: 1, Padding: Yes) -> ReLU1\" [cite: 587]\n",
        "    model.add(layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', input_shape=(715, 1)))\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    # --- Conv Block 2 ---\n",
        "    # \"Conv2 (Filters: 64, Filter Size: 1x3... Padding: Yes) -> ReLU2\" [cite: 589]\n",
        "    model.add(layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    # --- Conv Block 3 ---\n",
        "    # \"Conv3 (Filters: 128, Filter Size: 1x3... Padding: Yes) -> ReLU3\" [cite: 590]\n",
        "    model.add(layers.Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    # --- Flatten ---\n",
        "    # \"Following the 3 CNN layers... Flattening\"\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # --- Fully Connected Layers ---\n",
        "    # \"2 fully connected layers are used having 20 and 7 hidden layers\" [cite: 604]\n",
        "\n",
        "    # FC 1 (20 Neurons)\n",
        "    model.add(layers.Dense(20))\n",
        "    model.add(layers.ReLU()) # Non-linear activation implied by Eq 37 [cite: 606]\n",
        "\n",
        "    # FC 2 (Output, 7 Neurons for EMODB)\n",
        "    model.add(layers.Dense(7))\n",
        "\n",
        "    # Softmax Classifier [cite: 610]\n",
        "    model.add(layers.Softmax())\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_bhangale_1d_cnn()\n",
        "model.summary()\n",
        "\n",
        "# Check trainable params. Paper says \"1.77 M\".\n",
        "# Our Summary should show approx ~1.7 to 1.8 Million.\n",
        "\n",
        "# ==========================================\n",
        "# 4. COMPILE & TRAIN\n",
        "# ==========================================\n",
        "# \"trained using stochastic gradient descent with momentum (SGDM)\" [cite: 622]\n",
        "# \"batch size of 64\" [cite: 623]\n",
        "# \"200 epochs\" [cite: 624]\n",
        "# \"initial learning rate of 0.001, and momentum of 0.9\" [cite: 624]\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy', # Used because Y is integers (0, 1, 2...), not one-hot vectors\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "4th2EG6JQu7K",
        "outputId": "6efd2311-fae0-48d1-dfd7-de3ff8a59665"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Features: (535, 715, 1)\n",
            "Labels: (535,)\n",
            "Training Samples: 374\n",
            "Testing Samples: 161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91520\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │     \u001b[38;5;34m1,830,420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m147\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91520</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,830,420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,861,607\u001b[0m (7.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,861,607</span> (7.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,861,607\u001b[0m (7.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,861,607</span> (7.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStarting Training (Replication Mode)...\")\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 5. FINAL EVALUATION\n",
        "# ==========================================\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"\\n------------------------------------------------\")\n",
        "print(f\"FINAL REPLICATION RESULT:\")\n",
        "print(f\"Target Accuracy (Paper): ~93.31%\")\n",
        "print(f\"Achieved Accuracy:       {test_acc*100:.2f}%\")\n",
        "print(\"------------------------------------------------\")\n",
        "\n",
        "# Plotting to verify convergence (optional)\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Test')\n",
        "plt.title('Model Accuracy Replication')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F-8x34qj8fv0",
        "outputId": "ea685372-6652-48f3-fd7a-698affb4a239"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Training (Replication Mode)...\n",
            "Epoch 1/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.1520 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 2/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1508 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 3/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1603 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 4/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 5/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1471 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 6/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1545 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 7/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1348 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 8/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1324 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 9/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1406 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 10/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1513 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 11/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1374 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 12/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1312 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 13/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1255 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 14/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1440 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 15/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1668 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 16/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1309 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 17/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1538 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 18/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1434 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 19/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1451 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 20/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1595 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 21/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1396 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 22/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1405 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 23/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1485 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 24/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1555 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 25/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1237 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 26/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1504 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 27/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1451 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 28/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1507 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 29/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1535 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 30/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1243 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 31/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1283 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 32/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1661 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 33/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1239 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 34/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1355 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 35/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1371 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 36/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1482 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 37/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1477 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 38/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1674 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 39/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1469 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 40/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1601 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 41/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1460 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 42/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1597 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 43/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1480 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 44/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1799 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 45/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1647 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 46/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1427 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 47/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1278 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 48/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1409 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 49/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1506 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 50/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1517 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 51/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1547 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 52/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1617 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 53/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1412 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 54/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1355 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 55/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1397 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 56/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1451 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 57/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1621 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 58/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1339 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 59/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1405 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 60/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1489 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 61/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1359 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 62/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1568 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 63/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1498 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 64/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1488 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 65/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1421 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 66/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1316 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 67/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1288 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 68/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1494 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 69/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1612 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 70/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1661 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 71/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1470 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 72/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1502 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 73/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1530 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 74/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1547 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 75/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1526 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 76/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1450 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 77/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1527 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 78/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1408 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 79/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1605 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 80/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1660 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 81/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1429 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 82/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1476 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 83/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1231 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 84/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1428 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 85/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1644 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 86/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1494 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 87/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1406 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 88/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1437 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 89/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1405 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 90/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1698 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 91/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1460 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 92/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1575 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 93/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1380 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 94/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1358 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 95/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1489 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 96/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1649 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 97/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1249 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 98/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1681 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 99/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1553 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 100/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1368 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 101/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1594 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 102/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1657 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 103/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1490 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 104/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1384 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 105/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1540 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 106/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1448 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 107/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1361 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 108/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1469 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 109/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1545 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 110/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1594 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 111/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1533 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 112/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1291 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 113/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1467 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 114/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1468 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 115/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1546 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 116/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1444 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 117/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1619 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 118/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1437 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 119/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 120/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1444 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 121/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1395 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 122/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1346 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 123/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1512 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 124/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1602 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 125/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1329 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 126/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1475 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 127/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1243 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 128/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1440 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 129/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1567 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 130/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1488 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 131/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1407 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 132/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1493 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 133/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1546 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 134/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1285 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 135/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1552 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 136/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1290 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 137/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1531 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 138/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1345 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 139/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1518 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 140/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1250 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 141/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1732 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 142/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1383 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 143/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1445 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 144/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1626 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 145/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1410 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 146/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1461 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 147/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1288 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 148/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1310 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 149/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1442 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 150/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1358 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 151/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1453 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 152/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1435 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 153/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1418 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 154/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1365 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 155/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1615 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 156/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1467 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 157/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1728 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 158/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1460 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 159/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1375 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 160/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1512 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 161/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1422 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 162/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1400 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 163/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1486 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 164/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1426 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 165/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1486 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 166/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1542 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 167/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1357 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 168/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1641 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 169/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1378 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 170/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1527 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 171/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1375 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 172/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1533 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 173/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1566 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 174/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1486 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 175/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1503 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 176/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1516 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 177/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1367 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 178/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1466 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 179/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1538 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 180/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1589 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 181/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1356 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 182/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1377 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 183/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1436 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 184/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1372 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 185/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1337 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 186/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1566 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 187/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1497 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 188/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1401 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 189/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1368 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 190/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1172 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 191/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1443 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 192/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1388 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 193/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1803 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 194/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1439 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 195/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1409 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 196/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1978 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 197/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1569 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 198/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1388 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 199/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1496 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "Epoch 200/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1596 - loss: nan - val_accuracy: 0.1491 - val_loss: nan\n",
            "\n",
            "------------------------------------------------\n",
            "FINAL REPLICATION RESULT:\n",
            "Target Accuracy (Paper): ~93.31%\n",
            "Achieved Accuracy:       14.91%\n",
            "------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}