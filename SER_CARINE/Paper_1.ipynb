{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiRNuijgsPiuaJl+owuhUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/SER_CARINE/Paper_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa numpy scipy PyWavelets\n",
        "DATASET_PATH = \"/content/drive/MyDrive/DeepLearning/External/EMoDB/\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u07C48dbE7xq",
        "outputId": "8646a19f-02c3-4006-d3d2-6154504187ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (1.9.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.stats\n",
        "import pywt\n",
        "from scipy.signal import lfilter\n",
        "from tqdm import tqdm  # <--- NEW IMPORT\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP & CONFIGURATION\n",
        "# ==========================================\n",
        "DATASET_PATH = \"/content/drive/MyDrive/DeepLearning/External/EMoDB/\"\n",
        "OUTPUT_PATH = \"processed_data/\"\n",
        "\n",
        "CLASSES = ['Angry', 'Boredom', 'Disgust', 'Anxiety', 'Happiness', 'Sadness', 'Neutral']\n",
        "\n",
        "CODE_TO_EMOTION = {\n",
        "    'W': 'Angry',\n",
        "    'L': 'Boredom',\n",
        "    'E': 'Disgust',\n",
        "    'A': 'Anxiety',\n",
        "    'F': 'Happiness',\n",
        "    'T': 'Sadness',\n",
        "    'N': 'Neutral'\n",
        "}\n",
        "\n",
        "EMOTION_TO_INT = {label: i for i, label in enumerate(CLASSES)}\n",
        "\n",
        "# ==========================================\n",
        "# 2. FEATURE EXTRACTOR\n",
        "# ==========================================\n",
        "def extract_bhangale_features(audio_path):\n",
        "    \"\"\"\n",
        "    Extracts the exact 715-dim feature vector described in Bhangale et al. (2023).\n",
        "    \"\"\"\n",
        "    # [cite_start]Load audio, Resample to 16kHz [cite: 1795]\n",
        "    y, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "    # [cite_start]Standardize to 4 seconds (64000 samples) [cite: 1796]\n",
        "    target_length = 64000\n",
        "    if len(y) < target_length:\n",
        "        y = np.pad(y, (0, target_length - len(y)))\n",
        "    else:\n",
        "        y = y[:target_length]\n",
        "\n",
        "    # [cite_start]Pre-emphasis filter [cite: 1528]\n",
        "    y = lfilter([1, -0.97], [1], y)\n",
        "\n",
        "    # [cite_start]Frame Settings: 40ms window, 50% overlap [cite: 1529]\n",
        "    n_fft = 640\n",
        "    hop_length = 320\n",
        "\n",
        "    # --- A. TIME-SERIES FEATURES (Length 199 each) ---\n",
        "    zcr = _fix_length(librosa.feature.zero_crossing_rate(y, frame_length=n_fft, hop_length=hop_length)[0], 199)\n",
        "    centroid = _fix_length(librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)[0], 199)\n",
        "    S = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))\n",
        "    kurtosis = _fix_length(scipy.stats.kurtosis(S, axis=0), 199)\n",
        "\n",
        "    # --- B. STATIC FEATURES ---\n",
        "    # [cite_start]MFCC (39) [cite: 1553]\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=n_fft, hop_length=hop_length)\n",
        "    mfcc_combined = np.concatenate((mfcc, librosa.feature.delta(mfcc), librosa.feature.delta(mfcc, order=2)), axis=0)\n",
        "    mfcc_global = np.mean(mfcc_combined, axis=1)\n",
        "\n",
        "    # Scalars & Stats\n",
        "    rms_global = np.array([np.mean(librosa.feature.rms(y=y, frame_length=n_fft, hop_length=hop_length)[0])])\n",
        "    rolloff_global = np.array([np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)[0])])\n",
        "\n",
        "    # [cite_start]LPCC (13) [cite: 1599]\n",
        "    lpc_coeffs = librosa.lpc(y, order=13)\n",
        "    lpcc_global = lpc_coeffs[1:]\n",
        "    if len(lpcc_global) < 13: lpcc_global = np.pad(lpcc_global, (0, 13-len(lpcc_global)))\n",
        "\n",
        "    # [cite_start]Wavelet Packet Transform (56) [cite: 1668]\n",
        "    wp = pywt.WaveletPacket(data=y, wavelet='db2', mode='symmetric', maxlevel=3)\n",
        "    wpt_features = []\n",
        "    # Note: Loop is over only 8 nodes, so no tqdm needed here (too fast)\n",
        "    for node in wp.get_level(3, 'natural'):\n",
        "        d = node.data\n",
        "        wpt_features.extend([np.mean(d), np.median(d), np.std(d), np.var(d), scipy.stats.skew(d), scipy.stats.kurtosis(d), np.sum(d**2)])\n",
        "    wpt_global = np.array(wpt_features)\n",
        "\n",
        "    # [cite_start]Voice Quality (3) & Formants (5) [cite: 1614, 1629]\n",
        "    # PyIN is the slowest part of this function\n",
        "    f0, _, _ = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
        "    f0 = f0[~np.isnan(f0)]\n",
        "    pitch_val = np.mean(f0) if len(f0) > 0 else 0.0\n",
        "    jitter = (np.mean(np.abs(np.diff(f0))) / pitch_val) if pitch_val > 0 else 0.0\n",
        "    shimmer = 0.0\n",
        "    formants_vec = np.zeros(5)\n",
        "    vq_features = np.array([jitter, shimmer, pitch_val])\n",
        "\n",
        "    # [cite_start]Concatenate [cite: 1671]\n",
        "    return np.concatenate([mfcc_global, rms_global, zcr, centroid, lpcc_global, wpt_global, rolloff_global, kurtosis, vq_features, formants_vec])\n",
        "\n",
        "def _fix_length(arr, target_len):\n",
        "    if len(arr) < target_len: return np.pad(arr, (0, target_len - len(arr)))\n",
        "    return arr[:target_len]\n",
        "\n",
        "# ==========================================\n",
        "# 3. MAIN PROCESSING LOOP\n",
        "# ==========================================\n",
        "def process_emodb_data():\n",
        "    X_features = []\n",
        "    Y_labels = []\n",
        "    S_speakers = []\n",
        "\n",
        "    print(f\"Reading files from: {DATASET_PATH}\")\n",
        "\n",
        "    if not os.path.exists(DATASET_PATH):\n",
        "        print(\"Error: Dataset path does not exist.\")\n",
        "        return\n",
        "\n",
        "    files = [f for f in os.listdir(DATASET_PATH) if f.endswith('.wav')]\n",
        "    print(f\"Found {len(files)} .wav files.\")\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    # <--- TQDM ADDED HERE: This tracks the main bottleneck (file processing)\n",
        "    for file_name in tqdm(files, desc=\"Extracting Features\", unit=\"file\"):\n",
        "        file_path = os.path.join(DATASET_PATH, file_name)\n",
        "\n",
        "        try:\n",
        "            # 1. Extract Info from Filename\n",
        "            speaker_id = file_name[0:2]\n",
        "            emotion_code = file_name[5]\n",
        "\n",
        "            # 2. Validate Emotion Code\n",
        "            if emotion_code not in CODE_TO_EMOTION:\n",
        "                # Use tqdm.write so the print doesn't break the progress bar\n",
        "                tqdm.write(f\"Skipping {file_name}: Unknown code '{emotion_code}'\")\n",
        "                continue\n",
        "\n",
        "            emotion_name = CODE_TO_EMOTION[emotion_code]\n",
        "            label_int = EMOTION_TO_INT[emotion_name]\n",
        "\n",
        "            # 3. Extract Features (This takes the most time)\n",
        "            features = extract_bhangale_features(file_path)\n",
        "\n",
        "            # 4. Store\n",
        "            if features.shape[0] == 715:\n",
        "                X_features.append(features)\n",
        "                Y_labels.append(label_int)\n",
        "                S_speakers.append(speaker_id)\n",
        "                count += 1\n",
        "            else:\n",
        "                tqdm.write(f\"Error shape {features.shape} in {file_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 4. SAVE ARRAYS\n",
        "    # ==========================================\n",
        "    print(\"\\nConverting to Numpy Arrays...\")\n",
        "    X = np.array(X_features)\n",
        "    Y = np.array(Y_labels)\n",
        "    S = np.array(S_speakers)\n",
        "\n",
        "    # Reshape X for the 1D CNN: (Batch, 715, 1)\n",
        "    X = X[..., np.newaxis]\n",
        "\n",
        "    print(f\"Processed: {count} files\")\n",
        "    print(f\"X Shape: {X.shape}\")\n",
        "    print(f\"Y Shape: {Y.shape}\")\n",
        "    print(f\"Speakers: {len(np.unique(S))}\")\n",
        "\n",
        "    if not os.path.exists(OUTPUT_PATH):\n",
        "        os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "    print(f\"Saving .npy files to {OUTPUT_PATH}...\")\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"X_emodb.npy\"), X)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"Y_emodb.npy\"), Y)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"S_emodb.npy\"), S)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_emodb_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZobIGWKJxpw",
        "outputId": "c2253165-3d0d-4d55-ab87-2f3dc543f03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading files from: /content/drive/MyDrive/DeepLearning/External/EMoDB/\n",
            "Found 535 .wav files.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features:  16%|█▋        | 87/535 [02:01<09:01,  1.21s/file]/tmp/ipython-input-2224402440.py:57: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  kurtosis = _fix_length(scipy.stats.kurtosis(S, axis=0), 199)\n",
            "Extracting Features: 100%|██████████| 535/535 [11:27<00:00,  1.28s/file]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Converting to Numpy Arrays...\n",
            "Processed: 535 files\n",
            "X Shape: (535, 715, 1)\n",
            "Y Shape: (535,)\n",
            "Speakers: 10\n",
            "Saving .npy files to processed_data/...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Syntax: !zip -r <name_of_new_zip_file> <folder_to_zip>\n",
        "!zip -r processed_data.zip processed_data/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43DUM7ZBRtAn",
        "outputId": "7ca387c4-6f1d-4ac6-a6aa-ad8ff77b1131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: processed_data/ (stored 0%)\n",
            "  adding: processed_data/Y_emodb.npy (deflated 88%)\n",
            "  adding: processed_data/X_emodb.npy (deflated 43%)\n",
            "  adding: processed_data/S_emodb.npy (deflated 90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q processed_data.zip -d ./"
      ],
      "metadata": {
        "id": "dIJFzFzX8Ho0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler # Added for standardization\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD DATA\n",
        "# ==========================================\n",
        "DATA_PATH = \"processed_data/\"\n",
        "\n",
        "print(\"Loading data...\")\n",
        "X = np.load(os.path.join(DATA_PATH, \"X_emodb.npy\"))\n",
        "Y = np.load(os.path.join(DATA_PATH, \"Y_emodb.npy\"))\n",
        "\n",
        "# Handle NaN values by replacing them with zeros (as requested)\n",
        "X = np.nan_to_num(X, nan=0.0)\n",
        "\n",
        "# Verify Shapes\n",
        "# Input should be (535, 715, 1)\n",
        "# Output should be (535,)\n",
        "print(f\"Features: {X.shape}\")\n",
        "print(f\"Labels: {Y.shape}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. REPLICATE PAPER SPLIT (70:30)\n",
        "# ==========================================\n",
        "# The paper states: \"The data is split in the ratio of 70:30 for training and testing\" [cite: 667]\n",
        "# We use 'stratify=Y' to ensure every emotion is represented fairly, just like a good paper would.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    stratify=Y\n",
        ")\n",
        "\n",
        "print(f\"Training Samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing Samples: {X_test.shape[0]}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. APPLY MEAN/STD SCALING (Standardization)\n",
        "# ==========================================\n",
        "# Apply StandardScaler using only the training data to prevent data leakage\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Reshape X_train and X_test for the scaler, which expects 2D data (samples, features)\n",
        "# After scaling, reshape back to (samples, features, 1) for the Conv1D layer\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "X_train = X_train_scaled.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test_scaled.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "print(f\"X_train (scaled) Shape: {X_train.shape}\")\n",
        "print(f\"X_test (scaled) Shape: {X_test.shape}\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 4. BUILD MODEL (Exact Architecture)\n",
        "# ==========================================\n",
        "# Reference: Table 1 and Section 3 [cite: 586-610, 626]\n",
        "\n",
        "def build_bhangale_1d_cnn():\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # --- Conv Block 1 ---\n",
        "    # \"Conv1 (Filters: 32, Filter Size: 1x3, Stride: 1, Padding: Yes) -> ReLU1\" [cite: 587]\n",
        "    model.add(layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', input_shape=(715, 1)))\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    # --- Conv Block 2 ---\n",
        "    # \"Conv2 (Filters: 64, Filter Size: 1x3... Padding: Yes) -> ReLU2\" [cite: 589]\n",
        "    model.add(layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    # --- Conv Block 3 ---\n",
        "    # \"Conv3 (Filters: 128, Filter Size: 1x3... Padding: Yes) -> ReLU3\" [cite: 590]\n",
        "    model.add(layers.Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    # --- Flatten ---\n",
        "    # \"Following the 3 CNN layers... Flattening\"\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # --- Fully Connected Layers ---\n",
        "    # \"2 fully connected layers are used having 20 and 7 hidden layers\" [cite: 604]\n",
        "\n",
        "    # FC 1 (20 Neurons)\n",
        "    model.add(layers.Dense(20))\n",
        "\n",
        "    # FC 2 (Output, 7 Neurons for EMODB)\n",
        "    model.add(layers.Dense(7))\n",
        "\n",
        "    # Softmax Classifier [cite: 610]\n",
        "    # Removed: model.add(layers.ReLU()) as it's typically not used before softmax for classification\n",
        "    model.add(layers.Softmax())\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_bhangale_1d_cnn()\n",
        "model.summary()\n",
        "\n",
        "# Check trainable params. Paper says \"1.77 M\".\n",
        "# Our Summary should show approx ~1.7 to 1.8 Million.\n",
        "\n",
        "# ==========================================\n",
        "# 5. COMPILE & TRAIN\n",
        "# ==========================================\n",
        "# \"trained using stochastic gradient descent with momentum (SGDM)\" [cite: 622]\n",
        "# \"batch size of 64\" [cite: 623]\n",
        "# \"200 epochs\" [cite: 624]\n",
        "# \"initial learning rate of 0.001, and momentum of 0.9\" [cite: 624]\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy', # Used because Y is integers (0, 1, 2...), not one-hot vectors\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "4th2EG6JQu7K",
        "outputId": "2366fa9e-7633-447f-9a81-32bf1411c9df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Features: (535, 715, 1)\n",
            "Labels: (535,)\n",
            "Training Samples: 374\n",
            "Testing Samples: 161\n",
            "X_train (scaled) Shape: (374, 715, 1)\n",
            "X_test (scaled) Shape: (161, 715, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m715\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91520\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │     \u001b[38;5;34m1,830,420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m147\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax_1 (\u001b[38;5;33mSoftmax\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91520</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,830,420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,861,607\u001b[0m (7.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,861,607</span> (7.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,861,607\u001b[0m (7.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,861,607</span> (7.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStarting Training (Replication Mode)...\")\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 5. FINAL EVALUATION\n",
        "# ==========================================\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"\\n------------------------------------------------\")\n",
        "print(f\"FINAL REPLICATION RESULT:\")\n",
        "print(f\"Target Accuracy (Paper): ~93.31%\")\n",
        "print(f\"Achieved Accuracy:       {test_acc*100:.2f}%\")\n",
        "print(\"------------------------------------------------\")\n",
        "\n",
        "# Plotting to verify convergence (optional)\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Test')\n",
        "plt.title('Model Accuracy Replication')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F-8x34qj8fv0",
        "outputId": "aefd3771-f497-48ce-aae4-a8e9654ec358"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Training (Replication Mode)...\n",
            "Epoch 1/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - accuracy: 0.1884 - loss: 1.9297 - val_accuracy: 0.2484 - val_loss: 1.8750\n",
            "Epoch 2/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2511 - loss: 1.8534 - val_accuracy: 0.2547 - val_loss: 1.8202\n",
            "Epoch 3/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2753 - loss: 1.7551 - val_accuracy: 0.3540 - val_loss: 1.7451\n",
            "Epoch 4/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3657 - loss: 1.6804 - val_accuracy: 0.3602 - val_loss: 1.6821\n",
            "Epoch 5/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4280 - loss: 1.5918 - val_accuracy: 0.4596 - val_loss: 1.6162\n",
            "Epoch 6/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4820 - loss: 1.4930 - val_accuracy: 0.4596 - val_loss: 1.5517\n",
            "Epoch 7/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5331 - loss: 1.4017 - val_accuracy: 0.5093 - val_loss: 1.4938\n",
            "Epoch 8/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5409 - loss: 1.3298 - val_accuracy: 0.4845 - val_loss: 1.4413\n",
            "Epoch 9/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5546 - loss: 1.2443 - val_accuracy: 0.4969 - val_loss: 1.3945\n",
            "Epoch 10/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5714 - loss: 1.1735 - val_accuracy: 0.5093 - val_loss: 1.3479\n",
            "Epoch 11/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6398 - loss: 1.0887 - val_accuracy: 0.4969 - val_loss: 1.3066\n",
            "Epoch 12/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6566 - loss: 1.0375 - val_accuracy: 0.4845 - val_loss: 1.2727\n",
            "Epoch 13/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7022 - loss: 0.9575 - val_accuracy: 0.5217 - val_loss: 1.2433\n",
            "Epoch 14/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6961 - loss: 0.8935 - val_accuracy: 0.5342 - val_loss: 1.2098\n",
            "Epoch 15/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7465 - loss: 0.8382 - val_accuracy: 0.5404 - val_loss: 1.1953\n",
            "Epoch 16/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7613 - loss: 0.8035 - val_accuracy: 0.5652 - val_loss: 1.1648\n",
            "Epoch 17/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8287 - loss: 0.6856 - val_accuracy: 0.5590 - val_loss: 1.1472\n",
            "Epoch 18/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8148 - loss: 0.6839 - val_accuracy: 0.5901 - val_loss: 1.1332\n",
            "Epoch 19/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8505 - loss: 0.6164 - val_accuracy: 0.5839 - val_loss: 1.1110\n",
            "Epoch 20/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8650 - loss: 0.5639 - val_accuracy: 0.5839 - val_loss: 1.1114\n",
            "Epoch 21/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8520 - loss: 0.5176 - val_accuracy: 0.6087 - val_loss: 1.0978\n",
            "Epoch 22/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8886 - loss: 0.4833 - val_accuracy: 0.5963 - val_loss: 1.0810\n",
            "Epoch 23/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8926 - loss: 0.4337 - val_accuracy: 0.5839 - val_loss: 1.0938\n",
            "Epoch 24/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8849 - loss: 0.4256 - val_accuracy: 0.5901 - val_loss: 1.1201\n",
            "Epoch 25/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9426 - loss: 0.3515 - val_accuracy: 0.6149 - val_loss: 1.1075\n",
            "Epoch 26/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9199 - loss: 0.3274 - val_accuracy: 0.5901 - val_loss: 1.0989\n",
            "Epoch 27/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9398 - loss: 0.3161 - val_accuracy: 0.6025 - val_loss: 1.1075\n",
            "Epoch 28/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9636 - loss: 0.2919 - val_accuracy: 0.6149 - val_loss: 1.1046\n",
            "Epoch 29/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9504 - loss: 0.2625 - val_accuracy: 0.5404 - val_loss: 1.1772\n",
            "Epoch 30/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9614 - loss: 0.2481 - val_accuracy: 0.6087 - val_loss: 1.1244\n",
            "Epoch 31/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9709 - loss: 0.2117 - val_accuracy: 0.6025 - val_loss: 1.1585\n",
            "Epoch 32/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9795 - loss: 0.1798 - val_accuracy: 0.6025 - val_loss: 1.1370\n",
            "Epoch 33/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9855 - loss: 0.1799 - val_accuracy: 0.5901 - val_loss: 1.2274\n",
            "Epoch 34/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9839 - loss: 0.1638 - val_accuracy: 0.5901 - val_loss: 1.2239\n",
            "Epoch 35/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9836 - loss: 0.1525 - val_accuracy: 0.5590 - val_loss: 1.2682\n",
            "Epoch 36/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9932 - loss: 0.1292 - val_accuracy: 0.6087 - val_loss: 1.2923\n",
            "Epoch 37/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9919 - loss: 0.1371 - val_accuracy: 0.5714 - val_loss: 1.2653\n",
            "Epoch 38/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.1173 - val_accuracy: 0.5839 - val_loss: 1.2543\n",
            "Epoch 39/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9913 - loss: 0.1073 - val_accuracy: 0.5839 - val_loss: 1.2743\n",
            "Epoch 40/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0900 - val_accuracy: 0.5901 - val_loss: 1.2912\n",
            "Epoch 41/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0853 - val_accuracy: 0.5652 - val_loss: 1.3027\n",
            "Epoch 42/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0710 - val_accuracy: 0.5839 - val_loss: 1.3329\n",
            "Epoch 43/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0728 - val_accuracy: 0.5901 - val_loss: 1.3309\n",
            "Epoch 44/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0695 - val_accuracy: 0.6025 - val_loss: 1.3663\n",
            "Epoch 45/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0715 - val_accuracy: 0.5963 - val_loss: 1.3699\n",
            "Epoch 46/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9975 - loss: 0.0601 - val_accuracy: 0.5714 - val_loss: 1.3975\n",
            "Epoch 47/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0573 - val_accuracy: 0.5776 - val_loss: 1.3761\n",
            "Epoch 48/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0552 - val_accuracy: 0.5963 - val_loss: 1.4482\n",
            "Epoch 49/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0460 - val_accuracy: 0.5776 - val_loss: 1.3979\n",
            "Epoch 50/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0427 - val_accuracy: 0.5590 - val_loss: 1.4523\n",
            "Epoch 51/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0417 - val_accuracy: 0.5714 - val_loss: 1.4210\n",
            "Epoch 52/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0354 - val_accuracy: 0.5714 - val_loss: 1.4864\n",
            "Epoch 53/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0364 - val_accuracy: 0.5776 - val_loss: 1.4644\n",
            "Epoch 54/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0350 - val_accuracy: 0.5714 - val_loss: 1.4778\n",
            "Epoch 55/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0348 - val_accuracy: 0.5714 - val_loss: 1.4779\n",
            "Epoch 56/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0303 - val_accuracy: 0.5714 - val_loss: 1.5042\n",
            "Epoch 57/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0308 - val_accuracy: 0.5714 - val_loss: 1.5193\n",
            "Epoch 58/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 0.5714 - val_loss: 1.5122\n",
            "Epoch 59/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.5714 - val_loss: 1.5275\n",
            "Epoch 60/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.5714 - val_loss: 1.5555\n",
            "Epoch 61/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 0.5776 - val_loss: 1.5409\n",
            "Epoch 62/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0229 - val_accuracy: 0.5714 - val_loss: 1.5740\n",
            "Epoch 63/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 0.5714 - val_loss: 1.5697\n",
            "Epoch 64/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 0.5714 - val_loss: 1.5827\n",
            "Epoch 65/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0224 - val_accuracy: 0.5714 - val_loss: 1.5859\n",
            "Epoch 66/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 0.5714 - val_loss: 1.6012\n",
            "Epoch 67/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.5714 - val_loss: 1.6072\n",
            "Epoch 68/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.5714 - val_loss: 1.6157\n",
            "Epoch 69/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.5714 - val_loss: 1.6210\n",
            "Epoch 70/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.5714 - val_loss: 1.6412\n",
            "Epoch 71/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.5714 - val_loss: 1.6362\n",
            "Epoch 72/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.5714 - val_loss: 1.6460\n",
            "Epoch 73/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.5714 - val_loss: 1.6661\n",
            "Epoch 74/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.5714 - val_loss: 1.6644\n",
            "Epoch 75/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.5714 - val_loss: 1.6726\n",
            "Epoch 76/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.5714 - val_loss: 1.6812\n",
            "Epoch 77/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.5652 - val_loss: 1.6786\n",
            "Epoch 78/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.5714 - val_loss: 1.7015\n",
            "Epoch 79/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.5714 - val_loss: 1.7037\n",
            "Epoch 80/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.5714 - val_loss: 1.7118\n",
            "Epoch 81/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.5714 - val_loss: 1.7182\n",
            "Epoch 82/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.5590 - val_loss: 1.7145\n",
            "Epoch 83/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.5714 - val_loss: 1.7303\n",
            "Epoch 84/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.5714 - val_loss: 1.7380\n",
            "Epoch 85/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.5714 - val_loss: 1.7401\n",
            "Epoch 86/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.5652 - val_loss: 1.7430\n",
            "Epoch 87/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.5652 - val_loss: 1.7563\n",
            "Epoch 88/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.5714 - val_loss: 1.7619\n",
            "Epoch 89/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.5714 - val_loss: 1.7676\n",
            "Epoch 90/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.5652 - val_loss: 1.7736\n",
            "Epoch 91/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.5590 - val_loss: 1.7778\n",
            "Epoch 92/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.5714 - val_loss: 1.7954\n",
            "Epoch 93/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.5590 - val_loss: 1.7861\n",
            "Epoch 94/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.5590 - val_loss: 1.7946\n",
            "Epoch 95/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.5714 - val_loss: 1.8089\n",
            "Epoch 96/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.5590 - val_loss: 1.8082\n",
            "Epoch 97/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.5590 - val_loss: 1.8136\n",
            "Epoch 98/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.5590 - val_loss: 1.8170\n",
            "Epoch 99/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.5590 - val_loss: 1.8206\n",
            "Epoch 100/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.5590 - val_loss: 1.8298\n",
            "Epoch 101/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.5714 - val_loss: 1.8410\n",
            "Epoch 102/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.5652 - val_loss: 1.8455\n",
            "Epoch 103/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.5590 - val_loss: 1.8435\n",
            "Epoch 104/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.5590 - val_loss: 1.8505\n",
            "Epoch 105/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.5590 - val_loss: 1.8529\n",
            "Epoch 106/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.5590 - val_loss: 1.8623\n",
            "Epoch 107/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.5590 - val_loss: 1.8676\n",
            "Epoch 108/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.5590 - val_loss: 1.8703\n",
            "Epoch 109/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.5590 - val_loss: 1.8756\n",
            "Epoch 110/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.5590 - val_loss: 1.8805\n",
            "Epoch 111/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.5590 - val_loss: 1.8858\n",
            "Epoch 112/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.5590 - val_loss: 1.8872\n",
            "Epoch 113/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.5590 - val_loss: 1.8920\n",
            "Epoch 114/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.5590 - val_loss: 1.8978\n",
            "Epoch 115/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.5590 - val_loss: 1.9049\n",
            "Epoch 116/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.5590 - val_loss: 1.8990\n",
            "Epoch 117/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.5590 - val_loss: 1.9068\n",
            "Epoch 118/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.5590 - val_loss: 1.9184\n",
            "Epoch 119/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.5590 - val_loss: 1.9238\n",
            "Epoch 120/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.5590 - val_loss: 1.9263\n",
            "Epoch 121/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5590 - val_loss: 1.9301\n",
            "Epoch 122/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.5590 - val_loss: 1.9274\n",
            "Epoch 123/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5590 - val_loss: 1.9305\n",
            "Epoch 124/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.5590 - val_loss: 1.9423\n",
            "Epoch 125/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5590 - val_loss: 1.9451\n",
            "Epoch 126/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.5590 - val_loss: 1.9495\n",
            "Epoch 127/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.5590 - val_loss: 1.9519\n",
            "Epoch 128/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.5590 - val_loss: 1.9540\n",
            "Epoch 129/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5590 - val_loss: 1.9596\n",
            "Epoch 130/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.5590 - val_loss: 1.9633\n",
            "Epoch 131/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.5590 - val_loss: 1.9657\n",
            "Epoch 132/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.5590 - val_loss: 1.9709\n",
            "Epoch 133/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.5590 - val_loss: 1.9730\n",
            "Epoch 134/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.5590 - val_loss: 1.9787\n",
            "Epoch 135/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.5590 - val_loss: 1.9846\n",
            "Epoch 136/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.5590 - val_loss: 1.9875\n",
            "Epoch 137/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.5590 - val_loss: 1.9888\n",
            "Epoch 138/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.5590 - val_loss: 1.9883\n",
            "Epoch 139/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.5590 - val_loss: 1.9949\n",
            "Epoch 140/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.5590 - val_loss: 1.9976\n",
            "Epoch 141/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.5590 - val_loss: 2.0050\n",
            "Epoch 142/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.5590 - val_loss: 2.0080\n",
            "Epoch 143/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.5590 - val_loss: 2.0113\n",
            "Epoch 144/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5590 - val_loss: 2.0122\n",
            "Epoch 145/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.5590 - val_loss: 2.0152\n",
            "Epoch 146/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.5590 - val_loss: 2.0182\n",
            "Epoch 147/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5590 - val_loss: 2.0232\n",
            "Epoch 148/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.5590 - val_loss: 2.0258\n",
            "Epoch 149/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5590 - val_loss: 2.0261\n",
            "Epoch 150/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.5590 - val_loss: 2.0362\n",
            "Epoch 151/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.5590 - val_loss: 2.0356\n",
            "Epoch 152/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.5590 - val_loss: 2.0402\n",
            "Epoch 153/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.5590 - val_loss: 2.0426\n",
            "Epoch 154/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.5590 - val_loss: 2.0434\n",
            "Epoch 155/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.5590 - val_loss: 2.0485\n",
            "Epoch 156/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.5590 - val_loss: 2.0499\n",
            "Epoch 157/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.5590 - val_loss: 2.0549\n",
            "Epoch 158/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.5590 - val_loss: 2.0598\n",
            "Epoch 159/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.5590 - val_loss: 2.0609\n",
            "Epoch 160/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.5590 - val_loss: 2.0616\n",
            "Epoch 161/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.5590 - val_loss: 2.0702\n",
            "Epoch 162/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.5590 - val_loss: 2.0697\n",
            "Epoch 163/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.5590 - val_loss: 2.0718\n",
            "Epoch 164/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.5590 - val_loss: 2.0721\n",
            "Epoch 165/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.5590 - val_loss: 2.0777\n",
            "Epoch 166/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.5590 - val_loss: 2.0801\n",
            "Epoch 167/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.5590 - val_loss: 2.0852\n",
            "Epoch 168/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.5590 - val_loss: 2.0882\n",
            "Epoch 169/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.5590 - val_loss: 2.0904\n",
            "Epoch 170/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.5590 - val_loss: 2.0898\n",
            "Epoch 171/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.5590 - val_loss: 2.0935\n",
            "Epoch 172/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.5590 - val_loss: 2.0943\n",
            "Epoch 173/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5590 - val_loss: 2.0999\n",
            "Epoch 174/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.5590 - val_loss: 2.1047\n",
            "Epoch 175/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5590 - val_loss: 2.1079\n",
            "Epoch 176/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.5590 - val_loss: 2.1066\n",
            "Epoch 177/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.5590 - val_loss: 2.1086\n",
            "Epoch 178/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.5590 - val_loss: 2.1103\n",
            "Epoch 179/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.5590 - val_loss: 2.1158\n",
            "Epoch 180/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5652 - val_loss: 2.1215\n",
            "Epoch 181/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.5652 - val_loss: 2.1257\n",
            "Epoch 182/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.5590 - val_loss: 2.1237\n",
            "Epoch 183/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.5590 - val_loss: 2.1229\n",
            "Epoch 184/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5590 - val_loss: 2.1256\n",
            "Epoch 185/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.5652 - val_loss: 2.1311\n",
            "Epoch 186/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5652 - val_loss: 2.1373\n",
            "Epoch 187/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5652 - val_loss: 2.1376\n",
            "Epoch 188/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.5652 - val_loss: 2.1370\n",
            "Epoch 189/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.5652 - val_loss: 2.1393\n",
            "Epoch 190/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.5652 - val_loss: 2.1432\n",
            "Epoch 191/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.5652 - val_loss: 2.1456\n",
            "Epoch 192/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5652 - val_loss: 2.1473\n",
            "Epoch 193/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5652 - val_loss: 2.1523\n",
            "Epoch 194/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.5652 - val_loss: 2.1542\n",
            "Epoch 195/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5652 - val_loss: 2.1537\n",
            "Epoch 196/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5652 - val_loss: 2.1547\n",
            "Epoch 197/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5652 - val_loss: 2.1599\n",
            "Epoch 198/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.5652 - val_loss: 2.1633\n",
            "Epoch 199/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5652 - val_loss: 2.1655\n",
            "Epoch 200/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5652 - val_loss: 2.1677\n",
            "\n",
            "------------------------------------------------\n",
            "FINAL REPLICATION RESULT:\n",
            "Target Accuracy (Paper): ~93.31%\n",
            "Achieved Accuracy:       56.52%\n",
            "------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}