{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AoWjIunR44qIKGOKdoutg2BsiVMtNanM",
      "authorship_tag": "ABX9TyP4WR4abVnsUnxR2C9mnEA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/SER_CARINE/Paper_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4WhxoJEP7Bj",
        "outputId": "9cfcb4da-2433-40b0-ba53-7504c8e2990d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Dual-Channel Extraction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scanning : 100%|██████████| 22/22 [14:35<00:00, 39.79s/it]\n",
            "Scanning : 100%|██████████| 2/2 [01:16<00:00, 38.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Converting to Numpy Arrays...\n",
            "\n",
            "Final Dataset Stats:\n",
            "Mel Shape:  (1440, 60, 504, 1)\n",
            "IMel Shape: (1440, 60, 504, 1)\n",
            "Labels:     (1440,)\n",
            "Saving to dual_ravdess_processed_data/...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "# Two input paths (Your manual split folders)\n",
        "PATH_A = \"/content/drive/MyDrive/DeepLearning/External/RAVDESS Emotional Speech Audio/audio_speech_actors_01-24/\"\n",
        "PATH_B = \"/content/drive/MyDrive/DeepLearning/External/RAVDESS Emotional Speech Audio/Test/\"\n",
        "\n",
        "OUTPUT_PATH = \"dual_ravdess_processed_data/\"\n",
        "\n",
        "# RAVDESS Mapping (Merging Neutral 01 + Calm 02)\n",
        "# Classes: 0=Neutral, 1=Happy, 2=Sad, 3=Angry, 4=Fear, 5=Disgust, 6=Surprise\n",
        "EMOTION_MAP = {\n",
        "    1: 0, 2: 0,\n",
        "    3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6\n",
        "}\n",
        "\n",
        "# Technical Specs (Li et al. 2022)\n",
        "SAMPLE_RATE = 16000\n",
        "DURATION = 5.0 # Fixed duration to get ~504 frames\n",
        "TOTAL_SAMPLES = int(SAMPLE_RATE * DURATION) # 80,000\n",
        "\n",
        "# STFT Specs\n",
        "N_FFT = 512\n",
        "WIN_LENGTH = 400 # 25ms\n",
        "HOP_LENGTH = 160 # 10ms (This yields 500-504 frames for 5s)\n",
        "N_MELS = 60      # Paper Table 1\n",
        "FMAX = 8000      # Paper Comparison Result\n",
        "\n",
        "# ==========================================\n",
        "# 2. CUSTOM IMEL MATH (The Innovation)\n",
        "# ==========================================\n",
        "def hz_to_imel(freq):\n",
        "    return 2595 * np.exp(1 + freq / 700.0)\n",
        "\n",
        "def imel_to_hz(imel):\n",
        "    return 700 * (np.log(imel / 2595.0) - 1)\n",
        "\n",
        "def imel_filter_bank(sr, n_fft, n_mels=60, fmin=0.0, fmax=8000):\n",
        "    \"\"\"Generates the Inverse-Mel Triangular Filter Bank\"\"\"\n",
        "    imel_min = hz_to_imel(fmin)\n",
        "    imel_max = hz_to_imel(fmax)\n",
        "\n",
        "    # Create evenly spaced points in IMel scale\n",
        "    imel_points = np.linspace(imel_min, imel_max, n_mels + 2)\n",
        "    hz_points = imel_to_hz(imel_points)\n",
        "\n",
        "    # Convert to FFT bins\n",
        "    bin_points = np.floor((n_fft + 1) * hz_points / sr).astype(int)\n",
        "\n",
        "    filters = np.zeros((n_mels, 1 + n_fft // 2))\n",
        "\n",
        "    for i in range(n_mels):\n",
        "        f_m_minus = bin_points[i]\n",
        "        f_m = bin_points[i+1]\n",
        "        f_m_plus = bin_points[i+2]\n",
        "\n",
        "        for k in range(f_m_minus, f_m):\n",
        "            filters[i, k] = (k - f_m_minus) / (f_m - f_m_minus)\n",
        "        for k in range(f_m, f_m_plus):\n",
        "            filters[i, k] = (f_m_plus - k) / (f_m_plus - f_m)\n",
        "\n",
        "    return filters\n",
        "\n",
        "# ==========================================\n",
        "# 3. FEATURE EXTRACTOR\n",
        "# ==========================================\n",
        "def extract_dual_features(audio_path):\n",
        "    try:\n",
        "        # 1. Load & Pad\n",
        "        y, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
        "        if len(y) < TOTAL_SAMPLES:\n",
        "            y = np.pad(y, (0, TOTAL_SAMPLES - len(y)))\n",
        "        else:\n",
        "            y = y[:TOTAL_SAMPLES]\n",
        "\n",
        "        # 2. Pre-emphasis\n",
        "        # y = lfilter([1, -0.97], [1], y) # Optional, often handled by Mel filter design\n",
        "\n",
        "        # 3. Power Spectrum\n",
        "        D = np.abs(librosa.stft(y, n_fft=N_FFT, win_length=WIN_LENGTH, hop_length=HOP_LENGTH))**2\n",
        "\n",
        "        # 4. Channel A: Mel Spectrogram\n",
        "        mel_filters = librosa.filters.mel(sr=sr, n_fft=N_FFT, n_mels=N_MELS, fmax=FMAX)\n",
        "        mel_spec = np.dot(mel_filters, D)\n",
        "        log_mel = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "        # 5. Channel B: IMel Spectrogram\n",
        "        imel_filters = imel_filter_bank(sr, N_FFT, N_MELS, fmax=FMAX)\n",
        "        imel_spec = np.dot(imel_filters, D)\n",
        "        log_imel = librosa.power_to_db(imel_spec, ref=np.max)\n",
        "\n",
        "        # Shape Check: Should be (60, ~500)\n",
        "        # We need strict shape for CNN. Let's crop/pad to 504 width (Table 1)\n",
        "        TARGET_WIDTH = 504\n",
        "\n",
        "        def fix_width(spec):\n",
        "            if spec.shape[1] > TARGET_WIDTH:\n",
        "                return spec[:, :TARGET_WIDTH]\n",
        "            else:\n",
        "                return np.pad(spec, ((0,0), (0, TARGET_WIDTH - spec.shape[1])))\n",
        "\n",
        "        log_mel = fix_width(log_mel)\n",
        "        log_imel = fix_width(log_imel)\n",
        "\n",
        "        # Add Channel Dim: (60, 504, 1)\n",
        "        return log_mel[..., np.newaxis], log_imel[..., np.newaxis]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# ==========================================\n",
        "# 4. PROCESSING LOOP (MERGING)\n",
        "# ==========================================\n",
        "def process_ravdess_unified():\n",
        "    # Master Lists\n",
        "    X_mel_all = []\n",
        "    X_imel_all = []\n",
        "    Y_all = []\n",
        "    S_all = [] # Speakers\n",
        "\n",
        "    paths_to_scan = [PATH_A, PATH_B]\n",
        "\n",
        "    if not os.path.exists(OUTPUT_PATH):\n",
        "        os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "    print(\"Starting Dual-Channel Extraction...\")\n",
        "\n",
        "    # Iterate over both directories (Train Folder AND Test Folder)\n",
        "    for root_path in paths_to_scan:\n",
        "        if not os.path.exists(root_path):\n",
        "            print(f\"Skipping missing path: {root_path}\")\n",
        "            continue\n",
        "\n",
        "        # Get Actor Folders\n",
        "        actor_folders = [d for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))]\n",
        "\n",
        "        for actor in tqdm(actor_folders, desc=f\"Scanning {os.path.basename(root_path)}\"):\n",
        "            actor_path = os.path.join(root_path, actor)\n",
        "            files = [f for f in os.listdir(actor_path) if f.endswith('.wav')]\n",
        "\n",
        "            for file_name in files:\n",
        "                # Parse Filename: 03-01-06-01-02-01-24.wav\n",
        "                parts = file_name.split('.')[0].split('-')\n",
        "                if len(parts) < 7: continue\n",
        "\n",
        "                emotion_code = int(parts[2])\n",
        "                speaker_id = parts[6] # '24'\n",
        "\n",
        "                if emotion_code not in EMOTION_MAP: continue\n",
        "                label = EMOTION_MAP[emotion_code]\n",
        "\n",
        "                # Extract\n",
        "                full_path = os.path.join(actor_path, file_name)\n",
        "                mel, imel = extract_dual_features(full_path)\n",
        "\n",
        "                if mel is not None:\n",
        "                    X_mel_all.append(mel)\n",
        "                    X_imel_all.append(imel)\n",
        "                    Y_all.append(label)\n",
        "                    S_all.append(speaker_id)\n",
        "\n",
        "    # Convert to Arrays\n",
        "    print(\"\\nConverting to Numpy Arrays...\")\n",
        "    X_mel_all = np.array(X_mel_all)\n",
        "    X_imel_all = np.array(X_imel_all)\n",
        "    Y_all = np.array(Y_all)\n",
        "    S_all = np.array(S_all)\n",
        "\n",
        "    # Clean NaNs\n",
        "    X_mel_all = np.nan_to_num(X_mel_all)\n",
        "    X_imel_all = np.nan_to_num(X_imel_all)\n",
        "\n",
        "    print(f\"\\nFinal Dataset Stats:\")\n",
        "    print(f\"Mel Shape:  {X_mel_all.shape}\")\n",
        "    print(f\"IMel Shape: {X_imel_all.shape}\")\n",
        "    print(f\"Labels:     {Y_all.shape}\")\n",
        "\n",
        "    # Save\n",
        "    print(f\"Saving to {OUTPUT_PATH}...\")\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"X_mel_all.npy\"), X_mel_all)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"X_imel_all.npy\"), X_imel_all)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"Y_all.npy\"), Y_all)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"S_all.npy\"), S_all)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_ravdess_unified()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r dual_ravdess_processed_data.zip dual_ravdess_processed_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqnsl9KqXKYE",
        "outputId": "902d955c-925f-4bcb-af99-2f820d7f9bee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: dual_ravdess_processed_data/ (stored 0%)\n",
            "  adding: dual_ravdess_processed_data/X_mel_all.npy (deflated 58%)\n",
            "  adding: dual_ravdess_processed_data/Y_all.npy (deflated 91%)\n",
            "  adding: dual_ravdess_processed_data/S_all.npy (deflated 98%)\n",
            "  adding: dual_ravdess_processed_data/X_imel_all.npy (deflated 75%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dual_ravdess_processed_data.zip -d ./"
      ],
      "metadata": {
        "id": "agYZx7kbYLex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}