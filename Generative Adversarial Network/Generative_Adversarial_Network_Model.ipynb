{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/Generative%20Adversarial%20Network/Generative_Adversarial_Network_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HL-s5Wr1A8VG"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow matplotlib tensorflow datasets ipywidgets\n",
        "#installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUpRSaxnBmrG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "#importing fashion dataset\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Sg6qNUbKCgHm"
      },
      "outputs": [],
      "source": [
        "#Loading datasets into variable using tensorflow api\n",
        "#'fashion_mnist' specifies which dataset is being loaded\n",
        "ds = tfds.load('fashion_mnist', split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdVhoP0KCHzX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Checking nature of data\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr0xEZJZDtbi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Visualizing data\n",
        "import numpy as np\n",
        "#Building iterator to constantly fetch data\n",
        "dataiterator= ds.as_numpy_iterator()\n",
        "dataiterator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYD8ruuZFPHW"
      },
      "outputs": [],
      "source": [
        "#Setting up matplotlib\n",
        "fig, ax = plt.subplots(ncols =4, figsize=(20,20))\n",
        "#Looping to pick four shapes\n",
        "for idx in range(4):\n",
        "  #Grab image and label\n",
        "  sample = dataiterator.next()\n",
        "  #Plot image\n",
        "  ax[idx].imshow(np.squeeze(sample['image']))\n",
        "  #Print image and prints the axis\n",
        "  ax[idx].title.set_text(sample['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-md0_fhHRA-"
      },
      "outputs": [],
      "source": [
        "#Normalizing data\n",
        "def normalize_data(data):\n",
        "  image = data['image']\n",
        "  return image/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VE51FPJeCvs"
      },
      "outputs": [],
      "source": [
        "#Reloading dataset\n",
        "ds = tfds.load('fashion_mnist', split='train')\n",
        "\n",
        "ds = ds.map(normalize_data)\n",
        "ds = ds.cache()\n",
        "#Shuffle data\n",
        "ds = ds.shuffle(60000)\n",
        "#Batch into 128 images per sample\n",
        "ds = ds.batch(128)\n",
        "#Reduces possibility of bottlenecking\n",
        "ds = ds.prefetch(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N00T_Peue-_K",
        "outputId": "0c16893e-51bd-4786-dab9-b36f9cd8d994"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ds.as_numpy_iterator().next().shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, LeakyReLU, Reshape, UpSampling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "6Nin1F8jsJXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "  model = Sequential()\n",
        "\n",
        "  #Takes in random values and reshapes to 7x7x128\n",
        "  #Beginning of a generated image\n",
        "\n",
        "\n",
        "  model.add(Dense(7*7*128, input_dim = 128))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Reshape((7,7,128)))\n",
        "\n",
        "  #Block 1\n",
        "  model.add(UpSampling2D()) #increases dimension of image\n",
        "  model.add(Conv2D(128,5,padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #Block 2\n",
        "  model.add(UpSampling2D()) #increases dimension of image\n",
        "  model.add(Conv2D(128,5,padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #Down sampling\n",
        "  model.add(Conv2D(128,4,padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  model.add(Conv2D(128,4,padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #Final channel\n",
        "  model.add(Conv2D(1,4,padding=\"same\", activation= 'sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "nJysFYAErnCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = build_generator()\n",
        "test_model.summary()"
      ],
      "metadata": {
        "id": "H8czQZFNstVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator()"
      ],
      "metadata": {
        "id": "5acS1r-BvyqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = generator.predict(np.random.randn(4,128,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3wUSoCnvhkJ",
        "outputId": "18287dd5-4b0b-45df-eff1-d1db7ecfc0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 173ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvBSaSMrw9Qf",
        "outputId": "7af4c41c-b01c-4004-e300-5f6e83765a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = generator.predict(np.random.randn(4,128,1))\n",
        "#Setting up matplotlib\n",
        "fig, ax = plt.subplots(ncols =4, figsize=(20,20))\n",
        "#Looping to pick four shapes\n",
        "for idx,img in enumerate(img):\n",
        "  #Plot image\n",
        "  ax[idx].imshow(np.squeeze(img))\n",
        "  #Print image and prints the axis\n",
        "  ax[idx].title.set_text(idx)"
      ],
      "metadata": {
        "id": "d1RlvBtFwXwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32,5,input_shape=(28,28,1)))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(64,5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(128,5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(256,5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "xwlwBhuGx0zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "4tUnqPdbyHfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9pQbaaO0uJO",
        "outputId": "836b54cd-0d6a-4011-b61c-4ece2a40c2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.predict(np.expand_dims(img,0)) #used when predicting image on a deep neural network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMKfjRqP0JIv",
        "outputId": "b7080ca7-3bd3-4249-b4c2-ea6557137fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 79ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.50190806]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing loss and optimizer fuunctions\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ],
      "metadata": {
        "id": "hkTbX9lv3auE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating instances of loss and optimizer functions\n",
        "g_opt = Adam(learning_rate=0.0001)\n",
        "d_opt = Adam(learning_rate=0.00001)\n",
        "g_loss = BinaryCrossentropy()\n",
        "d_loss = BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "j0t0mHVR4KGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing model\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "-boH40Vhd5sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionGAN(Model):\n",
        "  def _init_(self, generator, discriminator, *args, **kwargs):\n",
        "    super()._init_(*args, **kwargs)\n",
        "    #Crating attributes\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "    pass\n",
        "  def compile(self, g_opt, g_loss, d_opt, d_loss,*args, **kwargs):\n",
        "\n",
        "    super().compile(*args, **kwargs)\n",
        "    self.g_opt = g_opt\n",
        "    self.g_loss = g_loss\n",
        "    self.d_opt = d_opt\n",
        "    self.d_loss = d_loss\n",
        "    pass\n",
        "  def train_step(self, batch):\n",
        "    #Get data\n",
        "    real_images = batch\n",
        "    fake_images = self.generator(tf.random.normal((128,128,1)), training= False)\n",
        "\n",
        "    #Train discriminator\n",
        "    with tf.GradientTape as d_tape:\n",
        "      #Pass the real and fake images to the model\n",
        "      yhat_real = self.discriminator(real_images, training= True)\n",
        "      yhat_fake = self.discriminator(fake_images, training = True)\n",
        "      yhat_realfake = tf.concat([yhat_real, yhat_fake], axis = 0)\n",
        "\n",
        "\n",
        "     #Create labels\n",
        "     y_realfake = tf.concat([tf.zeros_like(yhat_real),tf.ones_like(yhat_fake), axis = 0])\n",
        "\n",
        "      #Add some noise\n",
        "      noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
        "      noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
        "      y_realfake += tf.concat([noise_real, noise_fake], axis =0)\n",
        "\n",
        "      #Calculate loss\n",
        "      total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
        "\n",
        "    #Apply backpropagation\n",
        "    dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
        "    self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
        "\n",
        "    #Train the generator\n",
        "    with tf.GradientTape() as g_tape:\n",
        "      #Generate new images\n",
        "      gen_images = self.generator(tf.random.normal((128,128,1)), training= True)\n",
        "      #Create the predicted labels\n",
        "      predicted_labels =self.discriminator(gen_images, training= False)\n",
        "      #Calculate loss\n",
        "      total_g_loss =self.g_loss(tf.zeros_like(predicted_labels),predicted_labels)\n",
        "    #Apply backpropagation\n",
        "    ggrad = g_tape.gradient(total_g_loss,self.generator.trainable_variables)\n",
        "    self.g_opt.apply_gradient(zip(ggrad,self.generator.trainable_variables))\n",
        "\n",
        "    return{'d_loss: total_d_loss', 'g_loss':total_g_loss}\n"
      ],
      "metadata": {
        "id": "K5cMFq71eTFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create instance of subclass model\n",
        "fashgan = FashionGAN(generator,discriminator)"
      ],
      "metadata": {
        "id": "wMn7FE4ehk4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashgan.compile(g_opt, d_opt, g_loss, d_loss)"
      ],
      "metadata": {
        "id": "T_T-oNam05K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tesorflow.keras.callbacks import Callback"
      ],
      "metadata": {
        "id": "Hn4r4GkP1NXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = fashgan.fit(ds, epochs = 20)"
      ],
      "metadata": {
        "id": "FCAlmL7z18xl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}