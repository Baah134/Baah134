{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/Whisper/Whisper_Transcription_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDg0fv_MjKD3"
      },
      "outputs": [],
      "source": [
        "!pip install openai-whisper jiwer pandas\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import whisper\n",
        "from jiwer import wer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "audio_folder = '/content/drive/MyDrive/DeepLearning/Whisper/my_data/audio'\n",
        "csv_file = \"/content/drive/MyDrive/DeepLearning/Whisper/my_data/transcriptions.csv\""
      ],
      "metadata": {
        "id": "WS9tOR8ZEBFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "LXOl1zpwFulT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCp6xsOKhyGJ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Dictionary {audio file name (without extension): transcription}\n",
        "transcriptions = {os.path.splitext(row[\"filename\"])[0]: row[\"transcription\"] for _, row in df.iterrows()}\n",
        "\n",
        "# ============================\n",
        "# STEP 2: LOAD AUDIO FILES\n",
        "# ============================\n",
        "\n",
        "# Get all audio files (wav, m4a, etc.)\n",
        "audio_files = glob.glob(os.path.join(audio_folder, \"*\"))\n",
        "\n",
        "# ============================\n",
        "# STEP 3: INITIALIZE WHISPER\n",
        "# ============================\n",
        "model = whisper.load_model(\"large\")  # \"small\", \"medium\", \"large\" for better accuracy\n",
        "\n",
        "# ============================\n",
        "# STEP 4: PROCESS EACH AUDIO FILE\n",
        "# ============================\n",
        "matched_data = []  # Store results\n",
        "total_wer = 0  # Sum of all WERs\n",
        "valid_files = 0  # Count files with transcriptions\n",
        "\n",
        "for audio_path in tqdm(audio_files, desc=\"Processing Audios\"):\n",
        "    file_name = os.path.basename(audio_path)  # Extract filename (e.g., \"sample_001.wav\")\n",
        "    file_stem = os.path.splitext(file_name)[0]  # Remove extension (e.g., \"sample_001\")\n",
        "\n",
        "    # ✅ Ensure the transcription exists\n",
        "    ground_truth = transcriptions.get(file_stem)\n",
        "    if ground_truth is None:\n",
        "        continue  # Skip if no matching transcription\n",
        "\n",
        "    # ✅ Transcribe audio using Whisper\n",
        "    result = model.transcribe(audio_path, fp16 = False)\n",
        "    whisper_transcription = result[\"text\"].strip()\n",
        "\n",
        "    # ✅ Compute Word Error Rate (WER)\n",
        "    error_rate = wer(ground_truth, whisper_transcription)\n",
        "\n",
        "    # ✅ Store results\n",
        "    matched_data.append((file_name, whisper_transcription, ground_truth, error_rate))\n",
        "    total_wer += error_rate\n",
        "    valid_files += 1\n",
        "\n",
        "# ============================\n",
        "# STEP 5: COMPUTE AVERAGE WER\n",
        "# ============================\n",
        "average_wer = total_wer / valid_files if valid_files else 0\n",
        "\n",
        "# ============================\n",
        "# STEP 6: SAVE RESULTS TO CSV\n",
        "# ============================\n",
        "output_csv = \"whisper_results.csv\"\n",
        "df_results = pd.DataFrame(matched_data, columns=[\"Filename\", \"Whisper Transcription\", \"Ground Truth\", \"WER\"])\n",
        "df_results.to_csv(output_csv, index=False)\n",
        "\n",
        "# Print Results\n",
        "print(df_results)\n",
        "print(f\"\\n✅ Average WER: {average_wer:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPdFzoYB0n4ZouPfK08Vw5y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}