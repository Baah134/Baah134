{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXIh8RXzNhzsRq2gwojya9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/Whisper/Whisper_Transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "\n",
        "\n",
        "!pip install jiwer\n",
        "from jiwer import wer\n",
        "import whisper\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "QzthGgC1H-io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import soundfile as sf\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from jiwer import wer  # Library for Word Error Rate calculation\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "# Load Afrispeech dataset (e.g., Isizulu)\n",
        "dataset = load_dataset(\"tobiolatunji/afrispeech-200\", \"isizulu\", split=\"train\", streaming=True)\n",
        "\n",
        "# Initialize list to store results\n",
        "results = []\n",
        "\n",
        "# Process 100 samples\n",
        "for idx, sample in tqdm(enumerate(dataset.take(100)), total=100, desc=\"Processing Samples\"):\n",
        "    # Extract waveform and sample rate\n",
        "    audio_waveform = sample[\"audio\"][\"array\"]\n",
        "    sr = sample[\"audio\"][\"sampling_rate\"]\n",
        "\n",
        "    # Save the waveform as a temporary WAV file\n",
        "    wav_path = f\"temp_audio_{idx}.wav\"\n",
        "    sf.write(wav_path, audio_waveform, sr)\n",
        "\n",
        "    # Transcribe using Whisper\n",
        "    result = model.transcribe(wav_path)\n",
        "    whisper_text = result[\"text\"].strip()\n",
        "\n",
        "    # Get actual ground truth text\n",
        "    actual_text = sample[\"transcript\"].strip()\n",
        "\n",
        "    # Compute Word Error Rate (WER)\n",
        "    error_rate = wer(actual_text, whisper_text)\n",
        "\n",
        "    # Store results in a dictionary\n",
        "    results.append({\n",
        "        \"Whisper Transcription\": whisper_text,\n",
        "        \"Actual Label\": actual_text,\n",
        "        \"Word Error Rate\": round(error_rate, 4)  # Rounded to 4 decimal places\n",
        "    })\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"\\nSample {idx+1}:\")\n",
        "    print(\"Whisper:\", whisper_text)\n",
        "    print(\"Actual :\", actual_text)\n",
        "    print(\"WER    :\", round(error_rate, 4))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Save results to a CSV file\n",
        "df = pd.DataFrame(results)\n",
        "csv_filename = \"whisper_transcriptions.csv\"\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"\\nProcessing complete! Results saved in {csv_filename}\")\n"
      ],
      "metadata": {
        "id": "X0H4pdf-HLb4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}