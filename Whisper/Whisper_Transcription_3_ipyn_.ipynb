{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/Whisper/Whisper_Transcription_3_ipyn_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDg0fv_MjKD3"
      },
      "outputs": [],
      "source": [
        "!pip install openai-whisper jiwer pandas\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import whisper\n",
        "from jiwer import wer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "audio_folder = '/content/drive/MyDrive/DeepLearning/Whisper/my_data/audio'\n",
        "csv_file = \"/content/drive/MyDrive/DeepLearning/Whisper/my_data/transcriptions.csv\""
      ],
      "metadata": {
        "id": "WS9tOR8ZEBFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab22836-7541-44a9-a74e-79cc1b49eeb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "LXOl1zpwFulT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCp6xsOKhyGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5cd0a8-f08b-45e2-be5c-6e9f22db1a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.51G/1.51G [00:32<00:00, 50.5MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "Processing Audios: 100%|██████████| 61/61 [00:43<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Filename                              Whisper Transcription  \\\n",
            "0   sample_029.wav  I need to finish this report before the deadline.   \n",
            "1   sample_032.wav           De mizium ezibet showkiz egin artefakts.   \n",
            "2   sample_033.wav  A heavy storm is expected to hit the coast ton...   \n",
            "3   sample_007.wav  Tomorrow's forecast predicts heavy thunderstor...   \n",
            "4   sample_006.wav  Innovation drives the future of artificial int...   \n",
            "..             ...                                                ...   \n",
            "56  sample_073.wav     They practice their lines for the school play.   \n",
            "57  sample_074.wav     The machine learning model improved over time.   \n",
            "58  sample_072.wav       The chef carefully plaited the gourmet dish.   \n",
            "59  sample_063.wav            The alarm clock buzzed loudly at 6 a.m.   \n",
            "60  sample_065.wav     A rainbow appeared outside the heavy rainfall.   \n",
            "\n",
            "                                         Ground Truth       WER  \n",
            "0   I need to finish this report before the deadline.  0.000000  \n",
            "1     The museum exhibit showcased ancient artifacts.  1.000000  \n",
            "2   A heavy storm is expected to hit the coast ton...  0.000000  \n",
            "3   Tomorrow’s forecast predicts heavy thunderstor...  0.125000  \n",
            "4   Innovation drives the future of artificial int...  0.000000  \n",
            "..                                                ...       ...  \n",
            "56    They practiced their lines for the school play.  0.125000  \n",
            "57     The machine learning model improved over time.  0.000000  \n",
            "58        The chef carefully plated the gourmet dish.  0.142857  \n",
            "59             The alarm clock buzzed loudly at 6 AM.  0.125000  \n",
            "60     The rainbow appeared after the heavy rainfall.  0.285714  \n",
            "\n",
            "[61 rows x 4 columns]\n",
            "\n",
            "✅ Average WER: 0.1219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Dictionary {audio file name (without extension): transcription}\n",
        "transcriptions = {os.path.splitext(row[\"filename\"])[0]: row[\"transcription\"] for _, row in df.iterrows()}\n",
        "\n",
        "\n",
        "# Get all audio files (wav, m4a, etc.)\n",
        "audio_files = glob.glob(os.path.join(audio_folder, \"*\"))\n",
        "\n",
        "\n",
        "model = whisper.load_model(\"turbo\")  # \"small\", \"medium\", \"large\" for better accuracy\n",
        "\n",
        "\n",
        "matched_data = []  # Store results\n",
        "total_wer = 0  # Sum of all WERs\n",
        "valid_files = 0  # Count files with transcriptions\n",
        "\n",
        "for audio_path in tqdm(audio_files, desc=\"Processing Audios\"):\n",
        "    file_name = os.path.basename(audio_path)  # Extract filename (e.g., \"sample_001.wav\")\n",
        "    file_stem = os.path.splitext(file_name)[0]  # Remove extension (e.g., \"sample_001\")\n",
        "\n",
        "    #\n",
        "    ground_truth = transcriptions.get(file_stem)\n",
        "    if ground_truth is None:\n",
        "        continue  # Skip if no matching transcription\n",
        "\n",
        "    # Transcribe audio using Whisper\n",
        "    result = model.transcribe(audio_path)\n",
        "    whisper_transcription = result[\"text\"].strip()\n",
        "\n",
        "    # Compute Word Error Rate (WER)\n",
        "    error_rate = wer(ground_truth, whisper_transcription)\n",
        "\n",
        "    # Store results\n",
        "    matched_data.append((file_name, whisper_transcription, ground_truth, error_rate))\n",
        "    total_wer += error_rate\n",
        "    valid_files += 1\n",
        "\n",
        "average_wer = total_wer / valid_files if valid_files else 0\n",
        "\n",
        "# ============================\n",
        "# STEP 6: SAVE RESULTS TO CSV\n",
        "# ============================\n",
        "output_csv = \"whisper_results.csv\"\n",
        "df_results = pd.DataFrame(matched_data, columns=[\"Filename\", \"Whisper Transcription\", \"Ground Truth\", \"WER\"])\n",
        "df_results.to_csv(output_csv, index=False)\n",
        "\n",
        "# Print Results\n",
        "print(df_results)\n",
        "print(f\"\\n✅ Average WER: {average_wer:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHWWflkvFYV9uVSJK0Us7R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}