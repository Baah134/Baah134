{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baah134/Baah134/blob/main/Whisper/Whisper_Transcription_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGCdnjpCInO2"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4pr0pdt0iND"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# üìÇ Paths\n",
        "AUDIO_DIR = '/content/drive/MyDrive/DeepLearning/Whisper/dev'  # Folder containing subfolders of audio files\n",
        "CSV_PATH = \"/content/drive/MyDrive/DeepLearning/Whisper/transcripts.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPlhrbY6wcSy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# üìÇ Paths\n",
        "AUDIO_DIR = '/content/drive/MyDrive/DeepLearning/Whisper/dev'  # Folder containing subfolders of audio files\n",
        "CSV_PATH = \"/content/drive/MyDrive/DeepLearning/Whisper/transcripts.csv\"\n",
        "\n",
        "# üìå Load transcription CSV\n",
        "df_transcriptions = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Ensure the CSV has correct column names\n",
        "AUDIO_COLUMN = \"audio_path\"  # Column name containing full paths in the CSV\n",
        "TEXT_COLUMN = \"transcript\"  # Column name for transcriptions\n",
        "\n",
        "# Step 1Ô∏è‚É£: Extract just the filename (e.g., \"audio_001.wav\") from the CSV audio paths\n",
        "df_transcriptions[\"filename\"] = df_transcriptions[AUDIO_COLUMN].apply(lambda x: os.path.basename(x))\n",
        "\n",
        "# Convert CSV into a dictionary {filename: transcription}\n",
        "transcription_dict = dict(zip(df_transcriptions[\"filename\"], df_transcriptions[TEXT_COLUMN]))\n",
        "\n",
        "# Step 2Ô∏è‚É£: Get list of all .wav files inside subdirectories\n",
        "all_audio_files = []\n",
        "for root, dirs, files in os.walk(AUDIO_DIR):\n",
        "    for file in files:\n",
        "        if file.endswith(\".wav\"):\n",
        "            full_path = os.path.join(root, file)\n",
        "            all_audio_files.append(full_path)\n",
        "\n",
        "# Step 3Ô∏è‚É£: Extract filenames from actual audio file paths\n",
        "audio_dict = {os.path.basename(file): file for file in all_audio_files}  # {filename: full_path}\n",
        "\n",
        "# Step 4Ô∏è‚É£: Match filenames in CSV with actual audio file paths\n",
        "matched_audio_files = {audio_dict[f]: transcription_dict[f] for f in transcription_dict if f in audio_dict}\n",
        "\n",
        "# Step 5Ô∏è‚É£: Pick 100 random samples\n",
        "random.seed(42)\n",
        "selected_samples = random.sample(list(matched_audio_files.items()), 100)\n",
        "\n",
        "# üéØ Print first 5 matched samples\n",
        "for audio_path, transcription in selected_samples[:5]:\n",
        "    print(f\"Audio File: {audio_path}\")\n",
        "    print(f\"Transcription: {transcription}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqTRGlOh1Grn"
      },
      "outputs": [],
      "source": [
        "!pip install openai-whisper jiwer pandas tqdm\n",
        "\n",
        "\n",
        "import whisper\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from jiwer import wer\n",
        "\n",
        "# Load Whisper model (small for speed, you can use \"medium\" or \"large\" for better accuracy)\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "# CSV Output Path\n",
        "CSV_OUTPUT = \"transcription_results.csv\"\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Loop through the selected 100 audio samples\n",
        "for audio_path, actual_transcription in tqdm(selected_samples, desc=\"Processing Audio\"):\n",
        "\n",
        "    # Transcribe audio using Whisper\n",
        "    transcription_result = model.transcribe(audio_path)\n",
        "    whisper_transcription = transcription_result[\"text\"]\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    error_rate = wer(actual_transcription, whisper_transcription)\n",
        "\n",
        "    # Store result\n",
        "    results.append({\n",
        "        \"Audio File\": audio_path,\n",
        "        \"Actual Transcription\": actual_transcription,\n",
        "        \"Whisper Transcription\": whisper_transcription,\n",
        "        \"Word Error Rate\": error_rate\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Save to CSV\n",
        "df_results.to_csv(CSV_OUTPUT, index=False)\n",
        "\n",
        "print(f\"Transcriptions saved to {CSV_OUTPUT}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMXqIZ92MgTlnCNO/FbVP98",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}